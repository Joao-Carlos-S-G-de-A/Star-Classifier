{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of AGN spectra: 35936\n",
      "Number of STAR spectra: 86037\n",
      "Number of BIN spectra: 40676\n",
      "Number of GAL spectra: 1699\n"
     ]
    }
   ],
   "source": [
    "# Specify the directory\n",
    "directory = 'training_set/agn_spectra'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "id_train_agn = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "# star directory\n",
    "directory = 'training_set/star_spectra'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "id_train_star = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "# binary directory\n",
    "directory = 'training_set/bin_spectra'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "id_train_bin = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "# galaxy directory\n",
    "directory = 'training_set/gal_spectra'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "id_train_gal = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "# print the number of files in each category\n",
    "print('Number of AGN spectra:', len(id_train_agn))\n",
    "print('Number of STAR spectra:', len(id_train_star))\n",
    "print('Number of BIN spectra:', len(id_train_bin))\n",
    "print('Number of GAL spectra:', len(id_train_gal))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of AGN spectra: 400\n",
      "Number of STAR spectra: 400\n",
      "Number of BIN spectra: 400\n",
      "Number of GAL spectra: 400\n"
     ]
    }
   ],
   "source": [
    "# Specify the directory\n",
    "directory = 'validation_set/agn_spectra'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "id_val_agn = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "# star directory\n",
    "directory = 'validation_set/star_spectra'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "id_val_star = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "# binary directory\n",
    "directory = 'validation_set/bin_spectra'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "id_val_bin = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "# galaxy directory\n",
    "directory = 'validation_set/gal_spectra'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "id_val_gal = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "# print the number of files in each category\n",
    "print('Number of AGN spectra:', len(id_val_agn))\n",
    "print('Number of STAR spectra:', len(id_val_star))\n",
    "print('Number of BIN spectra:', len(id_val_bin))\n",
    "print('Number of GAL spectra:', len(id_val_gal))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: had to do it twice; val and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamost_catalog = pd.read_csv(\"dr9_v2.0_LRS_catalogue.csv\")  # Assuming CSV format for LAMOST catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting of with Gal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  ra        dec\n",
      "89        332.393310  -1.199750\n",
      "617       332.627720   0.360050\n",
      "1342      330.416750  -0.672220\n",
      "2102      331.741550   1.177070\n",
      "3482       43.313820  -0.989460\n",
      "...              ...        ...\n",
      "10670233  209.355176  55.069539\n",
      "10678832  189.839336  45.334841\n",
      "10680626  155.780246  47.714593\n",
      "10681007  236.849923  32.482925\n",
      "10682030  222.381889  -3.255226\n",
      "\n",
      "[1699 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "obsid_list = id_train_gal\n",
    "obsid_list = [int(obsid) for obsid in obsid_list]\n",
    "\n",
    "# Filter the DataFrame\n",
    "filtered_df = lamost_catalog[lamost_catalog['obsid'].isin(obsid_list)]\n",
    "\n",
    "# Get the 'ra' and 'dec' values\n",
    "ra_dec_values = filtered_df[['ra', 'dec']]\n",
    "print(ra_dec_values)\n",
    "\n",
    "################################################################################################################\n",
    "\n",
    "# Load your GAL data and LAMOST catalog (assuming you have a local CSV or FITS file for LAMOST)\n",
    "gal_data = pd.read_pickle(\"gal_data.pkl\")  # Loaded GAL data\n",
    "\n",
    "# Ensure that RA and Dec columns are numeric and have units\n",
    "gal_data['ra'] = pd.to_numeric(gal_data['ra'], errors='coerce')  # Coerce non-numeric to NaN\n",
    "gal_data['dec'] = pd.to_numeric(gal_data['dec'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in 'ra' and 'dec' columns\n",
    "gal_data = gal_data.dropna(subset=['ra', 'dec'])\n",
    "ra_dec_values = filtered_df[['obsid','ra', 'dec']]\n",
    "\n",
    "# Convert GAL and LAMOST data to SkyCoord objects for crossmatching\n",
    "gal_coords = SkyCoord(ra=gal_data['ra'].values*u.deg, dec=gal_data['dec'].values*u.deg)\n",
    "lamost_coords = SkyCoord(ra=ra_dec_values['ra'].values*u.deg, dec=ra_dec_values['dec'].values*u.deg)\n",
    "\n",
    "# Crossmatch the GAL and LAMOST data\n",
    "idx, d2d, _ = gal_coords.match_to_catalog_sky(lamost_coords)\n",
    "\n",
    "# Define a matching radius\n",
    "match_radius = 1 * u.arcsec\n",
    "matches = d2d < match_radius\n",
    "\n",
    "# Filter the matches\n",
    "matched_gal = gal_data.iloc[matches]\n",
    "matched_lamost = ra_dec_values.iloc[idx[matches]]\n",
    "\n",
    "# Combine the matched data\n",
    "matched_data = pd.concat([matched_gal.reset_index(drop=True), matched_lamost.reset_index(drop=True)], axis=1)\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "# Specify the directory\n",
    "directory = 'gaia_training_set/gal_data'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Loop through the DataFrame and save each row as a .npy file\n",
    "for index, row in matched_data.iterrows():\n",
    "    # Extract the filename\n",
    "    filename = row['obsid']\n",
    "    \n",
    "    # Select the columns you want to save\n",
    "    values_to_save = row[['ra','ra_error', 'dec', 'dec_error', 'phot_g_mean_flux', 'phot_g_mean_flux_error', 'phot_bp_mean_flux', 'phot_bp_mean_flux_error', 'phot_rp_mean_flux', 'phot_rp_mean_flux_error', 'parallax', 'parallax_error', 'pmra', 'pmra_error', 'pmdec', 'pmdec_error']].values\n",
    "    \n",
    "    # Save the values as a .npy file in the specified directory\n",
    "    np.save(os.path.join(directory, f\"{filename}.npy\"), values_to_save)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Doing the same for bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  ra        dec\n",
      "16577     351.174109  31.489124\n",
      "119044    106.765840  27.194232\n",
      "189217      0.000707  32.146507\n",
      "198231     55.221293  52.095851\n",
      "220948     45.609962  50.278437\n",
      "...              ...        ...\n",
      "10624028  357.123560  51.339421\n",
      "10628359  125.487290  23.334434\n",
      "10636107   37.437670  58.890582\n",
      "10638219   54.564625  54.660116\n",
      "10683416  275.201100   8.617276\n",
      "\n",
      "[400 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "obsid_list = id_val_bin\n",
    "obsid_list = [int(obsid) for obsid in obsid_list]\n",
    "\n",
    "# Filter the DataFrame\n",
    "# Filter the DataFrame\n",
    "filtered_df = lamost_catalog[lamost_catalog['obsid'].isin(obsid_list)]\n",
    "\n",
    "# Get the 'ra' and 'dec' values\n",
    "ra_dec_values = filtered_df[['ra', 'dec']]\n",
    "print(ra_dec_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your GAL data and LAMOST catalog (assuming you have a local CSV or FITS file for LAMOST)\n",
    "bin_data = pd.read_pickle(\"Pickles/bin_data.pkl\")  # Loaded BIN data\n",
    "\n",
    "# Ensure that RA and Dec columns are numeric and have units\n",
    "bin_data['ra'] = pd.to_numeric(bin_data['ra'], errors='coerce')  # Coerce non-numeric to NaN\n",
    "bin_data['dec'] = pd.to_numeric(bin_data['dec'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in 'ra' and 'dec' columns\n",
    "bin_data = bin_data.dropna(subset=['ra', 'dec'])\n",
    "ra_dec_values = filtered_df[['obsid','ra', 'dec']]\n",
    "# Convert GAL and LAMOST data to SkyCoord objects for crossmatching\n",
    "bin_coords = SkyCoord(ra=bin_data['ra'].values*u.deg, dec=bin_data['dec'].values*u.deg)\n",
    "lamost_coords = SkyCoord(ra=ra_dec_values['ra'].values*u.deg, dec=ra_dec_values['dec'].values*u.deg)\n",
    "\n",
    "# Crossmatch the GAL and LAMOST data\n",
    "idx, d2d, _ = bin_coords.match_to_catalog_sky(lamost_coords)\n",
    "\n",
    "# Define a matching radius\n",
    "match_radius = 1 * u.arcsec\n",
    "matches = d2d < match_radius\n",
    "\n",
    "# Filter the matches\n",
    "matched_bin = bin_data.iloc[matches]\n",
    "matched_lamost = ra_dec_values.iloc[idx[matches]]\n",
    "\n",
    "# Combine the matched data\n",
    "matched_data = pd.concat([matched_bin.reset_index(drop=True), matched_lamost.reset_index(drop=True)], axis=1)\n",
    "\n",
    "#######################################################################################################################\n",
    "# Specify the directory\n",
    "directory = 'gaia_validation_set/bin_data'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Loop through the DataFrame and save each row as a .npy file\n",
    "# Loop through the DataFrame and save each row as a .npy file\n",
    "for index, row in matched_data.iterrows():\n",
    "    # Extract the filename\n",
    "    filename = row['obsid']\n",
    "    \n",
    "    # Select the columns you want to save\n",
    "    values_to_save = row[['ra','ra_error', 'dec', 'dec_error', 'phot_g_mean_flux', 'phot_g_mean_flux_error', 'phot_bp_mean_flux', 'phot_bp_mean_flux_error', 'phot_rp_mean_flux', 'phot_rp_mean_flux_error', 'parallax', 'parallax_error', 'pmra', 'pmra_error', 'pmdec', 'pmdec_error']].values\n",
    "    \n",
    "    # Save the values as a .npy file in the specified directory\n",
    "    np.save(os.path.join(directory, f\"{filename}.npy\"), values_to_save)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing the same for Stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  ra        dec\n",
      "78867      50.714358  51.674194\n",
      "157499     56.451623  48.307761\n",
      "245373    145.822784  31.473291\n",
      "288677     19.738333  -0.429333\n",
      "344065     39.539134  56.226054\n",
      "...              ...        ...\n",
      "10542009   62.107115  55.052085\n",
      "10590464  156.773001  35.559637\n",
      "10612659  316.005910  34.610072\n",
      "10616792   44.856373  29.498262\n",
      "10685162  282.309970   8.837147\n",
      "\n",
      "[400 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "obsid_list = id_val_star\n",
    "obsid_list = [int(obsid) for obsid in obsid_list]\n",
    "\n",
    "# Filter the DataFrame\n",
    "filtered_df = lamost_catalog[lamost_catalog['obsid'].isin(obsid_list)]\n",
    "\n",
    "# Get the 'ra' and 'dec' values\n",
    "ra_dec_values = filtered_df[['ra', 'dec']]\n",
    "print(ra_dec_values)    \n",
    "\n",
    "# Load your GAL data and LAMOST catalog (assuming you have a local CSV or FITS file for LAMOST)\n",
    "star_data = pd.read_pickle(\"Pickles/star_data.pkl\")  # Loaded STAR data\n",
    "\n",
    "# Ensure that RA and Dec columns are numeric and have units\n",
    "star_data['ra'] = pd.to_numeric(star_data['ra'], errors='coerce')  # Coerce non-numeric to NaN\n",
    "star_data['dec'] = pd.to_numeric(star_data['dec'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in 'ra' and 'dec' columns\n",
    "star_data = star_data.dropna(subset=['ra', 'dec'])\n",
    "ra_dec_values = filtered_df[['obsid','ra', 'dec']]\n",
    "# Convert GAL and LAMOST data to SkyCoord objects for crossmatching\n",
    "star_coords = SkyCoord(ra=star_data['ra'].values*u.deg, dec=star_data['dec'].values*u.deg)\n",
    "lamost_coords = SkyCoord(ra=ra_dec_values['ra'].values*u.deg, dec=ra_dec_values['dec'].values*u.deg)\n",
    "\n",
    "# Crossmatch the GAL and LAMOST data\n",
    "idx, d2d, _ = star_coords.match_to_catalog_sky(lamost_coords)\n",
    "\n",
    "# Define a matching radius\n",
    "match_radius = 1 * u.arcsec\n",
    "matches = d2d < match_radius\n",
    "\n",
    "# Filter the matches\n",
    "matched_star = star_data.iloc[matches]\n",
    "matched_lamost = ra_dec_values.iloc[idx[matches]]\n",
    "\n",
    "# Combine the matched data\n",
    "matched_data = pd.concat([matched_star.reset_index(drop=True), matched_lamost.reset_index(drop=True)], axis=1)\n",
    "\n",
    "#######################################################################################################################\n",
    "# Specify the directory\n",
    "directory = 'gaia_validation_set/star_data'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Loop through the DataFrame and save each row as a .npy file\n",
    "# Loop through the DataFrame and save each row as a .npy file\n",
    "for index, row in matched_data.iterrows():\n",
    "    # Extract the filename\n",
    "    filename = row['obsid']\n",
    "    \n",
    "    # Select the columns you want to save\n",
    "    values_to_save = row[['ra','ra_error', 'dec', 'dec_error', 'phot_g_mean_flux', 'phot_g_mean_flux_error', 'phot_bp_mean_flux', 'phot_bp_mean_flux_error', 'phot_rp_mean_flux', 'phot_rp_mean_flux_error', 'parallax', 'parallax_error', 'pmra', 'pmra_error', 'pmdec', 'pmdec_error']].values\n",
    "    \n",
    "    # Save the values as a .npy file in the specified directory\n",
    "    np.save(os.path.join(directory, f\"{filename}.npy\"), values_to_save)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing the same for AGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  ra        dec\n",
      "191       330.559330  -1.194770\n",
      "250       330.872710  -1.160080\n",
      "265       330.263060  -0.883410\n",
      "344       331.182280  -0.110750\n",
      "357       330.774316   0.581631\n",
      "...              ...        ...\n",
      "10685617  223.215770  38.688223\n",
      "10685708  241.194370   5.478200\n",
      "10685736  242.269670   5.353891\n",
      "10685779  243.686543   4.325836\n",
      "10686193  226.997120  26.928283\n",
      "\n",
      "[35936 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "obsid_list = id_train_agn\n",
    "obsid_list = [int(obsid) for obsid in obsid_list]\n",
    "\n",
    "# Filter the DataFrame\n",
    "filtered_df = lamost_catalog[lamost_catalog['obsid'].isin(obsid_list)]\n",
    "\n",
    "# Get the 'ra' and 'dec' values\n",
    "ra_dec_values = filtered_df[['ra', 'dec']]\n",
    "print(ra_dec_values)    \n",
    "\n",
    "# Load your GAL data and LAMOST catalog (assuming you have a local CSV or FITS file for LAMOST)\n",
    "agn_data = pd.read_pickle(\"Pickles/agn_data.pkl\")  # Loaded AGN data\n",
    "\n",
    "# Ensure that RA and Dec columns are numeric and have units\n",
    "agn_data['ra'] = pd.to_numeric(agn_data['ra'], errors='coerce')  # Coerce non-numeric to NaN\n",
    "agn_data['dec'] = pd.to_numeric(agn_data['dec'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in 'ra' and 'dec' columns\n",
    "agn_data = agn_data.dropna(subset=['ra', 'dec'])\n",
    "ra_dec_values = filtered_df[['obsid','ra', 'dec']]\n",
    "\n",
    "# Convert GAL and LAMOST data to SkyCoord objects for crossmatching\n",
    "agn_coords = SkyCoord(ra=agn_data['ra'].values*u.deg, dec=agn_data['dec'].values*u.deg)\n",
    "lamost_coords = SkyCoord(ra=ra_dec_values['ra'].values*u.deg, dec=ra_dec_values['dec'].values*u.deg)\n",
    "\n",
    "# Crossmatch the GAL and LAMOST data\n",
    "idx, d2d, _ = agn_coords.match_to_catalog_sky(lamost_coords)\n",
    "\n",
    "# Define a matching radius\n",
    "match_radius = 1 * u.arcsec\n",
    "matches = d2d < match_radius\n",
    "\n",
    "# Filter the matches\n",
    "matched_agn = agn_data.iloc[matches]\n",
    "matched_lamost = ra_dec_values.iloc[idx[matches]]\n",
    "\n",
    "# Combine the matched data\n",
    "matched_data = pd.concat([matched_agn.reset_index(drop=True), matched_lamost.reset_index(drop=True)], axis=1)\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "# Specify the directory\n",
    "directory = 'gaia_training_set/agn_data'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Loop through the DataFrame and save each row as a .npy file\n",
    "\n",
    "for index, row in matched_data.iterrows():\n",
    "    # Extract the filename\n",
    "    filename = row['obsid']\n",
    "    \n",
    "    # Select the columns you want to save\n",
    "    values_to_save = row[['ra','ra_error', 'dec', 'dec_error', 'phot_g_mean_flux', 'phot_g_mean_flux_error', 'phot_bp_mean_flux', 'phot_bp_mean_flux_error', 'phot_rp_mean_flux', 'phot_rp_mean_flux_error', 'parallax', 'parallax_error', 'pmra', 'pmra_error', 'pmdec', 'pmdec_error']].values\n",
    "    \n",
    "    # Save the values as a .npy file in the specified directory\n",
    "    np.save(os.path.join(directory, f\"{filename}.npy\"), values_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
