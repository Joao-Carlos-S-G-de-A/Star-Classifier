{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from astroquery.gaia import Gaia\n",
    "from astroquery.simbad import Simbad\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "import numpy as np\n",
    "import pyvo as vo\n",
    "import pickle\n",
    "from astroquery.vizier import Vizier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetGAIAData(GaiaDR3SourceIDs):\n",
    "    try:\n",
    "        qry = f\"SELECT * FROM gaiadr3.gaia_source gs WHERE gs.source_id in ({GaiaDR3SourceIDs});\"\n",
    "        job = Gaia.launch_job_async(qry)\n",
    "        tblGaia = job.get_results()\n",
    "        dfGaia = tblGaia.to_pandas()\n",
    "        return dfGaia\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame in case of error\n",
    "\n",
    "def split_ids_into_chunks(id_string, chunk_size=50000):\n",
    "    id_list = id_string.split(', ')\n",
    "    chunks = [', '.join(id_list[i:i + chunk_size]) for i in range(0, len(id_list), chunk_size)]\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting AGN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting SIMBAD labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136918, 2)\n",
      "(819121, 2)\n"
     ]
    }
   ],
   "source": [
    "criteria_ = \"otype = 'AGN..' \"\n",
    "\n",
    "# Initialize SIMBAD\n",
    "simbad = Simbad()\n",
    "simbad.ROW_LIMIT = -1\n",
    "simbad.add_votable_fields(\"ids\", \"otype\")\n",
    "\n",
    "# Define coordinates (random)\n",
    "coordinates = SkyCoord(0, -90, unit=(\"deg\", \"deg\"))\n",
    "coordinates2 = SkyCoord(0, 90, unit=(\"deg\", \"deg\"))\n",
    "\n",
    "# Query region 1st half\n",
    "result = simbad.query_region(coordinates, radius=\"90d0m\",\n",
    "                           #  criteria=\"otype = 'Ma*..' OR otype = 'MS*..' OR otype = 'Y*O..' OR otype = 'Ev*..' \")\n",
    "                           criteria=criteria_)\n",
    "filtered_result = result[\"ids\", \"otype\"] # Keep only the columns we need\n",
    "result_df = filtered_result.to_pandas() # Convert result to a Pandas DataFrame\n",
    "print(result_df.shape)\n",
    "filtered_result = result_df.dropna() # Remove rows with any NULL values\n",
    "data1 = filtered_result.to_numpy() # Convert to numpy array\n",
    "\n",
    "\n",
    "# Query region 2nd half\n",
    "result2 = simbad.query_region(coordinates2, radius=\"90d0m\",\n",
    "                             #criteria=\"otype = 'Ma*..' OR otype = 'MS*..' OR otype = 'Y*O..' OR otype = 'Ev*..' \")\n",
    "                             criteria=criteria_)\n",
    "filtered_result2 = result2[\"ids\", \"otype\"] # Keep only the columns we need\n",
    "result_df2 = filtered_result2.to_pandas() # Convert result to a Pandas DataFrame\n",
    "print(result_df2.shape)\n",
    "filtered_result2 = result_df2.dropna() # Remove rows with any NULL values\n",
    "data2 = filtered_result2.to_numpy() # Convert to numpy array\n",
    "\n",
    "# Combine the two arrays & save\n",
    "#otypes_agn = np.row_stack((data1, data2))\n",
    "#np.save(\"fullsky4catsunfiltered\", simbad_data)\n",
    "\n",
    "# without filtering\n",
    "otypes_agn = pd.concat([result_df, result_df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting coresponding Gaia data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcwin\\AppData\\Local\\Temp\\ipykernel_10088\\1695916639.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  simbad_data['gaia_id'] = simbad_data['gaia_id'].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcwin\\AppData\\Local\\Temp\\ipykernel_10088\\1695916639.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gaia_data['source_id'] = gaia_data['source_id'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the DataFrames\n",
    "simbad_data = otypes_agn\n",
    "\n",
    "# Filter SIMBAD data to only include rows where 'ids' contains 'Gaia DR3'\n",
    "simbad_data['gaia_id'] = simbad_data['ids'].apply(lambda x: next((id for id in x.split('|') if id.startswith('Gaia DR3')), None))\n",
    "\n",
    "# Remove 'Gaia DR3' prefix and drop rows with NaN values in 'gaia_id'\n",
    "simbad_data['gaia_id'] = simbad_data['gaia_id'].str.lstrip('Gaia DR3')\n",
    "simbad_data = simbad_data.dropna(subset=['gaia_id'])\n",
    "\n",
    "# Ensure 'gaia_id' is a string\n",
    "simbad_data['gaia_id'] = simbad_data['gaia_id'].astype(str)\n",
    "\n",
    "# Split the Gaia DR3 source IDs into chunks of 30,000 IDs each\n",
    "GaiaDR3SourceIDs = ', '.join(simbad_data['gaia_id'].astype(str))\n",
    "chunks = split_ids_into_chunks(GaiaDR3SourceIDs)\n",
    "\n",
    "# Initialize an empty DataFrame to store all data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Process each chunk and append the results to the combined DataFrame\n",
    "for chunk in chunks:\n",
    "    dfGaia = GetGAIAData(chunk)\n",
    "    combined_df = pd.concat([combined_df, dfGaia], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a NumPy array if needed\n",
    "combined_matrix = combined_df.to_numpy()\n",
    "\n",
    "# GAIA data\n",
    "gaia_data = combined_df[[\"source_id\", \"ra\", \"ra_error\", \"dec\", \"dec_error\", \"phot_g_mean_flux\", \"phot_g_mean_flux_error\", \"pmra\", \"pmra_error\", \"pmdec\", \"pmdec_error\", \"parallax\", \"parallax_error\", \"phot_bp_mean_flux\", \"phot_bp_mean_flux_error\", \"phot_rp_mean_flux\", \"phot_rp_mean_flux_error\"]]\n",
    "\n",
    "# Convert Gaia source_id to string\n",
    "gaia_data['source_id'] = gaia_data['source_id'].astype(str)\n",
    "\n",
    "# Merge Gaia and SIMBAD data on matching IDs\n",
    "agn_data = pd.merge(gaia_data, simbad_data, left_on='source_id', right_on='gaia_id', how='inner')\n",
    "agn_data.to_pickle(\"agn_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'agn_data.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43magn_data.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     agn_data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      3\u001b[0m agn_data_high_otype \u001b[38;5;241m=\u001b[39m agn_data\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'agn_data.pkl'"
     ]
    }
   ],
   "source": [
    "with open(\"agn_data.pkl\", \"rb\") as f:\n",
    "    agn_data = pickle.load(f)\n",
    "agn_data_high_otype = agn_data.copy()\n",
    "agn_data_high_otype = agn_data_high_otype.assign(otype= \"AGN\")\n",
    "agn_data_high_otype = agn_data_high_otype[[\"source_id\", \"ra\", \"ra_error\", \"dec\", \"dec_error\", \"phot_g_mean_flux\", \"phot_g_mean_flux_error\", \"pmra\", \"pmra_error\", \"pmdec\", \"pmdec_error\", \"parallax\", \"parallax_error\", \"phot_bp_mean_flux\", \"phot_bp_mean_flux_error\", \"phot_rp_mean_flux\", \"phot_rp_mean_flux_error\", \"otype\"]]\n",
    "agn_data_high_otype.to_pickle(\"agn_data_high_otype.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting non-AGN Galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SimbadClass.query_region_async() got an unexpected keyword argument 'criteria'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m coordinates2 \u001b[38;5;241m=\u001b[39m SkyCoord(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m90\u001b[39m, unit\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeg\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Query region 1st half\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43msimbad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_region\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoordinates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m90d0m\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriteria_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m filtered_result \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124motype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;66;03m# Keep only the columns we need\u001b[39;00m\n\u001b[1;32m     15\u001b[0m result_df \u001b[38;5;241m=\u001b[39m filtered_result\u001b[38;5;241m.\u001b[39mto_pandas() \u001b[38;5;66;03m# Convert result to a Pandas DataFrame\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/astroquery/utils/class_or_instance.py:25\u001b[0m, in \u001b[0;36mclass_or_instance.__get__.<locals>.f\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/astroquery/utils/process_asyncs.py:26\u001b[0m, in \u001b[0;36masync_to_sync.<locals>.create_method.<locals>.newmethod\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;129m@class_or_instance\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnewmethod\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     24\u001b[0m     verbose \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 26\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masync_method_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_query_payload\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfield_help\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[0;31mTypeError\u001b[0m: SimbadClass.query_region_async() got an unexpected keyword argument 'criteria'"
     ]
    }
   ],
   "source": [
    "criteria_ = \"otype = 'LSB..' OR otype = 'bCG..' OR otype = 'SBG..' OR otype = 'H2G..' OR otype = 'EmG..'\"\n",
    "\n",
    "# Initialize SIMBAD\n",
    "simbad = Simbad()\n",
    "simbad.ROW_LIMIT = -1\n",
    "simbad.add_votable_fields(\"ids\", \"otype\")\n",
    "\n",
    "# Define coordinates (random)\n",
    "coordinates = SkyCoord(0, -90, unit=(\"deg\", \"deg\"))\n",
    "coordinates2 = SkyCoord(0, 90, unit=(\"deg\", \"deg\"))\n",
    "\n",
    "# Query region 1st half\n",
    "result = simbad.query_region(coordinates, radius=\"90d0m\", criteria=criteria_)\n",
    "filtered_result = result[\"ids\", \"otype\"] # Keep only the columns we need\n",
    "result_df = filtered_result.to_pandas() # Convert result to a Pandas DataFrame\n",
    "print(result_df.shape)\n",
    "filtered_result = result_df.dropna() # Remove rows with any NULL values\n",
    "data1 = filtered_result.to_numpy() # Convert to numpy array\n",
    "\n",
    "\n",
    "# Query region 2nd half\n",
    "result2 = simbad.query_region(coordinates2, radius=\"90d0m\",\n",
    "                             #criteria=\"otype = 'Ma*..' OR otype = 'MS*..' OR otype = 'Y*O..' OR otype = 'Ev*..' \")\n",
    "                             criteria=criteria_)\n",
    "filtered_result2 = result2[\"ids\", \"otype\"] # Keep only the columns we need\n",
    "result_df2 = filtered_result2.to_pandas() # Convert result to a Pandas DataFrame\n",
    "print(result_df2.shape)\n",
    "filtered_result2 = result_df2.dropna() # Remove rows with any NULL values\n",
    "data2 = filtered_result2.to_numpy() # Convert to numpy array\n",
    "\n",
    "# Combine the two arrays & save\n",
    "#otypes_agn = np.row_stack((data1, data2))\n",
    "#np.save(\"fullsky4catsunfiltered\", simbad_data)\n",
    "\n",
    "# without filtering\n",
    "otypes_gal = pd.concat([result_df, result_df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting corresponding gaia data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcwin\\AppData\\Local\\Temp\\ipykernel_10088\\1415820394.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  simbad_data['gaia_id'] = simbad_data['gaia_id'].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Query finished. [astroquery.utils.tap.core]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcwin\\AppData\\Local\\Temp\\ipykernel_10088\\1415820394.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gaia_data['source_id'] = gaia_data['source_id'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the DataFrames\n",
    "simbad_data = otypes_gal\n",
    "\n",
    "# Filter SIMBAD data to only include rows where 'ids' contains 'Gaia DR3'\n",
    "simbad_data['gaia_id'] = simbad_data['ids'].apply(lambda x: next((id for id in x.split('|') if id.startswith('Gaia DR3')), None))\n",
    "\n",
    "# Remove 'Gaia DR3' prefix and drop rows with NaN values in 'gaia_id'\n",
    "simbad_data['gaia_id'] = simbad_data['gaia_id'].str.lstrip('Gaia DR3')\n",
    "simbad_data = simbad_data.dropna(subset=['gaia_id'])\n",
    "\n",
    "# Ensure 'gaia_id' is a string\n",
    "simbad_data['gaia_id'] = simbad_data['gaia_id'].astype(str)\n",
    "\n",
    "# Split the Gaia DR3 source IDs into chunks of 30,000 IDs each\n",
    "GaiaDR3SourceIDs = ', '.join(simbad_data['gaia_id'].astype(str))\n",
    "chunks = split_ids_into_chunks(GaiaDR3SourceIDs)\n",
    "\n",
    "# Initialize an empty DataFrame to store all data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Process each chunk and append the results to the combined DataFrame\n",
    "for chunk in chunks:\n",
    "    dfGaia = GetGAIAData(chunk)\n",
    "    combined_df = pd.concat([combined_df, dfGaia], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a NumPy array if needed\n",
    "combined_matrix = combined_df.to_numpy()\n",
    "\n",
    "# GAIA data\n",
    "gaia_data = combined_df[[\"source_id\", \"ra\", \"ra_error\", \"dec\", \"dec_error\", \"phot_g_mean_flux\", \"phot_g_mean_flux_error\", \"pmra\", \"pmra_error\", \"pmdec\", \"pmdec_error\", \"parallax\", \"parallax_error\", \"phot_bp_mean_flux\", \"phot_bp_mean_flux_error\", \"phot_rp_mean_flux\", \"phot_rp_mean_flux_error\"]]\n",
    "\n",
    "# Convert Gaia source_id to string\n",
    "gaia_data['source_id'] = gaia_data['source_id'].astype(str)\n",
    "\n",
    "# Merge Gaia and SIMBAD data on matching IDs\n",
    "gal_data = pd.merge(gaia_data, simbad_data, left_on='source_id', right_on='gaia_id', how='inner')\n",
    "gal_data.to_pickle(\"gal_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'gal_data.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgal_data.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     gal_data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      3\u001b[0m gal_data_high_otype \u001b[38;5;241m=\u001b[39m gal_data\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gal_data.pkl'"
     ]
    }
   ],
   "source": [
    "with open(\"gal_data.pkl\", \"rb\") as f:\n",
    "    gal_data = pickle.load(f)\n",
    "gal_data_high_otype = gal_data.copy()\n",
    "gal_data_high_otype = gal_data_high_otype.assign(otype= \"GAL\") \n",
    "gal_data_high_otype = gal_data_high_otype[[\"source_id\", \"ra\", \"ra_error\", \"dec\", \"dec_error\", \"phot_g_mean_flux\", \"phot_g_mean_flux_error\", \"pmra\", \"pmra_error\", \"pmdec\", \"pmdec_error\", \"parallax\", \"parallax_error\", \"phot_bp_mean_flux\", \"phot_bp_mean_flux_error\", \"phot_rp_mean_flux\", \"phot_rp_mean_flux_error\", \"otype\"]]\n",
    "print(gal_data_high_otype.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Binaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1446685, 2)\n",
      "(917897, 2)\n"
     ]
    }
   ],
   "source": [
    "criteria_ = \"otype = '**..'\"\n",
    "\n",
    "# Initialize SIMBAD\n",
    "simbad = Simbad()\n",
    "simbad.ROW_LIMIT = -1\n",
    "simbad.add_votable_fields(\"ids\", \"otype\")\n",
    "\n",
    "# Define coordinates (random)\n",
    "coordinates = SkyCoord(0, -90, unit=(\"deg\", \"deg\"))\n",
    "coordinates2 = SkyCoord(0, 90, unit=(\"deg\", \"deg\"))\n",
    "\n",
    "# Query region 1st half\n",
    "result = simbad.query_region(coordinates, radius=\"90d0m\",\n",
    "                           #  criteria=\"otype = 'Ma*..' OR otype = 'MS*..' OR otype = 'Y*O..' OR otype = 'Ev*..' \")\n",
    "                           criteria=criteria_)\n",
    "filtered_result = result[\"ids\", \"otype\"] # Keep only the columns we need\n",
    "result_df = filtered_result.to_pandas() # Convert result to a Pandas DataFrame\n",
    "print(result_df.shape)\n",
    "filtered_result = result_df.dropna() # Remove rows with any NULL values\n",
    "data1 = filtered_result.to_numpy() # Convert to numpy array\n",
    "\n",
    "\n",
    "# Query region 2nd half\n",
    "result2 = simbad.query_region(coordinates2, radius=\"90d0m\",\n",
    "                             #criteria=\"otype = 'Ma*..' OR otype = 'MS*..' OR otype = 'Y*O..' OR otype = 'Ev*..' \")\n",
    "                             criteria=criteria_)\n",
    "filtered_result2 = result2[\"ids\", \"otype\"] # Keep only the columns we need\n",
    "result_df2 = filtered_result2.to_pandas() # Convert result to a Pandas DataFrame\n",
    "print(result_df2.shape)\n",
    "filtered_result2 = result_df2.dropna() # Remove rows with any NULL values\n",
    "data2 = filtered_result2.to_numpy() # Convert to numpy array\n",
    "\n",
    "# Combine the two arrays & save\n",
    "#otypes_agn = np.row_stack((data1, data2))\n",
    "#np.save(\"fullsky4catsunfiltered\", simbad_data)\n",
    "\n",
    "# without filtering\n",
    "otypes_bin = pd.concat([result_df, result_df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting coresponding gaia data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcwin\\AppData\\Local\\Temp\\ipykernel_10088\\249499439.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  simbad_data['gaia_id'] = simbad_data['gaia_id'].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcwin\\AppData\\Local\\Temp\\ipykernel_10088\\249499439.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gaia_data['source_id'] = gaia_data['source_id'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the DataFrames\n",
    "simbad_data = otypes_bin\n",
    "\n",
    "# Filter SIMBAD data to only include rows where 'ids' contains 'Gaia DR3'\n",
    "simbad_data['gaia_id'] = simbad_data['ids'].apply(lambda x: next((id for id in x.split('|') if id.startswith('Gaia DR3')), None))\n",
    "\n",
    "# Remove 'Gaia DR3' prefix and drop rows with NaN values in 'gaia_id'\n",
    "simbad_data['gaia_id'] = simbad_data['gaia_id'].str.lstrip('Gaia DR3')\n",
    "simbad_data = simbad_data.dropna(subset=['gaia_id'])\n",
    "\n",
    "# Ensure 'gaia_id' is a string\n",
    "simbad_data['gaia_id'] = simbad_data['gaia_id'].astype(str)\n",
    "\n",
    "# Split the Gaia DR3 source IDs into chunks of 30,000 IDs each\n",
    "GaiaDR3SourceIDs = ', '.join(simbad_data['gaia_id'].astype(str))\n",
    "chunks = split_ids_into_chunks(GaiaDR3SourceIDs)\n",
    "\n",
    "# Initialize an empty DataFrame to store all data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Process each chunk and append the results to the combined DataFrame\n",
    "for chunk in chunks:\n",
    "    dfGaia = GetGAIAData(chunk)\n",
    "    combined_df = pd.concat([combined_df, dfGaia], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a NumPy array if needed\n",
    "combined_matrix = combined_df.to_numpy()\n",
    "\n",
    "# GAIA data\n",
    "gaia_data = combined_df[[\"source_id\", \"ra\", \"ra_error\", \"dec\", \"dec_error\", \"phot_g_mean_flux\", \"phot_g_mean_flux_error\", \"pmra\", \"pmra_error\", \"pmdec\", \"pmdec_error\", \"parallax\", \"parallax_error\", \"phot_bp_mean_flux\", \"phot_bp_mean_flux_error\", \"phot_rp_mean_flux\", \"phot_rp_mean_flux_error\"]]\n",
    "\n",
    "# Convert Gaia source_id to string\n",
    "gaia_data['source_id'] = gaia_data['source_id'].astype(str)\n",
    "\n",
    "# Merge Gaia and SIMBAD data on matching IDs\n",
    "bin_data = pd.merge(gaia_data, simbad_data, left_on='source_id', right_on='gaia_id', how='inner')\n",
    "bin_data.to_pickle(\"bin_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1700440, 18)\n"
     ]
    }
   ],
   "source": [
    "with open(\"bin_data.pkl\", \"rb\") as f:\n",
    "    bin_data = pickle.load(f)\n",
    "bin_data_high_otype = bin_data.copy()\n",
    "bin_data_high_otype = bin_data_high_otype.assign(otype= \"BIN\")\n",
    "bin_data_high_otype = bin_data_high_otype[[\"source_id\", \"ra\", \"ra_error\", \"dec\", \"dec_error\", \"phot_g_mean_flux\", \"phot_g_mean_flux_error\", \"pmra\", \"pmra_error\", \"pmdec\", \"pmdec_error\", \"parallax\", \"parallax_error\", \"phot_bp_mean_flux\", \"phot_bp_mean_flux_error\", \"phot_rp_mean_flux\", \"phot_rp_mean_flux_error\", \"otype\"]]\n",
    "print(bin_data_high_otype.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data for single stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1237922, 2)\n",
      "(810162, 2)\n"
     ]
    }
   ],
   "source": [
    "criteria_ = \"otype = 'Ma*..' OR otype = 'MS*..' OR otype = 'Y*O..' OR otype = 'Ev*..' OR otype = 'Pe*..' OR otype = 'SN*' OR otype = 'LM*' OR otype = 'V*' OR otype = 'Em*' OR otype = 'PM*' OR otype = 'HV*'\"\n",
    "\n",
    "# Initialize SIMBAD\n",
    "simbad = Simbad()\n",
    "simbad.ROW_LIMIT = -1\n",
    "simbad.add_votable_fields(\"ids\", \"otype\")\n",
    "\n",
    "# Define coordinates (random)\n",
    "coordinates = SkyCoord(0, -90, unit=(\"deg\", \"deg\"))\n",
    "coordinates2 = SkyCoord(0, 90, unit=(\"deg\", \"deg\"))\n",
    "\n",
    "# Query region 1st half\n",
    "result = simbad.query_region(coordinates, radius=\"90d0m\",\n",
    "                           #  criteria=\"otype = 'Ma*..' OR otype = 'MS*..' OR otype = 'Y*O..' OR otype = 'Ev*..' \")\n",
    "                           criteria=criteria_)\n",
    "filtered_result = result[\"ids\", \"otype\"] # Keep only the columns we need\n",
    "result_df = filtered_result.to_pandas() # Convert result to a Pandas DataFrame\n",
    "print(result_df.shape)\n",
    "filtered_result = result_df.dropna() # Remove rows with any NULL values\n",
    "data1 = filtered_result.to_numpy() # Convert to numpy array\n",
    "\n",
    "\n",
    "# Query region 2nd half\n",
    "result2 = simbad.query_region(coordinates2, radius=\"90d0m\",\n",
    "                             #criteria=\"otype = 'Ma*..' OR otype = 'MS*..' OR otype = 'Y*O..' OR otype = 'Ev*..' \")\n",
    "                             criteria=criteria_)\n",
    "filtered_result2 = result2[\"ids\", \"otype\"] # Keep only the columns we need\n",
    "result_df2 = filtered_result2.to_pandas() # Convert result to a Pandas DataFrame\n",
    "print(result_df2.shape)\n",
    "filtered_result2 = result_df2.dropna() # Remove rows with any NULL values\n",
    "data2 = filtered_result2.to_numpy() # Convert to numpy array\n",
    "\n",
    "# Combine the two arrays & save\n",
    "#otypes_agn = np.row_stack((data1, data2))\n",
    "#np.save(\"fullsky4catsunfiltered\", simbad_data)\n",
    "\n",
    "# without filtering\n",
    "otypes_star = pd.concat([result_df, result_df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting coresponding gaia data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcwin\\AppData\\Local\\Temp\\ipykernel_24756\\1499858909.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  simbad_data['gaia_id'] = simbad_data['gaia_id'].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcwin\\AppData\\Local\\Temp\\ipykernel_24756\\1499858909.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gaia_data['source_id'] = gaia_data['source_id'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the DataFrames\n",
    "simbad_data = otypes_star\n",
    "\n",
    "# Filter SIMBAD data to only include rows where 'ids' contains 'Gaia DR3'\n",
    "simbad_data['gaia_id'] = simbad_data['ids'].apply(lambda x: next((id for id in x.split('|') if id.startswith('Gaia DR3')), None))\n",
    "\n",
    "# Remove 'Gaia DR3' prefix and drop rows with NaN values in 'gaia_id'\n",
    "simbad_data['gaia_id'] = simbad_data['gaia_id'].str.lstrip('Gaia DR3')\n",
    "simbad_data = simbad_data.dropna(subset=['gaia_id'])\n",
    "\n",
    "# Ensure 'gaia_id' is a string\n",
    "simbad_data['gaia_id'] = simbad_data['gaia_id'].astype(str)\n",
    "\n",
    "# Split the Gaia DR3 source IDs into chunks of 30,000 IDs each\n",
    "GaiaDR3SourceIDs = ', '.join(simbad_data['gaia_id'].astype(str))\n",
    "chunks = split_ids_into_chunks(GaiaDR3SourceIDs)\n",
    "\n",
    "# Initialize an empty DataFrame to store all data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Process each chunk and append the results to the combined DataFrame\n",
    "for chunk in chunks:\n",
    "    dfGaia = GetGAIAData(chunk)\n",
    "    combined_df = pd.concat([combined_df, dfGaia], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a NumPy array if needed\n",
    "combined_matrix = combined_df.to_numpy()\n",
    "\n",
    "# GAIA data\n",
    "gaia_data = combined_df[[\"source_id\", \"ra\", \"ra_error\", \"dec\", \"dec_error\", \"phot_g_mean_flux\", \"phot_g_mean_flux_error\", \"pmra\", \"pmra_error\", \"pmdec\", \"pmdec_error\", \"parallax\", \"parallax_error\", \"phot_bp_mean_flux\", \"phot_bp_mean_flux_error\", \"phot_rp_mean_flux\", \"phot_rp_mean_flux_error\"]]\n",
    "\n",
    "# Convert Gaia source_id to string\n",
    "gaia_data['source_id'] = gaia_data['source_id'].astype(str)\n",
    "\n",
    "# Merge Gaia and SIMBAD data on matching IDs\n",
    "star_data = pd.merge(gaia_data, simbad_data, left_on='source_id', right_on='gaia_id', how='inner')\n",
    "star_data.to_pickle(\"star_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1499508, 18)\n"
     ]
    }
   ],
   "source": [
    "with open('star_data.pkl', 'rb') as file:\n",
    "    star_data = pickle.load(file)\n",
    "star_data_high_otype = star_data.copy()\n",
    "star_data_high_otype = star_data_high_otype.assign(otype= \"STAR\")\n",
    "star_data_high_otype = star_data_high_otype[[\"source_id\", \"ra\", \"ra_error\", \"dec\", \"dec_error\", \"phot_g_mean_flux\", \"phot_g_mean_flux_error\", \"pmra\", \"pmra_error\", \"pmdec\", \"pmdec_error\", \"parallax\", \"parallax_error\", \"phot_bp_mean_flux\", \"phot_bp_mean_flux_error\", \"phot_rp_mean_flux\", \"phot_rp_mean_flux_error\", \"otype\"]]\n",
    "print(star_data_high_otype.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive way combining all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3267794, 18)\n"
     ]
    }
   ],
   "source": [
    "all_data_high_otype = pd.concat([agn_data_high_otype, gal_data_high_otype, bin_data_high_otype, star_data_high_otype])\n",
    "all_data_high_otype = all_data_high_otype.dropna()  \n",
    "np.save(\"all_data_high_otype\", all_data_high_otype.to_numpy())\n",
    "print(all_data_high_otype.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting equal amounts of data for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agn_data_high_otype' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[43magn_data_high_otype\u001b[49m\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], gal_data_high_otype\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], bin_data_high_otype\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], star_data_high_otype\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      2\u001b[0m equal_data_high_otype \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([agn_data_high_otype\u001b[38;5;241m.\u001b[39msample(n\u001b[38;5;241m=\u001b[39mn), gal_data_high_otype, bin_data_high_otype\u001b[38;5;241m.\u001b[39msample(n\u001b[38;5;241m=\u001b[39mn), star_data_high_otype\u001b[38;5;241m.\u001b[39msample(n\u001b[38;5;241m=\u001b[39mn)])\n\u001b[1;32m      3\u001b[0m equal_data_high_otype \u001b[38;5;241m=\u001b[39m equal_data_high_otype\u001b[38;5;241m.\u001b[39mdropna()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'agn_data_high_otype' is not defined"
     ]
    }
   ],
   "source": [
    "n = min(agn_data_high_otype.dropna().shape[0], gal_data_high_otype.dropna().shape[0], bin_data_high_otype.dropna().shape[0], star_data_high_otype.dropna().shape[0])\n",
    "equal_data_high_otype = pd.concat([agn_data_high_otype.sample(n=n), gal_data_high_otype, bin_data_high_otype.sample(n=n), star_data_high_otype.sample(n=n)])\n",
    "equal_data_high_otype = equal_data_high_otype.dropna()\n",
    "np.save(\"equal_data_high_otype\", equal_data_high_otype.to_numpy())\n",
    "print(equal_data_high_otype.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using all except galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(949731, 18)\n"
     ]
    }
   ],
   "source": [
    "n = min(agn_data_high_otype.dropna().shape[0], bin_data_high_otype.dropna().shape[0], star_data_high_otype.dropna().shape[0])\n",
    "no_gal_high_otype = pd.concat([agn_data_high_otype.dropna().sample(n=n), bin_data_high_otype.dropna().sample(n=n), star_data_high_otype.dropna().sample(n=n)])\n",
    "#equal_data_high_otype = equal_data_high_otype.dropna()\n",
    "np.save(\"no_gal_high_otype\",no_gal_high_otype.to_numpy())\n",
    "print(no_gal_high_otype.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_gal_high_otype = pd.concat([agn_data_high_otype, bin_data_high_otype, star_data_high_otype])\n",
    "no_gal_high_otype = no_gal_high_otype.dropna()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
