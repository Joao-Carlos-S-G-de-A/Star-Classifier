{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of AGN spectra: 35936\n",
      "Number of STAR spectra: 86037\n",
      "Number of BIN spectra: 40676\n",
      "Number of GAL spectra: 1699\n"
     ]
    }
   ],
   "source": [
    "# Specify the directory\n",
    "directory = 'lamost_train_set/agn_data'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "id_train_agn = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "# star directory\n",
    "directory = 'lamost_train_set/star_data'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "id_train_star = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "# binary directory\n",
    "directory = 'lamost_train_set/bin_data'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "id_train_bin = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "# galaxy directory\n",
    "directory = 'lamost_train_set/gal_data'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "id_train_gal = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "# print the number of files in each category\n",
    "print('Number of AGN spectra:', len(id_train_agn))\n",
    "print('Number of STAR spectra:', len(id_train_star))\n",
    "print('Number of BIN spectra:', len(id_train_bin))\n",
    "print('Number of GAL spectra:', len(id_train_gal))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of AGN spectra: 400\n",
      "Number of STAR spectra: 400\n",
      "Number of BIN spectra: 400\n",
      "Number of GAL spectra: 400\n"
     ]
    }
   ],
   "source": [
    "# Specify the directory\n",
    "directory = 'lamost_val_set/agn_data'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "id_val_agn = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "# star directory\n",
    "directory = 'lamost_val_set/star_data'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "id_val_star = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "# binary directory\n",
    "directory = 'lamost_val_set/bin_data'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "id_val_bin = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "# galaxy directory\n",
    "directory = 'lamost_val_set/gal_data'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "id_val_gal = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "# print the number of files in each category\n",
    "print('Number of AGN spectra:', len(id_val_agn))\n",
    "print('Number of STAR spectra:', len(id_val_star))\n",
    "print('Number of BIN spectra:', len(id_val_bin))\n",
    "print('Number of GAL spectra:', len(id_val_gal))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: had to do it twice; val and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamost_catalog = pd.read_csv(\"dr9_v2.0_LRS_catalogue.csv\")  # Assuming CSV format for LAMOST catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting of with Gal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  ra        dec\n",
      "1838      333.865510   0.776690\n",
      "113126    138.383021  31.957768\n",
      "237337     42.455140  -0.324820\n",
      "285166    175.558822  28.841412\n",
      "288652     20.021740  -0.404700\n",
      "...              ...        ...\n",
      "10491764  246.803116  29.998576\n",
      "10567385  117.924140  53.057106\n",
      "10595660  227.251731  31.032884\n",
      "10669548  115.395570  23.501689\n",
      "10681656  189.348344  55.694221\n",
      "\n",
      "[400 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "obsid_list = id_val_gal\n",
    "\n",
    "\n",
    "\n",
    "obsid_list = [int(obsid) for obsid in obsid_list]\n",
    "\n",
    "# Filter the DataFrame\n",
    "filtered_df = lamost_catalog[lamost_catalog['obsid'].isin(obsid_list)]\n",
    "\n",
    "# Get the 'ra' and 'dec' values\n",
    "ra_dec_values = filtered_df[['ra', 'dec']]\n",
    "print(ra_dec_values)\n",
    "\n",
    "################################################################################################################\n",
    "\n",
    "# Load your GAL data and LAMOST catalog (assuming you have a local CSV or FITS file for LAMOST)\n",
    "gal_data = pd.read_pickle(\"Pickles/gal_data.pkl\")  # Loaded GAL data\n",
    "\n",
    "# Ensure that RA and Dec columns are numeric and have units\n",
    "gal_data['ra'] = pd.to_numeric(gal_data['ra'], errors='coerce')  # Coerce non-numeric to NaN\n",
    "gal_data['dec'] = pd.to_numeric(gal_data['dec'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in 'ra' and 'dec' columns\n",
    "gal_data = gal_data.dropna(subset=['ra', 'dec'])\n",
    "ra_dec_values = filtered_df[['obsid','ra', 'dec']]\n",
    "\n",
    "# Convert GAL and LAMOST data to SkyCoord objects for crossmatching\n",
    "gal_coords = SkyCoord(ra=gal_data['ra'].values*u.deg, dec=gal_data['dec'].values*u.deg)\n",
    "lamost_coords = SkyCoord(ra=ra_dec_values['ra'].values*u.deg, dec=ra_dec_values['dec'].values*u.deg)\n",
    "\n",
    "# Crossmatch the GAL and LAMOST data\n",
    "idx, d2d, _ = gal_coords.match_to_catalog_sky(lamost_coords)\n",
    "\n",
    "# Define a matching radius\n",
    "match_radius = 1 * u.arcsec\n",
    "matches = d2d < match_radius\n",
    "\n",
    "# Filter the matches\n",
    "matched_gal = gal_data.iloc[matches]\n",
    "matched_lamost = ra_dec_values.iloc[idx[matches]]\n",
    "\n",
    "# Combine the matched data\n",
    "matched_data = pd.concat([matched_gal.reset_index(drop=True), matched_lamost.reset_index(drop=True)], axis=1)\n",
    "\n",
    "#######################################################################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['obsid', 'ra', 'dec', 'ra_error', 'dec_error', 'parallax',\n",
      "       'parallax_error', 'pmra', 'pmra_error', 'pmdec', 'pmdec_error',\n",
      "       'phot_g_mean_flux', 'phot_g_mean_flux_error', 'phot_bp_mean_flux',\n",
      "       'phot_bp_mean_flux_error', 'phot_rp_mean_flux',\n",
      "       'phot_rp_mean_flux_error'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "gal_gaia = matched_data[['obsid','ra', 'dec','ra_error', 'dec_error', 'parallax', 'parallax_error', 'pmra', 'pmra_error', 'pmdec', 'pmdec_error', 'phot_g_mean_flux', 'phot_g_mean_flux_error', 'phot_bp_mean_flux', 'phot_bp_mean_flux_error', 'phot_rp_mean_flux', 'phot_rp_mean_flux_error']]\n",
    "gal_gaia.columns = ['obsid','ra','ra2', 'dec', 'dec2','ra_error', 'dec_error', 'parallax', 'parallax_error', 'pmra', 'pmra_error', 'pmdec', 'pmdec_error', 'phot_g_mean_flux', 'phot_g_mean_flux_error', 'phot_bp_mean_flux', 'phot_bp_mean_flux_error', 'phot_rp_mean_flux', 'phot_rp_mean_flux_error']\n",
    "gal_gaia = gal_gaia.drop(columns=['ra2', 'dec2'])\n",
    "print(gal_gaia.columns)\n",
    "\n",
    "# create a new folder for the pickles\n",
    "if not os.path.exists(\"Pickles/vcleaned\"):\n",
    "    os.makedirs(\"Pickles/vcleaned\")\n",
    "gal_gaia.to_pickle(\"Pickles/vcleaned/gal_gaia.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Doing the same for bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  ra        dec\n",
      "778       333.964749   0.302551\n",
      "1903      330.641667   1.239245\n",
      "1942      330.369258   0.786806\n",
      "9462       79.412996  30.833612\n",
      "9983      330.698645  28.929285\n",
      "...              ...        ...\n",
      "10686771  278.870280  11.083686\n",
      "10686845  277.704890  11.178101\n",
      "10686858  277.555770  11.421151\n",
      "10686863  277.662760  11.637670\n",
      "10686918  276.793290  11.188747\n",
      "\n",
      "[40676 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "obsid_list = id_train_bin\n",
    "obsid_list = [int(obsid) for obsid in obsid_list]\n",
    "\n",
    "\n",
    "# Filter the DataFrame\n",
    "filtered_df = lamost_catalog[lamost_catalog['obsid'].isin(obsid_list)]\n",
    "\n",
    "# Get the 'ra' and 'dec' values\n",
    "ra_dec_values = filtered_df[['ra', 'dec']]\n",
    "print(ra_dec_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your GAL data and LAMOST catalog (assuming you have a local CSV or FITS file for LAMOST)\n",
    "bin_data = pd.read_pickle(\"Pickles/bin_data.pkl\")  # Loaded BIN data\n",
    "\n",
    "# Ensure that RA and Dec columns are numeric and have units\n",
    "bin_data['ra'] = pd.to_numeric(bin_data['ra'], errors='coerce')  # Coerce non-numeric to NaN\n",
    "bin_data['dec'] = pd.to_numeric(bin_data['dec'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in 'ra' and 'dec' columns\n",
    "bin_data = bin_data.dropna(subset=['ra', 'dec'])\n",
    "ra_dec_values = filtered_df[['obsid','ra', 'dec']]\n",
    "# Convert GAL and LAMOST data to SkyCoord objects for crossmatching\n",
    "bin_coords = SkyCoord(ra=bin_data['ra'].values*u.deg, dec=bin_data['dec'].values*u.deg)\n",
    "lamost_coords = SkyCoord(ra=ra_dec_values['ra'].values*u.deg, dec=ra_dec_values['dec'].values*u.deg)\n",
    "\n",
    "# Crossmatch the GAL and LAMOST data\n",
    "idx, d2d, _ = bin_coords.match_to_catalog_sky(lamost_coords)\n",
    "\n",
    "# Define a matching radius\n",
    "match_radius = 1 * u.arcsec\n",
    "matches = d2d < match_radius\n",
    "\n",
    "# Filter the matches\n",
    "matched_bin = bin_data.iloc[matches]\n",
    "matched_lamost = ra_dec_values.iloc[idx[matches]]\n",
    "\n",
    "# Combine the matched data\n",
    "matched_data = pd.concat([matched_bin.reset_index(drop=True), matched_lamost.reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['obsid', 'ra', 'dec', 'ra_error', 'dec_error', 'parallax',\n",
      "       'parallax_error', 'pmra', 'pmra_error', 'pmdec', 'pmdec_error',\n",
      "       'phot_g_mean_flux', 'phot_g_mean_flux_error', 'phot_bp_mean_flux',\n",
      "       'phot_bp_mean_flux_error', 'phot_rp_mean_flux',\n",
      "       'phot_rp_mean_flux_error'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "bin_gaia = matched_data[['obsid','ra', 'dec','ra_error', 'dec_error', 'parallax', 'parallax_error', 'pmra', 'pmra_error', 'pmdec', 'pmdec_error', 'phot_g_mean_flux', 'phot_g_mean_flux_error', 'phot_bp_mean_flux', 'phot_bp_mean_flux_error', 'phot_rp_mean_flux', 'phot_rp_mean_flux_error']]\n",
    "bin_gaia.columns = ['obsid','ra','ra2', 'dec', 'dec2','ra_error', 'dec_error', 'parallax', 'parallax_error', 'pmra', 'pmra_error', 'pmdec', 'pmdec_error', 'phot_g_mean_flux', 'phot_g_mean_flux_error', 'phot_bp_mean_flux', 'phot_bp_mean_flux_error', 'phot_rp_mean_flux', 'phot_rp_mean_flux_error']\n",
    "bin_gaia = bin_gaia.drop(columns=['ra2', 'dec2'])\n",
    "print(bin_gaia.columns)\n",
    "\n",
    "# create a new folder for the pickles\n",
    "if not os.path.exists(\"Pickles/tcleaned\"):\n",
    "    os.makedirs(\"Pickles/tcleaned\")\n",
    "bin_gaia.to_pickle(\"Pickles/tcleaned/bin_gaia.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing the same for Stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  ra        dec\n",
      "99        332.098588  -1.259508\n",
      "135       332.087160  -2.039786\n",
      "435       331.310760   0.145980\n",
      "452       331.312840   0.914318\n",
      "499       332.425814   0.696325\n",
      "...              ...        ...\n",
      "10686847  277.463350  11.244976\n",
      "10686850  277.426030  11.074758\n",
      "10686879  276.872710  11.871802\n",
      "10686896  277.306960  11.241274\n",
      "10686899  277.242780  11.204973\n",
      "\n",
      "[86037 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "obsid_list = id_train_star\n",
    "obsid_list = [int(obsid) for obsid in obsid_list]\n",
    "\n",
    "# Filter the DataFrame\n",
    "filtered_df = lamost_catalog[lamost_catalog['obsid'].isin(obsid_list)]\n",
    "\n",
    "# Get the 'ra' and 'dec' values\n",
    "ra_dec_values = filtered_df[['ra', 'dec']]\n",
    "print(ra_dec_values)    \n",
    "\n",
    "# Load your GAL data and LAMOST catalog (assuming you have a local CSV or FITS file for LAMOST)\n",
    "star_data = pd.read_pickle(\"Pickles/star_data.pkl\")  # Loaded STAR data\n",
    "\n",
    "# Ensure that RA and Dec columns are numeric and have units\n",
    "star_data['ra'] = pd.to_numeric(star_data['ra'], errors='coerce')  # Coerce non-numeric to NaN\n",
    "star_data['dec'] = pd.to_numeric(star_data['dec'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in 'ra' and 'dec' columns\n",
    "star_data = star_data.dropna(subset=['ra', 'dec'])\n",
    "ra_dec_values = filtered_df[['obsid','ra', 'dec']]\n",
    "\n",
    "# Convert GAL and LAMOST data to SkyCoord objects for crossmatching\n",
    "star_coords = SkyCoord(ra=star_data['ra'].values*u.deg, dec=star_data['dec'].values*u.deg)\n",
    "lamost_coords = SkyCoord(ra=ra_dec_values['ra'].values*u.deg, dec=ra_dec_values['dec'].values*u.deg)\n",
    "\n",
    "# Crossmatch the GAL and LAMOST data\n",
    "idx, d2d, _ = star_coords.match_to_catalog_sky(lamost_coords)\n",
    "\n",
    "# Define a matching radius\n",
    "match_radius = 1 * u.arcsec\n",
    "matches = d2d < match_radius\n",
    "\n",
    "# Filter the matches\n",
    "matched_star = star_data.iloc[matches]\n",
    "matched_lamost = ra_dec_values.iloc[idx[matches]]\n",
    "\n",
    "# Combine the matched data\n",
    "matched_data = pd.concat([matched_star.reset_index(drop=True), matched_lamost.reset_index(drop=True)], axis=1)\n",
    "\n",
    "######################################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['obsid', 'ra', 'dec', 'ra_error', 'dec_error', 'parallax',\n",
      "       'parallax_error', 'pmra', 'pmra_error', 'pmdec', 'pmdec_error',\n",
      "       'phot_g_mean_flux', 'phot_g_mean_flux_error', 'phot_bp_mean_flux',\n",
      "       'phot_bp_mean_flux_error', 'phot_rp_mean_flux',\n",
      "       'phot_rp_mean_flux_error'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "star_data = matched_data[['obsid','ra', 'dec','ra_error', 'dec_error', 'parallax', 'parallax_error', 'pmra', 'pmra_error', 'pmdec', 'pmdec_error', 'phot_g_mean_flux', 'phot_g_mean_flux_error', 'phot_bp_mean_flux', 'phot_bp_mean_flux_error', 'phot_rp_mean_flux', 'phot_rp_mean_flux_error']]\n",
    "star_data.columns = ['obsid','ra','ra2', 'dec', 'dec2','ra_error', 'dec_error', 'parallax', 'parallax_error', 'pmra', 'pmra_error', 'pmdec', 'pmdec_error', 'phot_g_mean_flux', 'phot_g_mean_flux_error', 'phot_bp_mean_flux', 'phot_bp_mean_flux_error', 'phot_rp_mean_flux', 'phot_rp_mean_flux_error']\n",
    "star_data = star_data.drop(columns=['ra2', 'dec2'])\n",
    "print(star_data.columns)\n",
    "\n",
    "# create a new folder for the pickles\n",
    "if not os.path.exists(\"Pickles/vcleaned\"):\n",
    "    os.makedirs(\"Pickles/vcleaned\")\n",
    "star_data.to_pickle(\"Pickles/tcleaned/star_gaia.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing the same for AGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  ra        dec\n",
      "279       330.366460  -0.800640\n",
      "3899       43.798310   0.049600\n",
      "176584    163.459516  28.013092\n",
      "247848     25.947470   2.692070\n",
      "262363     44.136010   5.782250\n",
      "...              ...        ...\n",
      "10594670  225.100220  31.664313\n",
      "10608168  351.991470  -0.349688\n",
      "10614698  345.211320  33.541183\n",
      "10626703  332.806910  21.561966\n",
      "10669837  136.487280  12.533718\n",
      "\n",
      "[400 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "obsid_list = id_val_agn\n",
    "obsid_list = [int(obsid) for obsid in obsid_list]\n",
    "\n",
    "# Filter the DataFrame\n",
    "filtered_df = lamost_catalog[lamost_catalog['obsid'].isin(obsid_list)]\n",
    "\n",
    "# Get the 'ra' and 'dec' values\n",
    "ra_dec_values = filtered_df[['ra', 'dec']]\n",
    "print(ra_dec_values)    \n",
    "\n",
    "# Load your GAL data and LAMOST catalog (assuming you have a local CSV or FITS file for LAMOST)\n",
    "df = pd.read_pickle(\"Pickles/agn_data.pkl\")  # Loaded AGN data\n",
    "\n",
    "# Ensure that RA and Dec columns are numeric and have units\n",
    "df['ra'] = pd.to_numeric(df['ra'], errors='coerce')  # Coerce non-numeric to NaN\n",
    "df['dec'] = pd.to_numeric(df['dec'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in 'ra' and 'dec' columns\n",
    "df = df.dropna(subset=['ra', 'dec'])\n",
    "ra_dec_values = filtered_df[['obsid','ra', 'dec']]\n",
    "\n",
    "# Convert GAL and LAMOST data to SkyCoord objects for crossmatching\n",
    "agn_coords = SkyCoord(ra=df['ra'].values*u.deg, dec=df['dec'].values*u.deg)\n",
    "lamost_coords = SkyCoord(ra=ra_dec_values['ra'].values*u.deg, dec=ra_dec_values['dec'].values*u.deg)\n",
    "\n",
    "# Crossmatch the GAL and LAMOST data\n",
    "idx, d2d, _ = agn_coords.match_to_catalog_sky(lamost_coords)\n",
    "\n",
    "# Define a matching radius\n",
    "match_radius = 1 * u.arcsec\n",
    "matches = d2d < match_radius\n",
    "\n",
    "# Filter the matches\n",
    "matched_agn = df.iloc[matches]\n",
    "matched_lamost = ra_dec_values.iloc[idx[matches]]\n",
    "\n",
    "# Combine the matched data\n",
    "matched_data = pd.concat([matched_agn.reset_index(drop=True), matched_lamost.reset_index(drop=True)], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['obsid', 'ra', 'dec', 'ra_error', 'dec_error', 'parallax',\n",
      "       'parallax_error', 'pmra', 'pmra_error', 'pmdec', 'pmdec_error',\n",
      "       'phot_g_mean_flux', 'phot_g_mean_flux_error', 'phot_bp_mean_flux',\n",
      "       'phot_bp_mean_flux_error', 'phot_rp_mean_flux',\n",
      "       'phot_rp_mean_flux_error'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df = matched_data[['obsid','ra', 'dec','ra_error', 'dec_error', 'parallax', 'parallax_error', 'pmra', 'pmra_error', 'pmdec', 'pmdec_error', 'phot_g_mean_flux', 'phot_g_mean_flux_error', 'phot_bp_mean_flux', 'phot_bp_mean_flux_error', 'phot_rp_mean_flux', 'phot_rp_mean_flux_error']]\n",
    "df.columns = ['obsid','ra','ra2', 'dec', 'dec2','ra_error', 'dec_error', 'parallax', 'parallax_error', 'pmra', 'pmra_error', 'pmdec', 'pmdec_error', 'phot_g_mean_flux', 'phot_g_mean_flux_error', 'phot_bp_mean_flux', 'phot_bp_mean_flux_error', 'phot_rp_mean_flux', 'phot_rp_mean_flux_error']\n",
    "df = df.drop(columns=['ra2', 'dec2'])\n",
    "print(df.columns)\n",
    "\n",
    "df.to_pickle(\"Pickles/vcleaned/agn_gaia.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows now: 400\n",
      "Number of rows dropped: 0 accounting for 0.0 %\n",
      "Number of rows now: 399\n",
      "Number of rows dropped: 1 accounting for 0.25 %\n",
      "Number of rows now: 400\n",
      "Number of rows dropped: 0 accounting for 0.0 %\n",
      "Number of rows now: 399\n",
      "Number of rows dropped: 1 accounting for 0.25 %\n",
      "Number of rows now: 35931\n",
      "Number of rows dropped: 5 accounting for 0.013913624220837043 %\n",
      "Number of rows now: 40608\n",
      "Number of rows dropped: 71 accounting for 0.1745372305120578 %\n",
      "Number of rows now: 85928\n",
      "Number of rows dropped: 157 accounting for 0.1823778823256084 %\n",
      "Number of rows now: 1698\n",
      "Number of rows dropped: 1 accounting for 0.05885815185403178 %\n"
     ]
    }
   ],
   "source": [
    "def clean_nans(input_pkl, output_pkl):    \n",
    "    # open the pickles\n",
    "    df = pd.read_pickle(input_pkl)\n",
    "\n",
    "    # add a flag column if parallax is nan\n",
    "    df['flagnopllx'] = np.where(df['parallax'].isnull(), 1, 0)\n",
    "\n",
    "    # if parallax is nan, set the parallax to 0 and the error to 10\n",
    "    # 10 is a large value but still normalizabe\n",
    "\n",
    "    df.fillna({'parallax':0}, inplace=True)\n",
    "    df.fillna({'parallax_error':10}, inplace=True)\n",
    "\n",
    "    # if pmra or pmdec is nan, set the pmra to 0 and the error to 10\n",
    "\n",
    "    df.fillna({'pmra':0}, inplace=True)\n",
    "    df.fillna({'pmra_error':10}, inplace=True)\n",
    "    df.fillna({'pmdec':0}, inplace=True)\n",
    "    df.fillna({'pmdec_error':10}, inplace=True)\n",
    "\n",
    "    # if any nans are left, drop the row, save the obsid of dropped row,print the number of rows dropped out of the total\n",
    "    na_free = df.dropna()\n",
    "    only_na = df[~df.index.isin(na_free.index)]    \n",
    "    print('Number of rows now:', len(na_free))\n",
    "    print('Number of rows dropped:', len(df) - len(na_free), 'accounting for', ((len(df)-len(na_free))/len(df))*100, '%')\n",
    "\n",
    "    # save the pickle\n",
    "    df.to_pickle(output_pkl)\n",
    "    return only_na['obsid']\n",
    "\n",
    "obsid_drop_vagn = clean_nans(\"Pickles/vcleaned/agn_gaia.pkl\", \"Pickles/vcleaned2/agn_gaia.pkl\")\n",
    "obsid_drop_vbin = clean_nans(\"Pickles/vcleaned/bin_gaia.pkl\", \"Pickles/vcleaned2/bin_gaia.pkl\")\n",
    "obsid_drop_vstar = clean_nans(\"Pickles/vcleaned/star_gaia.pkl\", \"Pickles/vcleaned2/star_gaia.pkl\")\n",
    "obsid_drop_vgal = clean_nans(\"Pickles/vcleaned/gal_gaia.pkl\", \"Pickles/vcleaned2/gal_gaia.pkl\")\n",
    "obsid_drop_tagn = clean_nans(\"Pickles/tcleaned/agn_gaia.pkl\", \"Pickles/tcleaned2/agn_gaia.pkl\")\n",
    "obsid_drop_tbin = clean_nans(\"Pickles/tcleaned/bin_gaia.pkl\", \"Pickles/tcleaned2/bin_gaia.pkl\")\n",
    "obsid_drop_tstar = clean_nans(\"Pickles/tcleaned/star_gaia.pkl\", \"Pickles/tcleaned2/star_gaia.pkl\")\n",
    "obsid_drop_tgal = clean_nans(\"Pickles/tcleaned/gal_gaia.pkl\", \"Pickles/tcleaned2/gal_gaia.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the obsid of the dropped rows\n",
    "obsid_drop = pd.concat([obsid_drop_vagn, obsid_drop_vbin, obsid_drop_vstar, obsid_drop_vgal, obsid_drop_tagn, obsid_drop_tbin, obsid_drop_tstar, obsid_drop_tgal])\n",
    "obsid_drop.to_pickle(\"Pickles/drops/gaiaall.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note, drops are from lack of photometric data to bp and rp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove from gaia data the lamost nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before: 400 Number of rows dropped: 0 accounting for 0.0 %\n",
      "Number of rows dropped due to LAMOST: 0 accounting for 0.0 %\n",
      "Number of rows now: 400\n",
      "Number of rows before: 399 Number of rows dropped: 1 accounting for 0.25 %\n",
      "Number of rows dropped due to LAMOST: 0 accounting for 0.0 %\n",
      "Number of rows now: 399\n",
      "Number of rows before: 400 Number of rows dropped: 0 accounting for 0.0 %\n",
      "Number of rows dropped due to LAMOST: 0 accounting for 0.0 %\n",
      "Number of rows now: 400\n",
      "Number of rows before: 399 Number of rows dropped: 1 accounting for 0.25 %\n",
      "Number of rows dropped due to LAMOST: 0 accounting for 0.0 %\n",
      "Number of rows now: 399\n",
      "Number of rows before: 35931 Number of rows dropped: 5 accounting for 0.013913624220837043 %\n",
      "Number of rows dropped due to LAMOST: 125 accounting for 0.3478890094904122 %\n",
      "Number of rows now: 35806\n",
      "Number of rows before: 40608 Number of rows dropped: 71 accounting for 0.1745372305120578 %\n",
      "Number of rows dropped due to LAMOST: 122 accounting for 0.3004334121355398 %\n",
      "Number of rows now: 40486\n",
      "Number of rows before: 85928 Number of rows dropped: 157 accounting for 0.1823778823256084 %\n",
      "Number of rows dropped due to LAMOST: 2873 accounting for 3.3434968811097665 %\n",
      "Number of rows now: 83055\n",
      "Number of rows before: 1698 Number of rows dropped: 1 accounting for 0.05885815185403178 %\n",
      "Number of rows dropped due to LAMOST: 78 accounting for 4.593639575971731 %\n",
      "Number of rows now: 1620\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def clean_nans(input_pkl, output_pkl, lmst_drop):    \n",
    "    # open the pickles\n",
    "    df = pd.read_pickle(input_pkl)\n",
    "\n",
    "    # add a flag column if parallax is nan\n",
    "    df['flagnopllx'] = np.where(df['parallax'].isnull(), 1, 0)\n",
    "\n",
    "    # if parallax is nan, set the parallax to 0 and the error to 10\n",
    "    df.fillna({'parallax': 0, 'parallax_error': 10}, inplace=True)\n",
    "\n",
    "    # if pmra or pmdec is nan, set the pmra to 0 and the error to 10\n",
    "    df.fillna({'pmra': 0, 'pmra_error': 10, 'pmdec': 0, 'pmdec_error': 10}, inplace=True)\n",
    "\n",
    "    # if any nans are left, drop the row, save the obsid of dropped row, print the number of rows dropped out of the total\n",
    "    na_free = df.dropna()\n",
    "    only_na = df[~df.index.isin(na_free.index)]    \n",
    "    print('Number of rows before:', len(na_free),'Number of rows dropped:', len(df) - len(na_free), 'accounting for', ((len(df)-len(na_free))/len(df))*100, '%')\n",
    "\n",
    "    # Drop rows where obsid is in lmst_drop\n",
    "    df = na_free[~na_free['obsid'].isin(lmst_drop)]\n",
    "    print('Number of rows dropped due to LAMOST:', len(na_free) - len(df), 'accounting for', ((len(na_free)-len(df))/len(na_free))*100, '%')\n",
    "    print('Number of rows now:', len(df))\n",
    "    # save the pickle\n",
    "    df.to_pickle(output_pkl)\n",
    "    return only_na['obsid']\n",
    "\n",
    "# Load the list of obsid to drop\n",
    "lmst_drop = pd.read_pickle('Pickles/drops/lamost.pkl')\n",
    "\n",
    "# Apply the function to each file\n",
    "obsid_drop_vagn = clean_nans(\"Pickles/vcleaned/agn_gaia.pkl\", \"Pickles/vcleaned3/agn_gaia.pkl\", lmst_drop)\n",
    "obsid_drop_vbin = clean_nans(\"Pickles/vcleaned/bin_gaia.pkl\", \"Pickles/vcleaned3/bin_gaia.pkl\", lmst_drop)\n",
    "obsid_drop_vstar = clean_nans(\"Pickles/vcleaned/star_gaia.pkl\", \"Pickles/vcleaned3/star_gaia.pkl\", lmst_drop)\n",
    "obsid_drop_vgal = clean_nans(\"Pickles/vcleaned/gal_gaia.pkl\", \"Pickles/vcleaned3/gal_gaia.pkl\", lmst_drop)\n",
    "obsid_drop_tagn = clean_nans(\"Pickles/tcleaned/agn_gaia.pkl\", \"Pickles/tcleaned3/agn_gaia.pkl\", lmst_drop)\n",
    "obsid_drop_tbin = clean_nans(\"Pickles/tcleaned/bin_gaia.pkl\", \"Pickles/tcleaned3/bin_gaia.pkl\", lmst_drop)\n",
    "obsid_drop_tstar = clean_nans(\"Pickles/tcleaned/star_gaia.pkl\", \"Pickles/tcleaned3/star_gaia.pkl\", lmst_drop)\n",
    "obsid_drop_tgal = clean_nans(\"Pickles/tcleaned/gal_gaia.pkl\", \"Pickles/tcleaned3/gal_gaia.pkl\", lmst_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
