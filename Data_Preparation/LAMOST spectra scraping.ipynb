{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from astroquery.gaia import Gaia\n",
    "from astroquery.simbad import Simbad\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "import numpy as np\n",
    "import pyvo as vo\n",
    "import pickle\n",
    "from astroquery.vizier import Vizier\n",
    "import concurrent.futures\n",
    "import requests\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the main functions to download the spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download a file with retries\n",
    "def download_file(url):\n",
    "    file_name = os.path.join(save_folder, url.split('/')[-1])\n",
    "    \n",
    "    # If the file already exists, return success\n",
    "    if os.path.exists(file_name):\n",
    "        return True, file_name\n",
    "    \n",
    "    # Retry mechanism\n",
    "    retries = Retry(total=5, backoff_factor=1, status_forcelist=[429, 500, 502, 503, 504])\n",
    "    session = requests.Session()\n",
    "    session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "    try:\n",
    "        response = session.get(url)\n",
    "        response.raise_for_status()  # Check for HTTP errors\n",
    "        \n",
    "        # Save the file content\n",
    "        with open(file_name, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        \n",
    "        return True, file_name  # Success\n",
    "    except requests.HTTPError as e:\n",
    "        return False, f\"Failed to download {url}: {e}\"  # Failure\n",
    "    except Exception as e:\n",
    "        return False, f\"Other error occurred: {e}\"\n",
    "\n",
    "# Main function to download all files\n",
    "def download_all_files(urls):\n",
    "    success_count = 0\n",
    "    failure_count = 0\n",
    "\n",
    "    # Reduce the number of threads to avoid overwhelming the network\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=300) as executor:\n",
    "        # Create a progress bar with the total number of URLs\n",
    "        with tqdm(total=len(urls), desc=\"Downloading\", unit=\"file\") as pbar:\n",
    "            futures = {executor.submit(download_file, url): url for url in urls}\n",
    "            \n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                success, result = future.result()\n",
    "                pbar.update(1)  # Update the progress bar for each completed download\n",
    "                \n",
    "                if success:\n",
    "                    success_count += 1\n",
    "                else:\n",
    "                    failure_count += 1\n",
    "                    #print(f\"Error: {result}\")\n",
    "\n",
    "    # Print final counts for successful and failed downloads\n",
    "    print(f\"\\nDownload complete! Successfully downloaded: {success_count}, Failed: {failure_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying function to non-AGN Galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 2533\n",
      "out of  33531\n"
     ]
    }
   ],
   "source": [
    "# Load your GAL data and LAMOST catalog (assuming you have a local CSV or FITS file for LAMOST)\n",
    "gal_data = pd.read_pickle(\"gal_data.pkl\")  # Loaded GAL data\n",
    "lamost_catalog = pd.read_csv(\"dr9_v2.0_LRS_catalogue.csv\")  # Assuming CSV format for LAMOST catalog\n",
    "\n",
    "# Ensure that RA and Dec columns are numeric and have units\n",
    "gal_data['ra'] = pd.to_numeric(gal_data['ra'], errors='coerce')  # Coerce non-numeric to NaN\n",
    "gal_data['dec'] = pd.to_numeric(gal_data['dec'], errors='coerce')\n",
    "lamost_catalog['ra'] = pd.to_numeric(lamost_catalog['ra'], errors='coerce')\n",
    "lamost_catalog['dec'] = pd.to_numeric(lamost_catalog['dec'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in RA or Dec\n",
    "gal_data = gal_data.dropna(subset=['ra', 'dec'])\n",
    "lamost_catalog = lamost_catalog.dropna(subset=['ra', 'dec'])\n",
    "\n",
    "# Convert GAL and LAMOST data to SkyCoord objects for crossmatching\n",
    "gal_coords = SkyCoord(ra=gal_data['ra'].values*u.deg, dec=gal_data['dec'].values*u.deg)\n",
    "lamost_coords = SkyCoord(ra=lamost_catalog['ra'].values*u.deg, dec=lamost_catalog['dec'].values*u.deg)\n",
    "\n",
    "# Perform the crossmatch using astropy's match_to_catalog_sky function\n",
    "idx, d2d, _ = gal_coords.match_to_catalog_sky(lamost_coords)\n",
    "\n",
    "# Define a matching radius\n",
    "match_radius = 1 * u.arcsec\n",
    "matches = d2d < match_radius\n",
    "\n",
    "# Filter the matches\n",
    "matched_gal = gal_data.iloc[matches]\n",
    "matched_lamost = lamost_catalog.iloc[idx[matches]]\n",
    "\n",
    "# Combine matched data\n",
    "gal_lamost_data = pd.concat([matched_gal.reset_index(drop=True), matched_lamost.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Save the crossmatched data\n",
    "gal_lamost_data.to_pickle(\"gal_lamost_data.pkl\")\n",
    "\n",
    "print(f\"Number of matches: {gal_lamost_data.shape[0]}\")\n",
    "print(\"out of \", gal_data.shape[0])\n",
    "del gal_data, lamost_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 2533/2533 [01:21<00:00, 31.17file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Download complete! Successfully downloaded: 2099, Failed: 434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the crossmatched data\n",
    "gal_lamost_data = pd.read_pickle(\"gal_lamost_data.pkl\")\n",
    "obsid_list = gal_lamost_data['obsid'].values\n",
    "\n",
    "# Specify the folder to save the files\n",
    "save_folder = \"gal_spectra\"\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "# List of URLs to download (assuming obsid_list is available)\n",
    "urls = [f\"https://www.lamost.org/dr7/v2.0/spectrum/fits/{obsid}\" for obsid in obsid_list]\n",
    "\n",
    "# Call the function to start downloading\n",
    "download_all_files(urls)\n",
    "\n",
    "# Free up memory by deleting the large DataFrame\n",
    "del gal_lamost_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying function to Binaries data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 45070\n",
      "out of  1700440\n"
     ]
    }
   ],
   "source": [
    "# Load your BIN data and LAMOST catalog (assuming you have a local CSV or FITS file for LAMOST)\n",
    "bin_data = pd.read_pickle(\"bin_data.pkl\")  # Loaded BIN data\n",
    "lamost_catalog = pd.read_csv(\"dr9_v2.0_LRS_catalogue.csv\")  # Assuming CSV format for LAMOST catalog\n",
    "\n",
    "# Ensure that RA and Dec columns are numeric and have units\n",
    "bin_data['ra'] = pd.to_numeric(bin_data['ra'], errors='coerce')  # Coerce non-numeric to NaN\n",
    "bin_data['dec'] = pd.to_numeric(bin_data['dec'], errors='coerce')   \n",
    "lamost_catalog['ra'] = pd.to_numeric(lamost_catalog['ra'], errors='coerce')\n",
    "lamost_catalog['dec'] = pd.to_numeric(lamost_catalog['dec'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in RA or Dec\n",
    "bin_data = bin_data.dropna(subset=['ra', 'dec'])\n",
    "lamost_catalog = lamost_catalog.dropna(subset=['ra', 'dec'])\n",
    "\n",
    "# Convert BIN and LAMOST data to SkyCoord objects for crossmatching\n",
    "bin_coords = SkyCoord(ra=bin_data['ra'].values*u.deg, dec=bin_data['dec'].values*u.deg)\n",
    "lamost_coords = SkyCoord(ra=lamost_catalog['ra'].values*u.deg, dec=lamost_catalog['dec'].values*u.deg)\n",
    "\n",
    "# Perform the crossmatch using astropy's match_to_catalog_sky function\n",
    "idx, d2d, _ = bin_coords.match_to_catalog_sky(lamost_coords)\n",
    "\n",
    "# Define a matching radius\n",
    "match_radius = 1 * u.arcsec\n",
    "matches = d2d < match_radius\n",
    "\n",
    "# Filter the matches\n",
    "matched_bin = bin_data.iloc[matches]\n",
    "matched_lamost = lamost_catalog.iloc[idx[matches]]\n",
    "\n",
    "# Combine matched data\n",
    "bin_lamost_data = pd.concat([matched_bin.reset_index(drop=True), matched_lamost.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Save the crossmatched data\n",
    "bin_lamost_data.to_pickle(\"bin_lamost_data.pkl\")\n",
    "\n",
    "print(f\"Number of matches: {bin_lamost_data.shape[0]}\")\n",
    "print(\"out of \", bin_data.shape[0])\n",
    "del bin_data, lamost_catalog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 45070/45070 [07:49<00:00, 96.03file/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Download complete! Successfully downloaded: 41079, Failed: 3991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the crossmatched data\n",
    "bin_lamost_data = pd.read_pickle(\"bin_lamost_data.pkl\")\n",
    "obsid_list = bin_lamost_data['obsid'].values\n",
    "\n",
    "# Specify the folder to save the files\n",
    "save_folder = \"bin_spectra\"\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "# List of URLs to download (assuming obsid_list is available)\n",
    "urls = [f\"https://www.lamost.org/dr7/v2.0/spectrum/fits/{obsid}\" for obsid in obsid_list]\n",
    "\n",
    "# Call the function to start downloading\n",
    "download_all_files(urls)\n",
    "\n",
    "# Free up memory by deleting the large DataFrame\n",
    "del bin_lamost_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying function to Star data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 94651\n",
      "out of  1499508\n"
     ]
    }
   ],
   "source": [
    "# Load your STAR data and LAMOST catalog (assuming you have a local CSV or FITS file for LAMOST)\n",
    "star_data = pd.read_pickle(\"star_data.pkl\")  # Loaded STAR data\n",
    "lamost_catalog = pd.read_csv(\"dr9_v2.0_LRS_catalogue.csv\")  # Assuming CSV format for LAMOST catalog\n",
    "\n",
    "# Ensure that RA and Dec columns are numeric and have units\n",
    "star_data['ra'] = pd.to_numeric(star_data['ra'], errors='coerce')  # Coerce non-numeric to NaN\n",
    "star_data['dec'] = pd.to_numeric(star_data['dec'], errors='coerce')\n",
    "lamost_catalog['ra'] = pd.to_numeric(lamost_catalog['ra'], errors='coerce')\n",
    "lamost_catalog['dec'] = pd.to_numeric(lamost_catalog['dec'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in RA or Dec\n",
    "star_data = star_data.dropna(subset=['ra', 'dec'])\n",
    "lamost_catalog = lamost_catalog.dropna(subset=['ra', 'dec'])\n",
    "\n",
    "# Convert STAR and LAMOST data to SkyCoord objects for crossmatching\n",
    "star_coords = SkyCoord(ra=star_data['ra'].values*u.deg, dec=star_data['dec'].values*u.deg)\n",
    "lamost_coords = SkyCoord(ra=lamost_catalog['ra'].values*u.deg, dec=lamost_catalog['dec'].values*u.deg)\n",
    "\n",
    "# Perform the crossmatch using astropy's match_to_catalog_sky function\n",
    "idx, d2d, _ = star_coords.match_to_catalog_sky(lamost_coords)\n",
    "\n",
    "# Define a matching radius\n",
    "match_radius = 1 * u.arcsec\n",
    "matches = d2d < match_radius\n",
    "\n",
    "# Filter the matches\n",
    "matched_star = star_data.iloc[matches]\n",
    "matched_lamost = lamost_catalog.iloc[idx[matches]]\n",
    "\n",
    "# Combine matched data\n",
    "star_lamost_data = pd.concat([matched_star.reset_index(drop=True), matched_lamost.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Save the crossmatched data\n",
    "star_lamost_data.to_pickle(\"star_lamost_data.pkl\")\n",
    "\n",
    "print(f\"Number of matches: {star_lamost_data.shape[0]}\")\n",
    "print(\"out of \", star_data.shape[0])\n",
    "del star_data, lamost_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 94651/94651 [07:30<00:00, 209.87file/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Download complete! Successfully downloaded: 86484, Failed: 8167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the crossmatched data\n",
    "star_lamost_data = pd.read_pickle(\"star_lamost_data.pkl\")\n",
    "obsid_list = star_lamost_data['obsid'].values\n",
    "\n",
    "# Specify the folder to save the files\n",
    "save_folder = \"star_spectra\"\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "# List of URLs to download (assuming obsid_list is available)\n",
    "urls = [f\"https://www.lamost.org/dr7/v2.0/spectrum/fits/{obsid}\" for obsid in obsid_list]\n",
    "\n",
    "# Call the function to start downloading\n",
    "download_all_files(urls)\n",
    "\n",
    "# Free up memory by deleting the large DataFrame\n",
    "del star_lamost_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying function to AGN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 40138\n",
      "out of  412025\n"
     ]
    }
   ],
   "source": [
    "# Load your AGN data and LAMOST catalog (assuming you have a local CSV or FITS file for LAMOST)\n",
    "agn_data = pd.read_pickle(\"agn_data.pkl\")  # Loaded AGN data\n",
    "lamost_catalog = pd.read_csv(\"dr9_v2.0_LRS_catalogue.csv\")  # Assuming CSV format for LAMOST catalog\n",
    "\n",
    "# Ensure that RA and Dec columns are numeric and have units\n",
    "agn_data['ra'] = pd.to_numeric(agn_data['ra'], errors='coerce')  # Coerce non-numeric to NaN\n",
    "agn_data['dec'] = pd.to_numeric(agn_data['dec'], errors='coerce')\n",
    "lamost_catalog['ra'] = pd.to_numeric(lamost_catalog['ra'], errors='coerce')\n",
    "lamost_catalog['dec'] = pd.to_numeric(lamost_catalog['dec'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in RA or Dec\n",
    "agn_data = agn_data.dropna(subset=['ra', 'dec'])\n",
    "lamost_catalog = lamost_catalog.dropna(subset=['ra', 'dec'])\n",
    "\n",
    "# Convert AGN and LAMOST data to SkyCoord objects for crossmatching\n",
    "agn_coords = SkyCoord(ra=agn_data['ra'].values*u.deg, dec=agn_data['dec'].values*u.deg)\n",
    "lamost_coords = SkyCoord(ra=lamost_catalog['ra'].values*u.deg, dec=lamost_catalog['dec'].values*u.deg)\n",
    "\n",
    "# Perform the crossmatch using astropy's match_to_catalog_sky function\n",
    "idx, d2d, _ = agn_coords.match_to_catalog_sky(lamost_coords)\n",
    "\n",
    "# Define a matching radius\n",
    "match_radius = 1 * u.arcsec\n",
    "matches = d2d < match_radius\n",
    "\n",
    "# Filter the matches\n",
    "matched_agn = agn_data.iloc[matches]\n",
    "matched_lamost = lamost_catalog.iloc[idx[matches]]\n",
    "\n",
    "# Combine matched data\n",
    "agn_lamost_data = pd.concat([matched_agn.reset_index(drop=True), matched_lamost.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Save the crossmatched data\n",
    "agn_lamost_data.to_pickle(\"agn_lamost_data.pkl\")\n",
    "\n",
    "print(f\"Number of matches: {agn_lamost_data.shape[0]}\")\n",
    "print(\"out of \", agn_data.shape[0])\n",
    "del agn_data, lamost_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 40138/40138 [09:01<00:00, 74.06file/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Download complete! Successfully downloaded: 36336, Failed: 3802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the crossmatched data\n",
    "agn_lamost_data = pd.read_pickle(\"agn_lamost_data.pkl\")\n",
    "obsid_list = agn_lamost_data['obsid'].values\n",
    "\n",
    "# Specify the folder to save the files\n",
    "save_folder = \"agn_spectra\"\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "# List of URLs to download (assuming obsid_list is available)\n",
    "urls = [f\"https://www.lamost.org/dr7/v2.0/spectrum/fits/{obsid}\" for obsid in obsid_list]\n",
    "\n",
    "# Call the function to start downloading\n",
    "download_all_files(urls)\n",
    "\n",
    "# Free up memory by deleting the large DataFrame\n",
    "del agn_lamost_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
