{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location=('file:///C:/Users/jcwin/OneDrive - University of '\n",
       " 'Southampton/_Southampton/2024-25/Star-Classifier/mlflow/286740436428343516'), creation_time=1729267230861, experiment_id='286740436428343516', last_update_time=1729267230861, lifecycle_stage='active', name='Fusion_Gaia_LAMOST', tags={}>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import gc\n",
    "import psutil\n",
    "import GPUtil\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Enable MLflow autologging for PyTorch\n",
    "#mlflow.pytorch.autolog()\n",
    "mlflow.set_tracking_uri(uri=\"file:///C:/Users/jcwin/OneDrive - University of Southampton/_Southampton/2024-25/Star-Classifier/mlflow\")\n",
    "mlflow.set_experiment(\"Fusion_Gaia_LAMOST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetFusion(nn.Module):\n",
    "    def __init__(self, input_shape, num_classes, gaia_input_size, \n",
    "                 num_filters=[128, 128, 128, 128, 128, 128, 128, 128], \n",
    "                 kernel_size=9,\n",
    "                 dense_units=[256, 256, 256, 128, 128, 128, 64, 64, 64],\n",
    "                 dropout_rate=0.2, \n",
    "                 gaia_fusion_units=512,\n",
    "                 padding='same'):\n",
    "        super(ConvNetFusion, self).__init__()\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.pool_layers = nn.ModuleList()\n",
    "        in_channels = 1  # Since it's a 1D input\n",
    "        \n",
    "        # Add convolutional layers\n",
    "        for filters in num_filters:\n",
    "            conv_layer = nn.Conv1d(in_channels=in_channels, out_channels=filters, kernel_size=kernel_size, padding=kernel_size//2)\n",
    "            self.conv_layers.append(conv_layer)\n",
    "            self.pool_layers.append(nn.MaxPool1d(kernel_size=2))\n",
    "            self.dropout = nn.Dropout(dropout_rate)\n",
    "            in_channels = filters\n",
    "        \n",
    "        # Flatten the output\n",
    "        self.flatten = nn.Flatten()\n",
    "        final_seq_len = input_shape[0] // (2 ** len(num_filters)) * num_filters[-1]\n",
    "        print(\"Size of the flattened output:\", final_seq_len)\n",
    "\n",
    "        # Add Gaia features to the input\n",
    "        self.gaia_input_layer = nn.Linear(gaia_input_size, gaia_fusion_units)\n",
    "\n",
    "        # Add dense layers\n",
    "        dense_input_units = final_seq_len + gaia_fusion_units  # Add Gaia features to the dense input\n",
    "        print(\"Dense input units:\", dense_input_units)\n",
    "        print(\"Final sequence length:\", final_seq_len)\n",
    "        print(\"Number of filters:\", num_filters[-1])\n",
    "        self.dense_layers = nn.ModuleList()\n",
    "        for units in dense_units:\n",
    "            self.dense_layers.append(nn.Linear(dense_input_units, units))\n",
    "            dense_input_units = units\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(dense_input_units, num_classes)\n",
    "\n",
    "    \n",
    "    \n",
    "    def forward(self, x_conv, x_gaia):\n",
    "        # Pass through convolutional layers\n",
    "        for conv_layer, pool_layer in zip(self.conv_layers, self.pool_layers):\n",
    "            x_conv = pool_layer(torch.relu(conv_layer(x_conv)))\n",
    "            x_conv = self.dropout(x_conv)\n",
    "        # Flatten the conv output\n",
    "        x_conv = self.flatten(x_conv)\n",
    "\n",
    "        # Connect Gaia features to a separate dense layer and connect after to the main network\n",
    "        x_gaia = torch.relu(self.gaia_input_layer(x_gaia))\n",
    "\n",
    "        # Concatenate Gaia features\n",
    "        x = torch.cat((x_conv, x_gaia), dim=1)\n",
    "        \n",
    "        # Pass through dense layers\n",
    "        for dense_layer in self.dense_layers:\n",
    "            x = torch.relu(dense_layer(x))\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        # Output layer\n",
    "        x = self.output_layer(x)\n",
    "        return torch.softmax(x, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "# Create Datasets\n",
    "class BalancedDatasetFusion(Dataset):\n",
    "    def __init__(self, X_conv, X_gaia, y, limit_per_label=1600):\n",
    "        self.X_conv = X_conv\n",
    "        self.X_gaia = X_gaia\n",
    "        self.y = y\n",
    "        self.limit_per_label = limit_per_label\n",
    "        self.classes = np.unique(y)\n",
    "        self.indices = self.balance_classes()\n",
    "\n",
    "    def balance_classes(self):\n",
    "        indices = []\n",
    "        for cls in self.classes:\n",
    "            cls_indices = np.where(self.y == cls)[0]\n",
    "            if len(cls_indices) > self.limit_per_label:\n",
    "                cls_indices = np.random.choice(cls_indices, self.limit_per_label, replace=False)\n",
    "            indices.extend(cls_indices)\n",
    "        np.random.shuffle(indices)\n",
    "        return indices\n",
    "\n",
    "    def re_sample(self):\n",
    "        self.indices = self.balance_classes()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        index = self.indices[idx]\n",
    "        return self.X_conv[index], self.X_gaia[index], self.y[index]\n",
    "\n",
    "# Define a function to train the model\n",
    "def train_model(model, train_loader, val_loader, test_loader, num_epochs=200, lr=1e-4, patience=10):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    early_stopping_counter = 0\n",
    "    best_test_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Re-sample the training dataset at the start of each epoch\n",
    "        train_loader.dataset.re_sample()\n",
    "        model.train()\n",
    "        train_loss, correct_train, total_train = 0.0, 0, 0\n",
    "\n",
    "        # Training loop\n",
    "        for X_conv, X_gaia, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_conv, X_gaia)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * X_conv.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_train += (predicted == y).sum().item()\n",
    "            total_train += y.size(0)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc = correct_train / total_train\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss, correct_val, total_val, test_loss, correct_test, total_test = 0, 0, 0, 0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_conv, X_gaia, y in val_loader:\n",
    "                outputs = model(X_conv, X_gaia)\n",
    "                loss = criterion(outputs, y)\n",
    "                val_loss += loss.item() * X_conv.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_val += (predicted == y).sum().item()\n",
    "                total_val += y.size(0)\n",
    "        # Test loop\n",
    "        with torch.no_grad():\n",
    "            for X_conv, X_gaia, y in test_loader:\n",
    "                outputs = model(X_conv, X_gaia)\n",
    "                loss = criterion(outputs, y)\n",
    "                test_loss += loss.item() * X_conv.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_test += (predicted == y).sum().item()\n",
    "                total_test += y.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = correct_val / total_val\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        test_acc = correct_test / total_test\n",
    "\n",
    "        # Log metrics for MLflow\n",
    "        mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "        mlflow.log_metric(\"train_acc\", train_acc, step=epoch)\n",
    "        mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "        mlflow.log_metric(\"val_acc\", val_acc, step=epoch)\n",
    "        mlflow.log_metric(\"test_loss\", test_loss, step=epoch)\n",
    "        mlflow.log_metric(\"test_acc\", test_acc, step=epoch)\n",
    "\n",
    "\n",
    "        # Early stopping\n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            if early_stopping_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, \"\n",
    "              f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "\n",
    "    # Load the best model weights before returning\n",
    "    model.load_state_dict(best_model)\n",
    "    return model\n",
    "\n",
    "# Function to print confusion matrix and log it with MLflow\n",
    "def print_confusion_matrix(model, val_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_conv, X_gaia, y in val_loader:\n",
    "            outputs = model(X_conv, X_gaia)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Log confusion matrix\n",
    "    mlflow.log_artifact(confusion_matrix_to_image(cm), artifact_path=\"confusion_matrix\")\n",
    "\n",
    "def confusion_matrix_to_image(cm):\n",
    "    # Convert confusion matrix to an image (optional)\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import io\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    xticklabels=['Star', 'Binary Star', 'Galaxy', 'AGN']\n",
    "    yticklabels=['Star', 'Binary Star', 'Galaxy', 'AGN']\n",
    "\n",
    "    # Save the figure to a buffer\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    \n",
    "    # Return the buffer\n",
    "    return buf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "        # Load and preprocess data\n",
    "        X = pd.read_pickle(\"Pickles/fusionv0/train.pkl\")\n",
    "        gaia_features = [\"parallax\", \"ra\", \"dec\", \"ra_error\", \"dec_error\", \"parallax_error\", \"pmra\", \"pmdec\", \"pmra_error\", \"pmdec_error\", \n",
    "        \"phot_g_mean_flux\", \"flagnopllx\", \"phot_g_mean_flux_error\", \"phot_bp_mean_flux\", \"phot_rp_mean_flux\", \n",
    "        \"phot_bp_mean_flux_error\", \"phot_rp_mean_flux_error\"]\n",
    "\n",
    "        # Extract Gaia and LASMOST data\n",
    "        X_gaia = X[gaia_features].values\n",
    "        X_conv = X.drop(gaia_features + [\"label\"], axis=1).values\n",
    "        y = X[\"label\"]\n",
    "\n",
    "        # Mapping labels to integers\n",
    "        label_mapping = {'star': 0, 'binary_star': 1, 'galaxy': 2, 'agn': 3}\n",
    "        y = y.map(label_mapping).values\n",
    "\n",
    "        # Read test data\n",
    "        X_test = pd.read_pickle(\"Pickles/fusionv0/test.pkl\")\n",
    "        X_test_gaia = X_test[gaia_features].values\n",
    "        X_test_conv = X_test.drop(gaia_features + [\"label\"], axis=1).values\n",
    "        y_test = X_test[\"label\"]\n",
    "        y_test = y_test.map(label_mapping).values\n",
    "\n",
    "\n",
    "        # Split data into train and validation\n",
    "        X_train_conv, X_val_conv, X_train_gaia, X_val_gaia, y_train, y_val = train_test_split(X_conv, X_gaia, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        X_train_conv = torch.tensor(X_train_conv, dtype=torch.float32).unsqueeze(1)\n",
    "        X_val_conv = torch.tensor(X_val_conv, dtype=torch.float32).unsqueeze(1)\n",
    "        X_train_gaia = torch.tensor(X_train_gaia, dtype=torch.float32)\n",
    "        X_val_gaia = torch.tensor(X_val_gaia, dtype=torch.float32)\n",
    "        y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "        y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "        X_test_conv = torch.tensor(X_test_conv, dtype=torch.float32).unsqueeze(1)\n",
    "        X_test_gaia = torch.tensor(X_test_gaia, dtype=torch.float32)\n",
    "        y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_dataset = BalancedDatasetFusion(X_train_conv, X_train_gaia, y_train)\n",
    "        val_dataset = BalancedDatasetFusion(X_val_conv, X_val_gaia, y_val)\n",
    "        test_dataset = BalancedDatasetFusion(X_test_conv, X_test_gaia, y_test)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=512, shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaia input size: 17\n",
      "ConvNetFusion(\n",
      "  (spectra_branch): SpectraBranch(\n",
      "    (conv_layers): ModuleList(\n",
      "      (0): Conv1d(1, 16, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "      (1): Conv1d(16, 16, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "      (2): Conv1d(16, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "      (3-4): 2 x Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "      (5): Conv1d(32, 64, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "      (6-7): 2 x Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "      (8): Conv1d(64, 128, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "      (9-10): 2 x Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "    )\n",
      "    (pool_layers): ModuleList(\n",
      "      (0-10): 11 x MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (gaia_branch): GaiaBranch(\n",
      "    (fc): Linear(in_features=17, out_features=128, bias=True)\n",
      "  )\n",
      "  (dense_layers): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (dense_1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (relu_1): ReLU()\n",
      "    (dropout_1): Dropout(p=0.2, inplace=False)\n",
      "    (dense_2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (relu_2): ReLU()\n",
      "    (dropout_2): Dropout(p=0.2, inplace=False)\n",
      "    (dense_3): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (relu_3): ReLU()\n",
      "    (dropout_3): Dropout(p=0.2, inplace=False)\n",
      "    (dense_4): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (relu_4): ReLU()\n",
      "    (dropout_4): Dropout(p=0.2, inplace=False)\n",
      "    (dense_5): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (relu_5): ReLU()\n",
      "    (dropout_5): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (output_layer): Linear(in_features=32, out_features=4, bias=True)\n",
      ")\n",
      "Number of parameters: 730036\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the Spectra Branch as a separate module\n",
    "class SpectraBranch(nn.Module):\n",
    "    def __init__(self, input_shape, num_classes, \n",
    "                 num_filters=[128, 128, 128, 128, 128, 128, 128, 128], \n",
    "                 kernel_size=9,\n",
    "                 dropout_rate=0.2, padding='same'):\n",
    "        super(SpectraBranch, self).__init__()\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.pool_layers = nn.ModuleList()\n",
    "        in_channels = 1  # Since it's a 1D input\n",
    "        \n",
    "        # Add convolutional layers\n",
    "        for filters in num_filters:\n",
    "            conv_layer = nn.Conv1d(in_channels=in_channels, out_channels=filters, kernel_size=kernel_size, padding=kernel_size//2)\n",
    "            self.conv_layers.append(conv_layer)\n",
    "            self.pool_layers.append(nn.MaxPool1d(kernel_size=2))\n",
    "            in_channels = filters\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.flatten = nn.Flatten()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for conv_layer, pool_layer in zip(self.conv_layers, self.pool_layers):\n",
    "            x = pool_layer(torch.relu(conv_layer(x)))\n",
    "            x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        return x\n",
    "\n",
    "# Define the Gaia Branch as a separate module\n",
    "class GaiaBranch(nn.Module):\n",
    "    def __init__(self, gaia_input_size, gaia_fusion_units):\n",
    "        super(GaiaBranch, self).__init__()\n",
    "        self.fc = nn.Linear(gaia_input_size, gaia_fusion_units)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.relu(self.fc(x))\n",
    "\n",
    "# Fusion Model that combines both branches\n",
    "class ConvNetFusion(nn.Module):\n",
    "    def __init__(self, input_shape, num_classes, gaia_input_size, \n",
    "                 num_filters=[128, 128, 128, 128, 128, 128, 128, 128],  # More filters for SpectraBranch\n",
    "                 kernel_size=9,\n",
    "                 dense_units=[256, 128, 64, 32],\n",
    "                 dropout_rate=0.2, \n",
    "                 gaia_fusion_units=10000):\n",
    "        super(ConvNetFusion, self).__init__()\n",
    "\n",
    "        # Instantiate the two branches\n",
    "        self.spectra_branch = SpectraBranch(input_shape, num_classes, num_filters, kernel_size, dropout_rate)\n",
    "        self.gaia_branch = GaiaBranch(gaia_input_size, gaia_fusion_units)\n",
    "\n",
    "        # Fused input size\n",
    "        fused_input_size = gaia_fusion_units + num_filters[-1] * (input_shape[0] // (2 ** len(num_filters)))\n",
    "        \n",
    "        # Fully connected layers after fusion\n",
    "        for i, units in enumerate(dense_units):\n",
    "            if i == 0:\n",
    "                self.dense_layers = nn.Sequential(\n",
    "                    nn.Linear(fused_input_size, units),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(dropout_rate)\n",
    "                )\n",
    "            else:\n",
    "                self.dense_layers.add_module(f\"dense_{i}\", nn.Linear(dense_units[i-1], units))\n",
    "                self.dense_layers.add_module(f\"relu_{i}\", nn.ReLU())\n",
    "                self.dense_layers.add_module(f\"dropout_{i}\", nn.Dropout(dropout_rate))\n",
    "\n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(dense_units[-1], num_classes)\n",
    "\n",
    "    def forward(self, x_conv, x_gaia):\n",
    "        # Spectra branch forward pass\n",
    "        x_conv = self.spectra_branch(x_conv)\n",
    "        \n",
    "        # Gaia branch forward pass\n",
    "        x_gaia = self.gaia_branch(x_gaia)\n",
    "        \n",
    "        # Concatenate the two branches\n",
    "        x_fused = torch.cat((x_conv, x_gaia), dim=1)\n",
    "\n",
    "        # Pass through dense layers\n",
    "        x = self.dense_layers(x_fused)\n",
    "\n",
    "        # Output layer\n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        return torch.softmax(x, dim=1)\n",
    "# Initialize toy model\n",
    "gaia_input_size = X_train_gaia.shape[1]\n",
    "print(f\"Gaia input size: {gaia_input_size}\")\n",
    "filters = [16, 16, 32, 32, 32, 64, 64,64, 128, 128, 128]\n",
    "dense=[256, 256 , 256 ,128, 64, 32]\n",
    "\n",
    "model = ConvNetFusion(input_shape=(3748,), num_classes=4, gaia_input_size=gaia_input_size, \n",
    "                      num_filters=filters, kernel_size=9, dense_units=dense, dropout_rate=0.2, gaia_fusion_units=128)\n",
    "# Save the model\n",
    "torch.save(model, \"Models/toyv0.pth\")\n",
    "# Print model summary\n",
    "print(model)\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bunda bebe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/21 17:26:55 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "2024/10/21 17:26:55 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:27:05 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:27:15 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Train Loss: 1.2775, Train Acc: 0.4439, Val Loss: 1.2302, Val Acc: 0.5581, Test Loss: 1.2283, Test Acc: 0.5589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/21 17:27:25 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:27:35 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/200], Train Loss: 1.1011, Train Acc: 0.6480, Val Loss: 1.1058, Val Acc: 0.6130, Test Loss: 1.1093, Test Acc: 0.6084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/21 17:27:45 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:27:55 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/200], Train Loss: 1.0670, Train Acc: 0.6556, Val Loss: 1.0899, Val Acc: 0.6358, Test Loss: 1.0914, Test Acc: 0.6312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/21 17:28:05 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:28:16 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/200], Train Loss: 1.0487, Train Acc: 0.6721, Val Loss: 1.0785, Val Acc: 0.6261, Test Loss: 1.0797, Test Acc: 0.6225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/21 17:28:26 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:28:36 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/200], Train Loss: 1.0464, Train Acc: 0.6631, Val Loss: 1.0736, Val Acc: 0.6278, Test Loss: 1.0737, Test Acc: 0.6265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/21 17:28:46 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:28:56 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/200], Train Loss: 1.0242, Train Acc: 0.6912, Val Loss: 1.0626, Val Acc: 0.6323, Test Loss: 1.0624, Test Acc: 0.6341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/21 17:29:06 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:29:16 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/200], Train Loss: 1.0269, Train Acc: 0.6872, Val Loss: 1.0575, Val Acc: 0.6360, Test Loss: 1.0594, Test Acc: 0.6347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/21 17:29:26 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:29:36 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:29:46 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/200], Train Loss: 1.0175, Train Acc: 0.6963, Val Loss: 1.0540, Val Acc: 0.6432, Test Loss: 1.0548, Test Acc: 0.6424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/21 17:29:56 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:30:06 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/200], Train Loss: 1.0120, Train Acc: 0.7030, Val Loss: 1.0490, Val Acc: 0.6787, Test Loss: 1.0475, Test Acc: 0.6806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/21 17:30:17 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:30:27 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200], Train Loss: 1.0031, Train Acc: 0.7283, Val Loss: 1.0324, Val Acc: 0.7108, Test Loss: 1.0307, Test Acc: 0.7160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/21 17:30:37 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:30:47 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/200], Train Loss: 0.9945, Train Acc: 0.7508, Val Loss: 1.0092, Val Acc: 0.7326, Test Loss: 1.0085, Test Acc: 0.7344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/21 17:30:57 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:31:07 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/200], Train Loss: 0.9687, Train Acc: 0.7713, Val Loss: 0.9955, Val Acc: 0.7418, Test Loss: 0.9927, Test Acc: 0.7456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/21 17:31:17 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:31:27 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/200], Train Loss: 0.9618, Train Acc: 0.7749, Val Loss: 0.9839, Val Acc: 0.7572, Test Loss: 0.9782, Test Acc: 0.7626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/21 17:31:37 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:31:47 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/200], Train Loss: 0.9471, Train Acc: 0.7958, Val Loss: 0.9871, Val Acc: 0.7544, Test Loss: 0.9842, Test Acc: 0.7546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/21 17:31:57 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:32:07 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/200], Train Loss: 0.9494, Train Acc: 0.7941, Val Loss: 0.9699, Val Acc: 0.7704, Test Loss: 0.9624, Test Acc: 0.7780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/21 17:32:18 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:32:28 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:32:38 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/200], Train Loss: 0.9377, Train Acc: 0.8048, Val Loss: 0.9666, Val Acc: 0.7751, Test Loss: 0.9586, Test Acc: 0.7803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/21 17:32:48 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:32:58 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/200], Train Loss: 0.9283, Train Acc: 0.8145, Val Loss: 0.9621, Val Acc: 0.7780, Test Loss: 0.9564, Test Acc: 0.7846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/21 17:33:08 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:33:18 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/200], Train Loss: 0.9348, Train Acc: 0.8061, Val Loss: 0.9692, Val Acc: 0.7733, Test Loss: 0.9629, Test Acc: 0.7786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/21 17:33:28 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:33:38 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:33:48 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/200], Train Loss: 0.9302, Train Acc: 0.8128, Val Loss: 0.9606, Val Acc: 0.7811, Test Loss: 0.9565, Test Acc: 0.7852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/21 17:33:58 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:34:08 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/200], Train Loss: 0.9359, Train Acc: 0.8061, Val Loss: 0.9573, Val Acc: 0.7848, Test Loss: 0.9516, Test Acc: 0.7915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/21 17:34:19 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:34:29 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/200], Train Loss: 0.9373, Train Acc: 0.8043, Val Loss: 0.9502, Val Acc: 0.7903, Test Loss: 0.9445, Test Acc: 0.7969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/21 17:34:39 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:34:49 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/200], Train Loss: 0.9313, Train Acc: 0.8117, Val Loss: 0.9479, Val Acc: 0.7924, Test Loss: 0.9404, Test Acc: 0.8018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/21 17:34:59 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:35:09 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/200], Train Loss: 0.9188, Train Acc: 0.8235, Val Loss: 0.9441, Val Acc: 0.7981, Test Loss: 0.9372, Test Acc: 0.8029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/21 17:35:19 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:35:29 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/200], Train Loss: 0.9187, Train Acc: 0.8240, Val Loss: 0.9466, Val Acc: 0.7934, Test Loss: 0.9380, Test Acc: 0.8053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/21 17:35:39 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/10/21 17:35:43 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/10/21 17:35:43 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernel_size\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     23\u001b[0m print_confusion_matrix(trained_model, train_loader)\n",
      "Cell \u001b[1;32mIn[63], line 119\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, test_loader, num_epochs, lr, patience)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_conv, X_gaia, y \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m    118\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 119\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_conv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_gaia\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y)\n\u001b[0;32m    121\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[64], line 77\u001b[0m, in \u001b[0;36mConvNetFusion.forward\u001b[1;34m(self, x_conv, x_gaia)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_conv, x_gaia):\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;66;03m# Spectra branch forward pass\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     x_conv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspectra_branch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_conv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;66;03m# Gaia branch forward pass\u001b[39;00m\n\u001b[0;32m     80\u001b[0m     x_gaia \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgaia_branch(x_gaia)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[64], line 28\u001b[0m, in \u001b[0;36mSpectraBranch.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m conv_layer, pool_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool_layers):\n\u001b[1;32m---> 28\u001b[0m         x \u001b[38;5;241m=\u001b[39m pool_layer(torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[43mconv_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     29\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[0;32m     30\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\conv.py:308\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\conv.py:304\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    302\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    303\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 304\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "num_epochs = 200\n",
    "lr = 1e-3\n",
    "patience = 20\n",
    "batch_size = 512\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run(log_system_metrics=True):\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"num_epochs\", num_epochs)\n",
    "    mlflow.log_param(\"lr\", lr)\n",
    "    mlflow.log_param(\"patience\", patience)\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    mlflow.log_param(\"num_filters\", filters)\n",
    "    mlflow.log_param(\"dense_units\", dense)\n",
    "    mlflow.log_param(\"dropout_rate\", 0.2)\n",
    "    mlflow.log_param(\"kernel_size\", 20)\n",
    "\n",
    "    # Train the model\n",
    "    trained_model = train_model(model, train_loader, val_loader, test_loader, num_epochs=num_epochs, lr=lr, patience=patience)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print_confusion_matrix(trained_model, train_loader)\n",
    "    # Save the model in MLflow\n",
    "    #mlflow.pytorch.log_model(trained_model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1227  349    3   21]\n",
      " [ 374 1199    7   20]\n",
      " [   1    0  327    7]\n",
      " [  43   12  214 1331]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "stat: path should be string, bytes, os.PathLike or integer, not BytesIO",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mprint_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[63], line 210\u001b[0m, in \u001b[0;36mprint_confusion_matrix\u001b[1;34m(model, val_loader)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28mprint\u001b[39m(cm)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;66;03m# Log confusion matrix\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfusion_matrix_to_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfusion_matrix\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mlflow\\tracking\\fluent.py:1130\u001b[0m, in \u001b[0;36mlog_artifact\u001b[1;34m(local_path, artifact_path, run_id)\u001b[0m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;124;03mLog a local file or directory as an artifact of the currently active run. If no run is\u001b[39;00m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;124;03mactive, this method will create a new active run.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;124;03m            mlflow.log_artifact(path)\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1129\u001b[0m run_id \u001b[38;5;241m=\u001b[39m run_id \u001b[38;5;129;01mor\u001b[39;00m _get_or_start_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[1;32m-> 1130\u001b[0m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mlflow\\tracking\\client.py:1928\u001b[0m, in \u001b[0;36mMlflowClient.log_artifact\u001b[1;34m(self, run_id, local_path, artifact_path)\u001b[0m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_id\u001b[38;5;241m.\u001b[39mstartswith(TRACE_REQUEST_ID_PREFIX):\n\u001b[0;32m   1925\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m   1926\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid run id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. `log_artifact` run id must map to a valid run.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1927\u001b[0m     )\n\u001b[1;32m-> 1928\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:834\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_artifact\u001b[1;34m(self, run_id, local_path, artifact_path)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;124;03mWrite a local file or directory to the remote ``artifact_uri``.\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;124;03m    artifact_path: If provided, the directory in ``artifact_uri`` to write to.\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    833\u001b[0m artifact_repo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_artifact_repo(run_id)\n\u001b[1;32m--> 834\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    835\u001b[0m     dir_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(local_path))\n\u001b[0;32m    836\u001b[0m     path_name \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    837\u001b[0m         os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(artifact_path, dir_name) \u001b[38;5;28;01mif\u001b[39;00m artifact_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dir_name\n\u001b[0;32m    838\u001b[0m     )\n",
      "File \u001b[1;32m<frozen genericpath>:42\u001b[0m, in \u001b[0;36misdir\u001b[1;34m(s)\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: stat: path should be string, bytes, os.PathLike or integer, not BytesIO"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_confusion_matrix(trained_model, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix and classification report\n",
    "def print_confusion_matrix(model, val_loader, device='cuda'):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            preds = model(X_batch).cpu().numpy()\n",
    "            all_preds.extend(np.argmax(preds, axis=1))\n",
    "            all_labels.extend(y_batch.numpy())\n",
    "\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds))\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "                xticklabels=['Star', 'Binary Star', 'Galaxy', 'AGN'], \n",
    "                yticklabels=['Star', 'Binary Star', 'Galaxy', 'AGN'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
