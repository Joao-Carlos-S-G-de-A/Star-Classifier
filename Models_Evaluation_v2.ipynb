{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading datasets...\n",
      "Test samples: 259\n",
      "\n",
      "==================================================\n",
      "Evaluating model: MambaOut_1token\n",
      "==================================================\n",
      "Loading checkpoint from Comparing_Mambas_Trans/gated_cnn_(mambaout)_1_token.pth\n",
      "Number of parameters: 1,048,856,631\n",
      "Model size: 4001.07 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:00<00:00, 103.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics:\n",
      "  Loss: 0.0674\n",
      "  Accuracy: 0.9771\n",
      "  Micro F1: 0.6099\n",
      "  Macro F1: 0.4359\n",
      "  Weighted F1: 0.5772\n",
      "  Macro AUROC: 0.9298620191392433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Evaluating model: MambaOut_19_18token\n",
      "==================================================\n",
      "Loading checkpoint from Comparing_Mambas_Trans/gated_cnn_(mambaout)_balanced.pth\n",
      "Number of parameters: 1,042,237,495\n",
      "Model size: 3975.82 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:00<00:00, 20.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics:\n",
      "  Loss: 0.0751\n",
      "  Accuracy: 0.9735\n",
      "  Micro F1: 0.5152\n",
      "  Macro F1: 0.3707\n",
      "  Weighted F1: 0.4852\n",
      "  Macro AUROC: 0.9012070076937412\n",
      "\n",
      "==================================================\n",
      "Evaluating model: MambaOut_522_18token\n",
      "==================================================\n",
      "Loading checkpoint from Comparing_Mambas_Trans/gated_cnn_(mambaout)_max_tokens.pth\n",
      "Number of parameters: 589,799,479\n",
      "Model size: 2249.91 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:06<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics:\n",
      "  Loss: 0.0612\n",
      "  Accuracy: 0.9719\n",
      "  Micro F1: 0.4371\n",
      "  Macro F1: 0.3131\n",
      "  Weighted F1: 0.3990\n",
      "  Macro AUROC: 0.9174140493747273\n",
      "\n",
      "==================================================\n",
      "Evaluating model: Transformer_1token\n",
      "==================================================\n",
      "Checkpoint Comparing_Mambas_Trans/transformer_1_token.pth not found. Skipping this model.\n",
      "\n",
      "==================================================\n",
      "Evaluating model: Transformer_19_18token\n",
      "==================================================\n",
      "Loading checkpoint from Comparing_Mambas_Trans/transformer_balanced.pth\n",
      "Number of parameters: 1,041,377,335\n",
      "Model size: 4052.55 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:00<00:00, 19.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics:\n",
      "  Loss: 0.0760\n",
      "  Accuracy: 0.9743\n",
      "  Micro F1: 0.5782\n",
      "  Macro F1: 0.4444\n",
      "  Weighted F1: 0.5574\n",
      "  Macro AUROC: 0.8785354495338072\n",
      "\n",
      "==================================================\n",
      "Evaluating model: Transformer_522_18token\n",
      "==================================================\n",
      "Checkpoint Comparing_Mambas_Trans/transformer_max_tokens.pth not found. Skipping this model.\n",
      "\n",
      "==================================================\n",
      "Evaluating model: Mamba2_1token\n",
      "==================================================\n",
      "Checkpoint Comparing_Mambas_Trans/mamba_1_token.pth not found. Skipping this model.\n",
      "\n",
      "==================================================\n",
      "Evaluating model: Mamba2_19_18token\n",
      "==================================================\n",
      "Checkpoint Comparing_Mambas_Trans/mamba_balanced.pth not found. Skipping this model.\n",
      "\n",
      "==================================================\n",
      "Evaluating model: Mamba2_522_18token\n",
      "==================================================\n",
      "Loading checkpoint from Comparing_Mambas_Trans/mamba_max_tokens.pth\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for StarClassifierFusionMambaTokenized:\n\tsize mismatch for mamba_spectra.0.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.0.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.0.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.1.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.1.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.1.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.2.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.2.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.2.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.3.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.3.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.3.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.4.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.4.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.4.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.5.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.5.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.5.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.6.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.6.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.6.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.7.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.7.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.7.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.8.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.8.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.8.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.9.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.9.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.9.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.10.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.10.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.10.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.11.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.11.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.11.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.12.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.12.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.12.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.13.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.13.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.13.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.14.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.14.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.14.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.15.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.15.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.15.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.16.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.16.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.16.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.17.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.17.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.17.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.18.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.18.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.18.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.19.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.19.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.19.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.0.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.0.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.0.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.1.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.1.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.1.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.2.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.2.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.2.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.3.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.3.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.3.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.4.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.4.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.4.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.5.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.5.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.5.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.6.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.6.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.6.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.7.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.7.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.7.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.8.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.8.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.8.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.9.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.9.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.9.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.10.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.10.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.10.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.11.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.11.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.11.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.12.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.12.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.12.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.13.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.13.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.13.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.14.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.14.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.14.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.15.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.15.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.15.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.16.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.16.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.16.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.17.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.17.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.17.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.18.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.18.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.18.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.19.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.19.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.19.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 631\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummary report generated: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/summary_report.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 631\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 440\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(checkpoint_path):\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading checkpoint from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 440\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheckpoint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found. Skipping this model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Star-Classifier/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:2581\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2573\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2574\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2575\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2576\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2577\u001b[0m             ),\n\u001b[1;32m   2578\u001b[0m         )\n\u001b[1;32m   2580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2583\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2584\u001b[0m         )\n\u001b[1;32m   2585\u001b[0m     )\n\u001b[1;32m   2586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for StarClassifierFusionMambaTokenized:\n\tsize mismatch for mamba_spectra.0.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.0.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.0.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.1.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.1.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.1.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.2.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.2.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.2.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.3.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.3.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.3.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.4.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.4.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.4.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.5.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.5.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.5.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.6.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.6.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.6.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.7.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.7.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.7.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.8.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.8.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.8.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.9.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.9.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.9.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.10.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.10.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.10.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.11.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.11.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.11.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.12.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.12.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.12.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.13.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.13.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.13.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.14.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.14.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.14.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.15.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.15.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.15.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.16.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.16.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.16.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.17.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.17.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.17.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.18.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.18.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.18.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_spectra.19.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_spectra.19.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_spectra.19.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.0.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.0.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.0.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.1.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.1.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.1.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.2.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.2.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.2.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.3.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.3.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.3.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.4.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.4.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.4.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.5.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.5.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.5.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.6.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.6.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.6.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.7.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.7.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.7.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.8.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.8.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.8.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.9.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.9.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.9.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.10.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.10.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.10.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.11.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.11.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.11.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.12.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.12.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.12.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.13.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.13.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.13.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.14.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.14.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.14.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.15.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.15.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.15.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.16.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.16.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.16.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.17.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.17.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.17.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.18.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.18.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.18.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104]).\n\tsize mismatch for mamba_gaia.19.in_proj.weight: copying a param with shape torch.Size([6704, 1536]) from checkpoint, the shape in current model is torch.Size([6224, 1536]).\n\tsize mismatch for mamba_gaia.19.conv1d.weight: copying a param with shape torch.Size([3584, 1, 4]) from checkpoint, the shape in current model is torch.Size([3104, 1, 4]).\n\tsize mismatch for mamba_gaia.19.conv1d.bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([3104])."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, hamming_loss, roc_auc_score, average_precision_score\n",
    "import os\n",
    "import json\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# Import your model architectures\n",
    "from Fusion_Models import StarClassifierFusionMambaOut, StarClassifierFusionTransformer, StarClassifierFusionMambaTokenized\n",
    "\n",
    "class MultiModalBalancedMultiLabelDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A balanced multi-label dataset that returns (X_spectra, X_gaia, y).\n",
    "    It uses the same balancing strategy as `BalancedMultiLabelDataset`.\n",
    "    \"\"\"\n",
    "    def __init__(self, X_spectra, X_gaia, y, limit_per_label=201):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X_spectra (torch.Tensor): [num_samples, num_spectra_features]\n",
    "            X_gaia (torch.Tensor): [num_samples, num_gaia_features]\n",
    "            y (torch.Tensor): [num_samples, num_classes], multi-hot labels\n",
    "            limit_per_label (int): limit or target number of samples per label\n",
    "        \"\"\"\n",
    "        self.X_spectra = X_spectra\n",
    "        self.X_gaia = X_gaia\n",
    "        self.y = y\n",
    "        self.limit_per_label = limit_per_label\n",
    "        self.num_classes = y.shape[1]\n",
    "        self.indices = self.balance_classes()\n",
    "        \n",
    "    def balance_classes(self):\n",
    "        indices = []\n",
    "        class_counts = torch.sum(self.y, axis=0)\n",
    "        for cls in range(self.num_classes):\n",
    "            cls_indices = np.where(self.y[:, cls] == 1)[0]\n",
    "            if len(cls_indices) < self.limit_per_label:\n",
    "                if len(cls_indices) == 0:\n",
    "                    # No samples for this class\n",
    "                    continue\n",
    "                extra_indices = np.random.choice(\n",
    "                    cls_indices, self.limit_per_label - len(cls_indices), replace=True\n",
    "                )\n",
    "                cls_indices = np.concatenate([cls_indices, extra_indices])\n",
    "            elif len(cls_indices) > self.limit_per_label:\n",
    "                cls_indices = np.random.choice(cls_indices, self.limit_per_label, replace=False)\n",
    "            indices.extend(cls_indices)\n",
    "        indices = np.unique(indices)\n",
    "        np.random.shuffle(indices)\n",
    "        return indices\n",
    "\n",
    "    def re_sample(self):\n",
    "        self.indices = self.balance_classes()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        index = self.indices[idx]\n",
    "        return (\n",
    "            self.X_spectra[index],  # spectra features\n",
    "            self.X_gaia[index],     # gaia features\n",
    "            self.y[index],          # multi-hot labels\n",
    "        )\n",
    "    \n",
    "def calculate_class_weights(y):\n",
    "    if y.ndim > 1:  \n",
    "        class_counts = np.sum(y, axis=0)  \n",
    "    else:\n",
    "        class_counts = np.bincount(y)\n",
    "\n",
    "    total_samples = y.shape[0] if y.ndim > 1 else len(y)\n",
    "    class_counts = np.where(class_counts == 0, 1, class_counts)  # Prevent division by zero\n",
    "    class_weights = total_samples / (len(class_counts) * class_counts)\n",
    "    \n",
    "    return class_weights\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    metrics = {\n",
    "        \"micro_f1\": f1_score(y_true, y_pred, average='micro'),\n",
    "        \"macro_f1\": f1_score(y_true, y_pred, average='macro'),\n",
    "        \"weighted_f1\": f1_score(y_true, y_pred, average='weighted'),\n",
    "        \"micro_precision\": precision_score(y_true, y_pred, average='micro', zero_division=1),\n",
    "        \"macro_precision\": precision_score(y_true, y_pred, average='macro', zero_division=1),\n",
    "        \"weighted_precision\": precision_score(y_true, y_pred, average='weighted', zero_division=1),\n",
    "        \"micro_recall\": recall_score(y_true, y_pred, average='micro'),\n",
    "        \"macro_recall\": recall_score(y_true, y_pred, average='macro'),\n",
    "        \"weighted_recall\": recall_score(y_true, y_pred, average='weighted'),\n",
    "        \"hamming_loss\": hamming_loss(y_true, y_pred)\n",
    "    }\n",
    "    \n",
    "    # Check if there are at least two classes present in y_true\n",
    "    #if len(np.unique(y_true)) > 1:\n",
    "        #metrics[\"roc_auc\"] = roc_auc_score(y_true, y_pred, average='macro', multi_class='ovr')\n",
    "    #else:\n",
    "       # metrics[\"roc_auc\"] = None  # or you can set it to a default value or message\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Load and preprocess the data\"\"\"\n",
    "    print(\"Loading datasets...\")\n",
    "    \n",
    "    # Load classes\n",
    "    with open(\"Pickles/Updated_List_of_Classes_ubuntu.pkl\", \"rb\") as f:\n",
    "        classes = pickle.load(f)\n",
    "    \n",
    "    # Load test data\n",
    "    with open(\"Pickles/test_data_transformed_ubuntu.pkl\", \"rb\") as f:\n",
    "        X_test_full = pickle.load(f)\n",
    "    \n",
    "    # Extract labels\n",
    "    y_test = X_test_full[classes]\n",
    "    \n",
    "    # Drop labels from both datasets\n",
    "    X_test_full.drop(classes, axis=1, inplace=True)\n",
    "    \n",
    "    # Define Gaia columns\n",
    "    gaia_columns = [\"parallax\", \"ra\", \"dec\", \"ra_error\", \"dec_error\", \"parallax_error\", \n",
    "                   \"pmra\", \"pmdec\", \"pmra_error\", \"pmdec_error\", \"phot_g_mean_flux\", \n",
    "                   \"flagnopllx\", \"phot_g_mean_flux_error\", \"phot_bp_mean_flux\", \n",
    "                   \"phot_rp_mean_flux\", \"phot_bp_mean_flux_error\", \n",
    "                   \"phot_rp_mean_flux_error\", \"flagnoflux\"]\n",
    "    \n",
    "    # Split data into spectra and gaia parts\n",
    "    X_test_spectra = X_test_full.drop(columns={\"otype\", \"obsid\", *gaia_columns})\n",
    "    \n",
    "    X_test_gaia = X_test_full[gaia_columns]\n",
    "    \n",
    "    # Free up memory\n",
    "    del X_test_full\n",
    "    gc.collect()\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    X_test_spectra_tensor = torch.tensor(X_test_spectra.values, dtype=torch.float32)\n",
    "\n",
    "    X_test_gaia_tensor = torch.tensor(X_test_gaia.values, dtype=torch.float32)\n",
    "    \n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "    \n",
    "    return (X_test_spectra_tensor, X_test_gaia_tensor, y_test_tensor)\n",
    "\n",
    "def evaluate_model(model, test_loader, device='cuda'):\n",
    "    \"\"\"Evaluate a model on test data and return comprehensive metrics\"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "    y_true, y_pred, y_prob = [], [], []\n",
    "    \n",
    "    # Compute class weights for loss function\n",
    "    all_labels = []\n",
    "    for _, _, y_batch in test_loader:\n",
    "        all_labels.extend(y_batch.cpu().numpy())\n",
    "    \n",
    "    class_weights = calculate_class_weights(np.array(all_labels))\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights)\n",
    "    \n",
    "    # Evaluation loop\n",
    "    with torch.no_grad():\n",
    "        for X_spc, X_ga, y_batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            X_spc, X_ga, y_batch = X_spc.to(device), X_ga.to(device), y_batch.to(device)\n",
    "            outputs = model(X_spc, X_ga)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            test_loss += loss.item() * X_spc.size(0)\n",
    "            \n",
    "            probs = torch.sigmoid(outputs)\n",
    "            predicted = (probs > 0.5).float()\n",
    "            correct = (predicted == y_batch).float()\n",
    "            test_acc += correct.mean(dim=1).mean().item()\n",
    "\n",
    "            y_true.extend(y_batch.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "            y_prob.extend(probs.cpu().numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    y_true_array = np.array(y_true)\n",
    "    y_pred_array = np.array(y_pred)\n",
    "    y_prob_array = np.array(y_prob)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = calculate_metrics(y_true_array, y_pred_array)\n",
    "    \n",
    "    # Add average metrics\n",
    "    metrics[\"avg_loss\"] = test_loss / len(test_loader.dataset)\n",
    "    metrics[\"avg_accuracy\"] = test_acc / len(test_loader)\n",
    "    \n",
    "    # Calculate AUROC if possible\n",
    "    try:\n",
    "        class_aurocs = []\n",
    "        for i in range(y_true_array.shape[1]):\n",
    "            if len(np.unique(y_true_array[:, i])) > 1:\n",
    "                class_auroc = roc_auc_score(y_true_array[:, i], y_prob_array[:, i])\n",
    "                class_aurocs.append(class_auroc)\n",
    "        \n",
    "        if class_aurocs:\n",
    "            metrics[\"macro_auroc\"] = np.mean(class_aurocs)\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating AUROC: {e}\")\n",
    "        metrics[\"macro_auroc\"] = float('nan')\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def main():\n",
    "    # Create results directory\n",
    "    results_dir = f\"model_comparison_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    os.makedirs(\"Models\", exist_ok=True)\n",
    "    \n",
    "    # Set device\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load data\n",
    "    (X_test_spectra, X_test_gaia, y_test) = load_data()\n",
    "    \n",
    "    # Create datasets and dataloaders\n",
    "    batch_size = 16\n",
    "    batch_limit = int(batch_size / 2.5)\n",
    "    \n",
    "\n",
    "    test_dataset = MultiModalBalancedMultiLabelDataset(\n",
    "        X_test_spectra, X_test_gaia, y_test, limit_per_label=batch_limit\n",
    "    )\n",
    "    \n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "\n",
    "    print(f\"Test samples: {len(test_dataset)}\")\n",
    "    # Define model configurations to evaluate\n",
    "    model_configs = [\n",
    "        # MambaOut Models\n",
    "        {\n",
    "            \"name\": \"MambaOut_1token\",\n",
    "            \"model_class\": StarClassifierFusionMambaOut,\n",
    "            \"params\": {\n",
    "                \"d_model_spectra\": 2048,\n",
    "                \"d_model_gaia\": 2048,\n",
    "                \"num_classes\": 55,\n",
    "                \"input_dim_spectra\": 3647,\n",
    "                \"input_dim_gaia\": 18,\n",
    "                \"token_dim_spectra\": 3647,  # 1 token\n",
    "                \"token_dim_gaia\": 18,       # 1 token\n",
    "                \"n_layers\": 20,\n",
    "                \"d_conv\": 1,\n",
    "                \"use_cross_attention\": True,\n",
    "                \"n_cross_attn_heads\": 8\n",
    "            },\n",
    "            \"checkpoint\": \"Comparing_Mambas_Trans/gated_cnn_(mambaout)_1_token.pth\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"MambaOut_19_18token\",\n",
    "            \"model_class\": StarClassifierFusionMambaOut,\n",
    "            \"params\": {\n",
    "                \"d_model_spectra\": 2048,\n",
    "                \"d_model_gaia\": 2048,\n",
    "                \"num_classes\": 55,\n",
    "                \"input_dim_spectra\": 3647,\n",
    "                \"input_dim_gaia\": 18,\n",
    "                \"token_dim_spectra\": 192,  # ~19 tokens\n",
    "                \"token_dim_gaia\": 1,       # 18 tokens\n",
    "                \"n_layers\": 20,\n",
    "                \"d_conv\": 4,\n",
    "                \"use_cross_attention\": True,\n",
    "                \"n_cross_attn_heads\": 8\n",
    "            },\n",
    "            \"checkpoint\": \"Comparing_Mambas_Trans/gated_cnn_(mambaout)_balanced.pth\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"MambaOut_522_18token\",\n",
    "            \"model_class\": StarClassifierFusionMambaOut,\n",
    "            \"params\": {\n",
    "                \"d_model_spectra\": 1536,\n",
    "                \"d_model_gaia\": 1536,\n",
    "                \"num_classes\": 55,\n",
    "                \"input_dim_spectra\": 3647,\n",
    "                \"input_dim_gaia\": 18,\n",
    "                \"token_dim_spectra\": 7,    # ~522 tokens\n",
    "                \"token_dim_gaia\": 1,       # 18 tokens\n",
    "                \"n_layers\": 20,\n",
    "                \"d_conv\": 32,\n",
    "                \"use_cross_attention\": True,\n",
    "                \"n_cross_attn_heads\": 8\n",
    "            },\n",
    "            \"checkpoint\": \"Comparing_Mambas_Trans/gated_cnn_(mambaout)_max_tokens.pth\"\n",
    "        },\n",
    "        \n",
    "        # Transformer Models\n",
    "        {\n",
    "            \"name\": \"Transformer_1token\",\n",
    "            \"model_class\": StarClassifierFusionTransformer,\n",
    "            \"params\": {\n",
    "                \"d_model_spectra\": 2048,\n",
    "                \"d_model_gaia\": 2048,\n",
    "                \"num_classes\": 55,\n",
    "                \"input_dim_spectra\": 3647,\n",
    "                \"input_dim_gaia\": 18,\n",
    "                \"token_dim_spectra\": 3647,  # 1 token\n",
    "                \"token_dim_gaia\": 18,       # 1 token\n",
    "                \"n_layers\": 10,\n",
    "                \"n_heads\": 8,\n",
    "                \"use_cross_attention\": True,\n",
    "                \"n_cross_attn_heads\": 8,\n",
    "                \"dropout\": 0.1\n",
    "            },\n",
    "            \"checkpoint\": \"Comparing_Mambas_Trans/transformer_1_token.pth\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Transformer_19_18token\",\n",
    "            \"model_class\": StarClassifierFusionTransformer,\n",
    "            \"params\": {\n",
    "                \"d_model_spectra\": 2048,\n",
    "                \"d_model_gaia\": 2048,\n",
    "                \"num_classes\": 55,\n",
    "                \"input_dim_spectra\": 3647,\n",
    "                \"input_dim_gaia\": 18,\n",
    "                \"token_dim_spectra\": 192,  # ~19 tokens\n",
    "                \"token_dim_gaia\": 1,       # 18 tokens\n",
    "                \"n_layers\": 10,\n",
    "                \"n_heads\": 8,\n",
    "                \"use_cross_attention\": True,\n",
    "                \"n_cross_attn_heads\": 8,\n",
    "                \"dropout\": 0.1\n",
    "            },\n",
    "            \"checkpoint\": \"Comparing_Mambas_Trans/transformer_balanced.pth\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Transformer_522_18token\",\n",
    "            \"model_class\": StarClassifierFusionTransformer,\n",
    "            \"params\": {\n",
    "                \"d_model_spectra\": 1536,\n",
    "                \"d_model_gaia\": 1536,\n",
    "                \"num_classes\": 55,\n",
    "                \"input_dim_spectra\": 3647,\n",
    "                \"input_dim_gaia\": 18,\n",
    "                \"token_dim_spectra\": 7,    # ~522 tokens\n",
    "                \"token_dim_gaia\": 1,       # 18 tokens\n",
    "                \"n_layers\": 10,\n",
    "                \"n_heads\": 8,\n",
    "                \"use_cross_attention\": True,\n",
    "                \"n_cross_attn_heads\": 8,\n",
    "                \"dropout\": 0.1\n",
    "            },\n",
    "            \"checkpoint\": \"Comparing_Mambas_Trans/transformer_max_tokens.pth\"\n",
    "        },\n",
    "        \n",
    "        # Mamba2 Tokenized Models\n",
    "        {\n",
    "            \"name\": \"Mamba2_1token\",\n",
    "            \"model_class\": StarClassifierFusionMambaTokenized,\n",
    "            \"params\": {\n",
    "                \"d_model_spectra\": 2048,\n",
    "                \"d_model_gaia\": 2048,\n",
    "                \"num_classes\": 55,\n",
    "                \"input_dim_spectra\": 3647,\n",
    "                \"input_dim_gaia\": 18,\n",
    "                \"token_dim_spectra\": 3647,  # 1 token\n",
    "                \"token_dim_gaia\": 18,       # 1 token\n",
    "                \"n_layers\": 20,\n",
    "                \"d_state\": 32,\n",
    "                \"d_conv\": 2,\n",
    "                \"expand\": 2,\n",
    "                \"use_cross_attention\": True,\n",
    "                \"n_cross_attn_heads\": 8\n",
    "            },\n",
    "            \"checkpoint\": \"Comparing_Mambas_Trans/mamba_1_token.pth\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Mamba2_19_18token\",\n",
    "            \"model_class\": StarClassifierFusionMambaTokenized,\n",
    "            \"params\": {\n",
    "                \"d_model_spectra\": 2048,\n",
    "                \"d_model_gaia\": 2048,\n",
    "                \"num_classes\": 55,\n",
    "                \"input_dim_spectra\": 3647,\n",
    "                \"input_dim_gaia\": 18,\n",
    "                \"token_dim_spectra\": 192,  # ~19 tokens\n",
    "                \"token_dim_gaia\": 1,       # 18 tokens\n",
    "                \"n_layers\": 20,\n",
    "                \"d_state\": 32,\n",
    "                \"d_conv\": 4,\n",
    "                \"expand\": 2,\n",
    "                \"use_cross_attention\": True,\n",
    "                \"n_cross_attn_heads\": 8\n",
    "            },\n",
    "            \"checkpoint\": \"Comparing_Mambas_Trans/mamba_balanced.pth\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Mamba2_522_18token\",\n",
    "            \"model_class\": StarClassifierFusionMambaTokenized,\n",
    "            \"params\": {\n",
    "                \"d_model_spectra\": 1536,\n",
    "                \"d_model_gaia\": 1536,\n",
    "                \"num_classes\": 55,\n",
    "                \"input_dim_spectra\": 3647,\n",
    "                \"input_dim_gaia\": 18,\n",
    "                \"token_dim_spectra\": 7,    # ~522 tokens\n",
    "                \"token_dim_gaia\": 1,       # 18 tokens\n",
    "                \"n_layers\": 20,\n",
    "                \"d_state\": 16,\n",
    "                \"d_conv\": 4,\n",
    "                \"expand\": 2,\n",
    "                \"use_cross_attention\": True,\n",
    "                \"n_cross_attn_heads\": 8\n",
    "            },\n",
    "            \"checkpoint\": \"Comparing_Mambas_Trans/mamba_max_tokens.pth\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Store results\n",
    "    results = {}\n",
    "    \n",
    "    # Evaluate each model\n",
    "    for config in model_configs:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Evaluating model: {config['name']}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Create model instance\n",
    "        model = config[\"model_class\"](**config[\"params\"])\n",
    "        \n",
    "        # Load checkpoint if exists\n",
    "        checkpoint_path = config[\"checkpoint\"]\n",
    "        if os.path.exists(checkpoint_path):\n",
    "            print(f\"Loading checkpoint from {checkpoint_path}\")\n",
    "            model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "        else:\n",
    "            print(f\"Checkpoint {checkpoint_path} not found. Skipping this model.\")\n",
    "            continue\n",
    "        \n",
    "        # Move model to device\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # Print model statistics\n",
    "        num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f\"Number of parameters: {num_params:,}\")\n",
    "        \n",
    "        # Calculate model size in MB\n",
    "        param_size = sum(p.nelement() * p.element_size() for p in model.parameters())\n",
    "        buffer_size = sum(b.nelement() * b.element_size() for b in model.buffers())\n",
    "        size_mb = (param_size + buffer_size) / (1024**2)\n",
    "        print(f\"Model size: {size_mb:.2f} MB\")\n",
    "        \n",
    "        # Evaluate model\n",
    "        metrics = evaluate_model(model, test_loader, device)\n",
    "        \n",
    "        # Add model info to metrics\n",
    "        metrics[\"model_name\"] = config[\"name\"]\n",
    "        metrics[\"num_parameters\"] = num_params\n",
    "        metrics[\"model_size_mb\"] = size_mb\n",
    "        \n",
    "        # Get token counts for analysis\n",
    "        spectra_tokens = (config[\"params\"][\"input_dim_spectra\"] + config[\"params\"][\"token_dim_spectra\"] - 1) // config[\"params\"][\"token_dim_spectra\"]\n",
    "        gaia_tokens = (config[\"params\"][\"input_dim_gaia\"] + config[\"params\"][\"token_dim_gaia\"] - 1) // config[\"params\"][\"token_dim_gaia\"]\n",
    "        metrics[\"spectra_tokens\"] = spectra_tokens\n",
    "        metrics[\"gaia_tokens\"] = gaia_tokens\n",
    "        metrics[\"total_tokens\"] = spectra_tokens + gaia_tokens\n",
    "        \n",
    "        # Print key metrics\n",
    "        print(\"\\nTest Metrics:\")\n",
    "        print(f\"  Loss: {metrics['avg_loss']:.4f}\")\n",
    "        print(f\"  Accuracy: {metrics['avg_accuracy']:.4f}\")\n",
    "        print(f\"  Micro F1: {metrics['micro_f1']:.4f}\")\n",
    "        print(f\"  Macro F1: {metrics['macro_f1']:.4f}\")\n",
    "        print(f\"  Weighted F1: {metrics['weighted_f1']:.4f}\")\n",
    "        print(f\"  Macro AUROC: {metrics.get('macro_auroc', 'N/A')}\")\n",
    "        \n",
    "        # Store results\n",
    "        results[config[\"name\"]] = metrics\n",
    "        \n",
    "        # Clear memory\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    # Save results to JSON\n",
    "    results_file = os.path.join(results_dir, \"model_comparison_results.json\")\n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    # Convert to DataFrame for easier analysis\n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    \n",
    "    # Save DataFrame to CSV\n",
    "    csv_file = os.path.join(results_dir, \"model_comparison_results.csv\")\n",
    "    results_df.to_csv(csv_file)\n",
    "    \n",
    "    # Create model family summary\n",
    "    model_families = {\n",
    "        \"MambaOut\": [m for m in results_df.index if m.startswith(\"MambaOut\")],\n",
    "        \"Transformer\": [m for m in results_df.index if m.startswith(\"Transformer\")],\n",
    "        \"Mamba2\": [m for m in results_df.index if m.startswith(\"Mamba2\")]\n",
    "    }\n",
    "    \n",
    "    family_results = {}\n",
    "    for family, models in model_families.items():\n",
    "        if models:\n",
    "            family_results[family] = results_df.loc[models].mean()\n",
    "    \n",
    "    family_df = pd.DataFrame.from_dict(family_results, orient='index')\n",
    "    family_csv = os.path.join(results_dir, \"model_family_summary.csv\")\n",
    "    family_df.to_csv(family_csv)\n",
    "    \n",
    "    # Create comparative visualizations\n",
    "    \n",
    "    # 1. Performance by model metrics bar chart\n",
    "    key_metrics = ['micro_f1', 'macro_f1', 'weighted_f1', 'macro_auroc']\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i, metric in enumerate(key_metrics):\n",
    "        if metric in results_df.columns:\n",
    "            plt.subplot(2, 2, i+1)\n",
    "            sns.barplot(x=results_df.index, y=results_df[metric])\n",
    "            plt.title(f\"{metric.replace('_', ' ').title()}\")\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.ylim(0, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, \"key_metrics_comparison.png\"))\n",
    "    \n",
    "    # 2. Performance vs Model Size scatter plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    for family, models in model_families.items():\n",
    "        if models:\n",
    "            sns.scatterplot(\n",
    "                x=results_df.loc[models, 'model_size_mb'], \n",
    "                y=results_df.loc[models, 'macro_f1'],\n",
    "                label=family,\n",
    "                s=100\n",
    "            )\n",
    "    \n",
    "    for i, model in enumerate(results_df.index):\n",
    "        plt.annotate(\n",
    "            model,\n",
    "            (results_df.loc[model, 'model_size_mb'], results_df.loc[model, 'macro_f1']),\n",
    "            xytext=(5, 5),\n",
    "            textcoords='offset points'\n",
    "        )\n",
    "    \n",
    "    plt.xlabel(\"Model Size (MB)\")\n",
    "    plt.ylabel(\"Macro F1 Score\")\n",
    "    plt.title(\"Model Performance vs Model Size\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.savefig(os.path.join(results_dir, \"performance_vs_size.png\"))\n",
    "    \n",
    "    # 3. Performance vs Number of Tokens scatter plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    for family, models in model_families.items():\n",
    "        if models:\n",
    "            sns.scatterplot(\n",
    "                x=results_df.loc[models, 'total_tokens'], \n",
    "                y=results_df.loc[models, 'macro_f1'],\n",
    "                label=family,\n",
    "                s=100\n",
    "            )\n",
    "    \n",
    "    for i, model in enumerate(results_df.index):\n",
    "        plt.annotate(\n",
    "            model,\n",
    "            (results_df.loc[model, 'total_tokens'], results_df.loc[model, 'macro_f1']),\n",
    "            xytext=(5, 5),\n",
    "            textcoords='offset points'\n",
    "        )\n",
    "    \n",
    "    plt.xscale('log')\n",
    "    plt.xlabel(\"Total Number of Tokens (log scale)\")\n",
    "    plt.ylabel(\"Macro F1 Score\")\n",
    "    plt.title(\"Model Performance vs Number of Tokens\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.savefig(os.path.join(results_dir, \"performance_vs_tokens.png\"))\n",
    "    \n",
    "    print(f\"\\nResults saved to {results_dir}/\")\n",
    "    print(f\"Summary: {family_csv}\")\n",
    "    \n",
    "    # Generate a text summary report\n",
    "    with open(os.path.join(results_dir, \"summary_report.txt\"), 'w') as f:\n",
    "        f.write(\"MODEL EVALUATION SUMMARY\\n\")\n",
    "        f.write(\"======================\\n\\n\")\n",
    "        \n",
    "        f.write(\"Best Models by Metric:\\n\")\n",
    "        for metric in ['micro_f1', 'macro_f1', 'weighted_f1', 'macro_auroc']:\n",
    "            if metric in results_df.columns:\n",
    "                best_model = results_df[metric].idxmax()\n",
    "                f.write(f\"  Best {metric}: {best_model} ({results_df.loc[best_model, metric]:.4f})\\n\")\n",
    "        \n",
    "        f.write(\"\\nModel Family Comparison:\\n\")\n",
    "        for family, metrics in family_results.items():\n",
    "            f.write(f\"  {family}:\\n\")\n",
    "            f.write(f\"    Macro F1: {metrics['macro_f1']:.4f}\\n\")\n",
    "            f.write(f\"    Average Size: {metrics['model_size_mb']:.2f} MB\\n\")\n",
    "        \n",
    "        f.write(\"\\nToken Configuration Analysis:\\n\")\n",
    "        token_configs = [\"1token\", \"19_18token\", \"522_18token\"]\n",
    "        for config in token_configs:\n",
    "            models = [m for m in results_df.index if config in m]\n",
    "            if models:\n",
    "                config_df = results_df.loc[models]\n",
    "                f.write(f\"  {config}:\\n\")\n",
    "                f.write(f\"    Average Macro F1: {config_df['macro_f1'].mean():.4f}\\n\")\n",
    "                f.write(f\"    Best Model: {config_df['macro_f1'].idxmax()} ({config_df['macro_f1'].max():.4f})\\n\")\n",
    "        \n",
    "        f.write(\"\\nDetailed Model Rankings:\\n\")\n",
    "        for rank, (model, metrics) in enumerate(results_df.sort_values('macro_f1', ascending=False).iterrows(), 1):\n",
    "            f.write(f\"  {rank}. {model}:\\n\")\n",
    "            f.write(f\"     Macro F1: {metrics['macro_f1']:.4f}\\n\")\n",
    "            f.write(f\"     Size: {metrics['model_size_mb']:.2f} MB\\n\")\n",
    "            f.write(f\"     Parameters: {metrics['num_parameters']:,}\\n\")\n",
    "            f.write(f\"     Token Config: {metrics['spectra_tokens']} spectra, {metrics['gaia_tokens']} gaia\\n\")\n",
    "    \n",
    "    print(f\"Summary report generated: {results_dir}/summary_report.txt\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
