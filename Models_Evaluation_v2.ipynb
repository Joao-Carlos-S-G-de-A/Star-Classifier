{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading datasets...\n",
      "Train samples: 286\n",
      "Val samples: 236\n",
      "Test samples: 258\n",
      "\n",
      "==================================================\n",
      "Evaluating model: MambaOut_1token\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'DropPath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 667\u001b[0m\n\u001b[1;32m    664\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummary report generated: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/summary_report.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 667\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 470\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# Create model instance\u001b[39;00m\n\u001b[0;32m--> 470\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_class\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparams\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# Load checkpoint if exists\u001b[39;00m\n\u001b[1;32m    473\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/Star-Classifier/Fusion_Models.py:322\u001b[0m, in \u001b[0;36mStarClassifierFusionMambaOut.__init__\u001b[0;34m(self, d_model_spectra, d_model_gaia, num_classes, input_dim_spectra, input_dim_gaia, token_dim_spectra, token_dim_gaia, n_layers, use_cross_attention, n_cross_attn_heads, d_conv, expand)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer_gaia \u001b[38;5;241m=\u001b[39m FeatureTokenizer(\n\u001b[1;32m    315\u001b[0m     input_dim\u001b[38;5;241m=\u001b[39minput_dim_gaia,\n\u001b[1;32m    316\u001b[0m     token_dim\u001b[38;5;241m=\u001b[39mtoken_dim_gaia,\n\u001b[1;32m    317\u001b[0m     d_model\u001b[38;5;241m=\u001b[39md_model_gaia\n\u001b[1;32m    318\u001b[0m )\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m# --- MambaOut for spectra ---\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmamba_spectra \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;241m*\u001b[39m[\u001b[43mSequenceMambaOut\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43md_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md_model_spectra\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43md_conv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md_conv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_layers)]\n\u001b[1;32m    329\u001b[0m )\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# --- MambaOut for gaia ---\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmamba_gaia \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;241m*\u001b[39m[SequenceMambaOut(\n\u001b[1;32m    334\u001b[0m         d_model\u001b[38;5;241m=\u001b[39md_model_gaia,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    339\u001b[0m     ) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_layers)]\n\u001b[1;32m    340\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Star-Classifier/Fusion_Models.py:240\u001b[0m, in \u001b[0;36mSequenceMambaOut.__init__\u001b[0;34m(self, d_model, d_conv, expand, depth, drop_path)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# Create a sequence of GatedCNNBlocks\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;241m*\u001b[39m[\u001b[43mGatedCNNBlock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43md_conv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md_conv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_path\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(depth)]\n\u001b[1;32m    246\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Star-Classifier/Fusion_Models.py:194\u001b[0m, in \u001b[0;36mGatedCNNBlock.__init__\u001b[0;34m(self, dim, d_conv, expand, drop_path)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConv1d(\n\u001b[1;32m    186\u001b[0m     in_channels\u001b[38;5;241m=\u001b[39mhidden,\n\u001b[1;32m    187\u001b[0m     out_channels\u001b[38;5;241m=\u001b[39mhidden, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    190\u001b[0m     groups\u001b[38;5;241m=\u001b[39mhidden\n\u001b[1;32m    191\u001b[0m )\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(hidden, dim)\n\u001b[0;32m--> 194\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path \u001b[38;5;241m=\u001b[39m \u001b[43mDropPath\u001b[49m(drop_path) \u001b[38;5;28;01mif\u001b[39;00m drop_path \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m nn\u001b[38;5;241m.\u001b[39mIdentity()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DropPath' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, hamming_loss, roc_auc_score, average_precision_score\n",
    "import os\n",
    "import json\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from timm.models.layers import DropPath\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# Import your model architectures\n",
    "from Fusion_Models import StarClassifierFusionMambaOut, StarClassifierFusionTransformer, StarClassifierFusionMambaTokenized\n",
    "\n",
    "class MultiModalBalancedMultiLabelDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A balanced multi-label dataset that returns (X_spectra, X_gaia, y).\n",
    "    It uses the same balancing strategy as `BalancedMultiLabelDataset`.\n",
    "    \"\"\"\n",
    "    def __init__(self, X_spectra, X_gaia, y, limit_per_label=201):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X_spectra (torch.Tensor): [num_samples, num_spectra_features]\n",
    "            X_gaia (torch.Tensor): [num_samples, num_gaia_features]\n",
    "            y (torch.Tensor): [num_samples, num_classes], multi-hot labels\n",
    "            limit_per_label (int): limit or target number of samples per label\n",
    "        \"\"\"\n",
    "        self.X_spectra = X_spectra\n",
    "        self.X_gaia = X_gaia\n",
    "        self.y = y\n",
    "        self.limit_per_label = limit_per_label\n",
    "        self.num_classes = y.shape[1]\n",
    "        self.indices = self.balance_classes()\n",
    "        \n",
    "    def balance_classes(self):\n",
    "        indices = []\n",
    "        class_counts = torch.sum(self.y, axis=0)\n",
    "        for cls in range(self.num_classes):\n",
    "            cls_indices = np.where(self.y[:, cls] == 1)[0]\n",
    "            if len(cls_indices) < self.limit_per_label:\n",
    "                if len(cls_indices) == 0:\n",
    "                    # No samples for this class\n",
    "                    continue\n",
    "                extra_indices = np.random.choice(\n",
    "                    cls_indices, self.limit_per_label - len(cls_indices), replace=True\n",
    "                )\n",
    "                cls_indices = np.concatenate([cls_indices, extra_indices])\n",
    "            elif len(cls_indices) > self.limit_per_label:\n",
    "                cls_indices = np.random.choice(cls_indices, self.limit_per_label, replace=False)\n",
    "            indices.extend(cls_indices)\n",
    "        indices = np.unique(indices)\n",
    "        np.random.shuffle(indices)\n",
    "        return indices\n",
    "\n",
    "    def re_sample(self):\n",
    "        self.indices = self.balance_classes()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        index = self.indices[idx]\n",
    "        return (\n",
    "            self.X_spectra[index],  # spectra features\n",
    "            self.X_gaia[index],     # gaia features\n",
    "            self.y[index],          # multi-hot labels\n",
    "        )\n",
    "    \n",
    "def calculate_class_weights(y):\n",
    "    if y.ndim > 1:  \n",
    "        class_counts = np.sum(y, axis=0)  \n",
    "    else:\n",
    "        class_counts = np.bincount(y)\n",
    "\n",
    "    total_samples = y.shape[0] if y.ndim > 1 else len(y)\n",
    "    class_counts = np.where(class_counts == 0, 1, class_counts)  # Prevent division by zero\n",
    "    class_weights = total_samples / (len(class_counts) * class_counts)\n",
    "    \n",
    "    return class_weights\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    metrics = {\n",
    "        \"micro_f1\": f1_score(y_true, y_pred, average='micro'),\n",
    "        \"macro_f1\": f1_score(y_true, y_pred, average='macro'),\n",
    "        \"weighted_f1\": f1_score(y_true, y_pred, average='weighted'),\n",
    "        \"micro_precision\": precision_score(y_true, y_pred, average='micro', zero_division=1),\n",
    "        \"macro_precision\": precision_score(y_true, y_pred, average='macro', zero_division=1),\n",
    "        \"weighted_precision\": precision_score(y_true, y_pred, average='weighted', zero_division=1),\n",
    "        \"micro_recall\": recall_score(y_true, y_pred, average='micro'),\n",
    "        \"macro_recall\": recall_score(y_true, y_pred, average='macro'),\n",
    "        \"weighted_recall\": recall_score(y_true, y_pred, average='weighted'),\n",
    "        \"hamming_loss\": hamming_loss(y_true, y_pred)\n",
    "    }\n",
    "    \n",
    "    # Check if there are at least two classes present in y_true\n",
    "    #if len(np.unique(y_true)) > 1:\n",
    "        #metrics[\"roc_auc\"] = roc_auc_score(y_true, y_pred, average='macro', multi_class='ovr')\n",
    "    #else:\n",
    "       # metrics[\"roc_auc\"] = None  # or you can set it to a default value or message\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Load and preprocess the data\"\"\"\n",
    "    print(\"Loading datasets...\")\n",
    "    \n",
    "    # Load classes\n",
    "    with open(\"Pickles/Updated_List_of_Classes_ubuntu.pkl\", \"rb\") as f:\n",
    "        classes = pickle.load(f)\n",
    "    \n",
    "    # Load train and test data\n",
    "    with open(\"Pickles/train_data_transformed_ubuntu.pkl\", \"rb\") as f:\n",
    "        X_train_full = pickle.load(f)\n",
    "    with open(\"Pickles/test_data_transformed_ubuntu.pkl\", \"rb\") as f:\n",
    "        X_test_full = pickle.load(f)\n",
    "    \n",
    "    # Extract labels\n",
    "    y_train_full = X_train_full[classes]\n",
    "    y_test = X_test_full[classes]\n",
    "    \n",
    "    # Drop labels from both datasets\n",
    "    X_train_full.drop(classes, axis=1, inplace=True)\n",
    "    X_test_full.drop(classes, axis=1, inplace=True)\n",
    "    \n",
    "    # Define Gaia columns\n",
    "    gaia_columns = [\"parallax\", \"ra\", \"dec\", \"ra_error\", \"dec_error\", \"parallax_error\", \n",
    "                   \"pmra\", \"pmdec\", \"pmra_error\", \"pmdec_error\", \"phot_g_mean_flux\", \n",
    "                   \"flagnopllx\", \"phot_g_mean_flux_error\", \"phot_bp_mean_flux\", \n",
    "                   \"phot_rp_mean_flux\", \"phot_bp_mean_flux_error\", \n",
    "                   \"phot_rp_mean_flux_error\", \"flagnoflux\"]\n",
    "    \n",
    "    # Split data into spectra and gaia parts\n",
    "    X_train_spectra = X_train_full.drop(columns={\"otype\", \"obsid\", *gaia_columns})\n",
    "    X_test_spectra = X_test_full.drop(columns={\"otype\", \"obsid\", *gaia_columns})\n",
    "    \n",
    "    X_train_gaia = X_train_full[gaia_columns]\n",
    "    X_test_gaia = X_test_full[gaia_columns]\n",
    "    \n",
    "    # Free up memory\n",
    "    del X_train_full, X_test_full\n",
    "    gc.collect()\n",
    "    \n",
    "    # Split training set into train and validation\n",
    "    X_train_spectra, X_val_spectra, X_train_gaia, X_val_gaia, y_train, y_val = train_test_split(\n",
    "        X_train_spectra, X_train_gaia, y_train_full, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Free memory\n",
    "    del y_train_full\n",
    "    gc.collect()\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_spectra_tensor = torch.tensor(X_train_spectra.values, dtype=torch.float32)\n",
    "    X_val_spectra_tensor = torch.tensor(X_val_spectra.values, dtype=torch.float32)\n",
    "    X_test_spectra_tensor = torch.tensor(X_test_spectra.values, dtype=torch.float32)\n",
    "    \n",
    "    X_train_gaia_tensor = torch.tensor(X_train_gaia.values, dtype=torch.float32)\n",
    "    X_val_gaia_tensor = torch.tensor(X_val_gaia.values, dtype=torch.float32)\n",
    "    X_test_gaia_tensor = torch.tensor(X_test_gaia.values, dtype=torch.float32)\n",
    "    \n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "    y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "    \n",
    "    return (\n",
    "        X_train_spectra_tensor, X_val_spectra_tensor, X_test_spectra_tensor,\n",
    "        X_train_gaia_tensor, X_val_gaia_tensor, X_test_gaia_tensor,\n",
    "        y_train_tensor, y_val_tensor, y_test_tensor\n",
    "    )\n",
    "\n",
    "def evaluate_model(model, test_loader, device='cuda'):\n",
    "    \"\"\"Evaluate a model on test data and return comprehensive metrics\"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "    y_true, y_pred, y_prob = [], [], []\n",
    "    \n",
    "    # Compute class weights for loss function\n",
    "    all_labels = []\n",
    "    for _, _, y_batch in test_loader:\n",
    "        all_labels.extend(y_batch.cpu().numpy())\n",
    "    \n",
    "    class_weights = calculate_class_weights(np.array(all_labels))\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights)\n",
    "    \n",
    "    # Evaluation loop\n",
    "    with torch.no_grad():\n",
    "        for X_spc, X_ga, y_batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            X_spc, X_ga, y_batch = X_spc.to(device), X_ga.to(device), y_batch.to(device)\n",
    "            outputs = model(X_spc, X_ga)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            test_loss += loss.item() * X_spc.size(0)\n",
    "            \n",
    "            probs = torch.sigmoid(outputs)\n",
    "            predicted = (probs > 0.5).float()\n",
    "            correct = (predicted == y_batch).float()\n",
    "            test_acc += correct.mean(dim=1).mean().item()\n",
    "\n",
    "            y_true.extend(y_batch.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "            y_prob.extend(probs.cpu().numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    y_true_array = np.array(y_true)\n",
    "    y_pred_array = np.array(y_pred)\n",
    "    y_prob_array = np.array(y_prob)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = calculate_metrics(y_true_array, y_pred_array)\n",
    "    \n",
    "    # Add average metrics\n",
    "    metrics[\"avg_loss\"] = test_loss / len(test_loader.dataset)\n",
    "    metrics[\"avg_accuracy\"] = test_acc / len(test_loader)\n",
    "    \n",
    "    # Calculate AUROC if possible\n",
    "    try:\n",
    "        class_aurocs = []\n",
    "        for i in range(y_true_array.shape[1]):\n",
    "            if len(np.unique(y_true_array[:, i])) > 1:\n",
    "                class_auroc = roc_auc_score(y_true_array[:, i], y_prob_array[:, i])\n",
    "                class_aurocs.append(class_auroc)\n",
    "        \n",
    "        if class_aurocs:\n",
    "            metrics[\"macro_auroc\"] = np.mean(class_aurocs)\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating AUROC: {e}\")\n",
    "        metrics[\"macro_auroc\"] = float('nan')\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def main():\n",
    "    # Create results directory\n",
    "    results_dir = f\"model_comparison_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    os.makedirs(\"Models\", exist_ok=True)\n",
    "    \n",
    "    # Set device\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load data\n",
    "    (X_train_spectra, X_val_spectra, X_test_spectra,\n",
    "     X_train_gaia, X_val_gaia, X_test_gaia,\n",
    "     y_train, y_val, y_test) = load_data()\n",
    "    \n",
    "    # Create datasets and dataloaders\n",
    "    batch_size = 16\n",
    "    batch_limit = int(batch_size / 2.5)\n",
    "    \n",
    "    train_dataset = MultiModalBalancedMultiLabelDataset(\n",
    "        X_train_spectra, X_train_gaia, y_train, limit_per_label=batch_limit\n",
    "    )\n",
    "    val_dataset = MultiModalBalancedMultiLabelDataset(\n",
    "        X_val_spectra, X_val_gaia, y_val, limit_per_label=batch_limit\n",
    "    )\n",
    "    test_dataset = MultiModalBalancedMultiLabelDataset(\n",
    "        X_test_spectra, X_test_gaia, y_test, limit_per_label=batch_limit\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    print(f\"Train samples: {len(train_dataset)}\")\n",
    "    print(f\"Val samples: {len(val_dataset)}\")\n",
    "    print(f\"Test samples: {len(test_dataset)}\")\n",
    "    # Define model configurations to evaluate\n",
    "    model_configs = [\n",
    "        # MambaOut Models\n",
    "        {\n",
    "            \"name\": \"MambaOut_1token\",\n",
    "            \"model_class\": StarClassifierFusionMambaOut,\n",
    "            \"params\": {\n",
    "                \"d_model_spectra\": 2048,\n",
    "                \"d_model_gaia\": 2048,\n",
    "                \"num_classes\": 55,\n",
    "                \"input_dim_spectra\": 3647,\n",
    "                \"input_dim_gaia\": 18,\n",
    "                \"token_dim_spectra\": 3647,  # 1 token\n",
    "                \"token_dim_gaia\": 18,       # 1 token\n",
    "                \"n_layers\": 20,\n",
    "                \"d_conv\": 1,\n",
    "                \"use_cross_attention\": True,\n",
    "                \"n_cross_attn_heads\": 8\n",
    "            },\n",
    "            \"checkpoint\": \"Models/model_fusion_mambaoutv3.pth\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"MambaOut_19_18token\",\n",
    "            \"model_class\": StarClassifierFusionMambaOut,\n",
    "            \"params\": {\n",
    "                \"d_model_spectra\": 2048,\n",
    "                \"d_model_gaia\": 2048,\n",
    "                \"num_classes\": 55,\n",
    "                \"input_dim_spectra\": 3647,\n",
    "                \"input_dim_gaia\": 18,\n",
    "                \"token_dim_spectra\": 192,  # ~19 tokens\n",
    "                \"token_dim_gaia\": 1,       # 18 tokens\n",
    "                \"n_layers\": 20,\n",
    "                \"d_conv\": 4,\n",
    "                \"use_cross_attention\": True,\n",
    "                \"n_cross_attn_heads\": 8\n",
    "            },\n",
    "            \"checkpoint\": \"Models/model_fusion_MambaOut_18_19_v2.pth\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"MambaOut_522_18token\",\n",
    "            \"model_class\": StarClassifierFusionMambaOut,\n",
    "            \"params\": {\n",
    "                \"d_model_spectra\": 1536,\n",
    "                \"d_model_gaia\": 1536,\n",
    "                \"num_classes\": 55,\n",
    "                \"input_dim_spectra\": 3647,\n",
    "                \"input_dim_gaia\": 18,\n",
    "                \"token_dim_spectra\": 7,    # ~522 tokens\n",
    "                \"token_dim_gaia\": 1,       # 18 tokens\n",
    "                \"n_layers\": 20,\n",
    "                \"d_conv\": 32,\n",
    "                \"use_cross_attention\": True,\n",
    "                \"n_cross_attn_heads\": 8\n",
    "            },\n",
    "            \"checkpoint\": \"Models/model_fusion_MambaOut_Many_tokens.pth\"\n",
    "        },\n",
    "        \n",
    "        # Transformer Models\n",
    "        {\n",
    "            \"name\": \"Transformer_1token\",\n",
    "            \"model_class\": StarClassifierFusionTransformer,\n",
    "            \"params\": {\n",
    "                \"d_model_spectra\": 2048,\n",
    "                \"d_model_gaia\": 2048,\n",
    "                \"num_classes\": 55,\n",
    "                \"input_dim_spectra\": 3647,\n",
    "                \"input_dim_gaia\": 18,\n",
    "                \"token_dim_spectra\": 3647,  # 1 token\n",
    "                \"token_dim_gaia\": 18,       # 1 token\n",
    "                \"n_layers\": 10,\n",
    "                \"n_heads\": 8,\n",
    "                \"use_cross_attention\": True,\n",
    "                \"n_cross_attn_heads\": 8,\n",
    "                \"dropout\": 0.1\n",
    "            },\n",
    "            \"checkpoint\": \"Models/model_fusion_transformer_1token_v2.pth\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Transformer_19_18token\",\n",
    "            \"model_class\": StarClassifierFusionTransformer,\n",
    "            \"params\": {\n",
    "                \"d_model_spectra\": 2048,\n",
    "                \"d_model_gaia\": 2048,\n",
    "                \"num_classes\": 55,\n",
    "                \"input_dim_spectra\": 3647,\n",
    "                \"input_dim_gaia\": 18,\n",
    "                \"token_dim_spectra\": 192,  # ~19 tokens\n",
    "                \"token_dim_gaia\": 1,       # 18 tokens\n",
    "                \"n_layers\": 10,\n",
    "                \"n_heads\": 8,\n",
    "                \"use_cross_attention\": True,\n",
    "                \"n_cross_attn_heads\": 8,\n",
    "                \"dropout\": 0.1\n",
    "            },\n",
    "            \"checkpoint\": \"Models/model_fusion_transformer_tokenized.pth\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Transformer_522_18token\",\n",
    "            \"model_class\": StarClassifierFusionTransformer,\n",
    "            \"params\": {\n",
    "                \"d_model_spectra\": 1536,\n",
    "                \"d_model_gaia\": 1536,\n",
    "                \"num_classes\": 55,\n",
    "                \"input_dim_spectra\": 3647,\n",
    "                \"input_dim_gaia\": 18,\n",
    "                \"token_dim_spectra\": 7,    # ~522 tokens\n",
    "                \"token_dim_gaia\": 1,       # 18 tokens\n",
    "                \"n_layers\": 10,\n",
    "                \"n_heads\": 8,\n",
    "                \"use_cross_attention\": True,\n",
    "                \"n_cross_attn_heads\": 8,\n",
    "                \"dropout\": 0.1\n",
    "            },\n",
    "            \"checkpoint\": \"Models/model_fusion_transformer_tokenized_many_tokens.pth\"\n",
    "        },\n",
    "        \n",
    "        # Mamba2 Tokenized Models\n",
    "        {\n",
    "            \"name\": \"Mamba2_1token\",\n",
    "            \"model_class\": StarClassifierFusionMambaTokenized,\n",
    "            \"params\": {\n",
    "                \"d_model_spectra\": 2048,\n",
    "                \"d_model_gaia\": 2048,\n",
    "                \"num_classes\": 55,\n",
    "                \"input_dim_spectra\": 3647,\n",
    "                \"input_dim_gaia\": 18,\n",
    "                \"token_dim_spectra\": 3647,  # 1 token\n",
    "                \"token_dim_gaia\": 18,       # 1 token\n",
    "                \"n_layers\": 20,\n",
    "                \"d_state\": 32,\n",
    "                \"d_conv\": 2,\n",
    "                \"expand\": 2,\n",
    "                \"use_cross_attention\": True,\n",
    "                \"n_cross_attn_heads\": 8\n",
    "            },\n",
    "            \"checkpoint\": \"Models/model_fusion_mamba_1_token.pth\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Mamba2_19_18token\",\n",
    "            \"model_class\": StarClassifierFusionMambaTokenized,\n",
    "            \"params\": {\n",
    "                \"d_model_spectra\": 2048,\n",
    "                \"d_model_gaia\": 2048,\n",
    "                \"num_classes\": 55,\n",
    "                \"input_dim_spectra\": 3647,\n",
    "                \"input_dim_gaia\": 18,\n",
    "                \"token_dim_spectra\": 192,  # ~19 tokens\n",
    "                \"token_dim_gaia\": 1,       # 18 tokens\n",
    "                \"n_layers\": 20,\n",
    "                \"d_state\": 32,\n",
    "                \"d_conv\": 4,\n",
    "                \"expand\": 2,\n",
    "                \"use_cross_attention\": True,\n",
    "                \"n_cross_attn_heads\": 8\n",
    "            },\n",
    "            \"checkpoint\": \"Models/model_fusion_mamba_19_18.pth\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Mamba2_522_18token\",\n",
    "            \"model_class\": StarClassifierFusionMambaTokenized,\n",
    "            \"params\": {\n",
    "                \"d_model_spectra\": 1536,\n",
    "                \"d_model_gaia\": 1536,\n",
    "                \"num_classes\": 55,\n",
    "                \"input_dim_spectra\": 3647,\n",
    "                \"input_dim_gaia\": 18,\n",
    "                \"token_dim_spectra\": 7,    # ~522 tokens\n",
    "                \"token_dim_gaia\": 1,       # 18 tokens\n",
    "                \"n_layers\": 20,\n",
    "                \"d_state\": 16,\n",
    "                \"d_conv\": 4,\n",
    "                \"expand\": 2,\n",
    "                \"use_cross_attention\": True,\n",
    "                \"n_cross_attn_heads\": 8\n",
    "            },\n",
    "            \"checkpoint\": \"Models/model_fusion_mamba_maxtokens.pth\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Store results\n",
    "    results = {}\n",
    "    \n",
    "    # Evaluate each model\n",
    "    for config in model_configs:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Evaluating model: {config['name']}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Create model instance\n",
    "        model = config[\"model_class\"](**config[\"params\"])\n",
    "        \n",
    "        # Load checkpoint if exists\n",
    "        checkpoint_path = config[\"checkpoint\"]\n",
    "        if os.path.exists(checkpoint_path):\n",
    "            print(f\"Loading checkpoint from {checkpoint_path}\")\n",
    "            model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "        else:\n",
    "            print(f\"Checkpoint {checkpoint_path} not found. Skipping this model.\")\n",
    "            continue\n",
    "        \n",
    "        # Move model to device\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # Print model statistics\n",
    "        num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f\"Number of parameters: {num_params:,}\")\n",
    "        \n",
    "        # Calculate model size in MB\n",
    "        param_size = sum(p.nelement() * p.element_size() for p in model.parameters())\n",
    "        buffer_size = sum(b.nelement() * b.element_size() for b in model.buffers())\n",
    "        size_mb = (param_size + buffer_size) / (1024**2)\n",
    "        print(f\"Model size: {size_mb:.2f} MB\")\n",
    "        \n",
    "        # Evaluate model\n",
    "        metrics = evaluate_model(model, test_loader, device)\n",
    "        \n",
    "        # Add model info to metrics\n",
    "        metrics[\"model_name\"] = config[\"name\"]\n",
    "        metrics[\"num_parameters\"] = num_params\n",
    "        metrics[\"model_size_mb\"] = size_mb\n",
    "        \n",
    "        # Get token counts for analysis\n",
    "        spectra_tokens = (config[\"params\"][\"input_dim_spectra\"] + config[\"params\"][\"token_dim_spectra\"] - 1) // config[\"params\"][\"token_dim_spectra\"]\n",
    "        gaia_tokens = (config[\"params\"][\"input_dim_gaia\"] + config[\"params\"][\"token_dim_gaia\"] - 1) // config[\"params\"][\"token_dim_gaia\"]\n",
    "        metrics[\"spectra_tokens\"] = spectra_tokens\n",
    "        metrics[\"gaia_tokens\"] = gaia_tokens\n",
    "        metrics[\"total_tokens\"] = spectra_tokens + gaia_tokens\n",
    "        \n",
    "        # Print key metrics\n",
    "        print(\"\\nTest Metrics:\")\n",
    "        print(f\"  Loss: {metrics['avg_loss']:.4f}\")\n",
    "        print(f\"  Accuracy: {metrics['avg_accuracy']:.4f}\")\n",
    "        print(f\"  Micro F1: {metrics['micro_f1']:.4f}\")\n",
    "        print(f\"  Macro F1: {metrics['macro_f1']:.4f}\")\n",
    "        print(f\"  Weighted F1: {metrics['weighted_f1']:.4f}\")\n",
    "        print(f\"  Macro AUROC: {metrics.get('macro_auroc', 'N/A')}\")\n",
    "        \n",
    "        # Store results\n",
    "        results[config[\"name\"]] = metrics\n",
    "        \n",
    "        # Clear memory\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    # Save results to JSON\n",
    "    results_file = os.path.join(results_dir, \"model_comparison_results.json\")\n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    # Convert to DataFrame for easier analysis\n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    \n",
    "    # Save DataFrame to CSV\n",
    "    csv_file = os.path.join(results_dir, \"model_comparison_results.csv\")\n",
    "    results_df.to_csv(csv_file)\n",
    "    \n",
    "    # Create model family summary\n",
    "    model_families = {\n",
    "        \"MambaOut\": [m for m in results_df.index if m.startswith(\"MambaOut\")],\n",
    "        \"Transformer\": [m for m in results_df.index if m.startswith(\"Transformer\")],\n",
    "        \"Mamba2\": [m for m in results_df.index if m.startswith(\"Mamba2\")]\n",
    "    }\n",
    "    \n",
    "    family_results = {}\n",
    "    for family, models in model_families.items():\n",
    "        if models:\n",
    "            family_results[family] = results_df.loc[models].mean()\n",
    "    \n",
    "    family_df = pd.DataFrame.from_dict(family_results, orient='index')\n",
    "    family_csv = os.path.join(results_dir, \"model_family_summary.csv\")\n",
    "    family_df.to_csv(family_csv)\n",
    "    \n",
    "    # Create comparative visualizations\n",
    "    \n",
    "    # 1. Performance by model metrics bar chart\n",
    "    key_metrics = ['micro_f1', 'macro_f1', 'weighted_f1', 'macro_auroc']\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i, metric in enumerate(key_metrics):\n",
    "        if metric in results_df.columns:\n",
    "            plt.subplot(2, 2, i+1)\n",
    "            sns.barplot(x=results_df.index, y=results_df[metric])\n",
    "            plt.title(f\"{metric.replace('_', ' ').title()}\")\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.ylim(0, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, \"key_metrics_comparison.png\"))\n",
    "    \n",
    "    # 2. Performance vs Model Size scatter plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    for family, models in model_families.items():\n",
    "        if models:\n",
    "            sns.scatterplot(\n",
    "                x=results_df.loc[models, 'model_size_mb'], \n",
    "                y=results_df.loc[models, 'macro_f1'],\n",
    "                label=family,\n",
    "                s=100\n",
    "            )\n",
    "    \n",
    "    for i, model in enumerate(results_df.index):\n",
    "        plt.annotate(\n",
    "            model,\n",
    "            (results_df.loc[model, 'model_size_mb'], results_df.loc[model, 'macro_f1']),\n",
    "            xytext=(5, 5),\n",
    "            textcoords='offset points'\n",
    "        )\n",
    "    \n",
    "    plt.xlabel(\"Model Size (MB)\")\n",
    "    plt.ylabel(\"Macro F1 Score\")\n",
    "    plt.title(\"Model Performance vs Model Size\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.savefig(os.path.join(results_dir, \"performance_vs_size.png\"))\n",
    "    \n",
    "    # 3. Performance vs Number of Tokens scatter plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    for family, models in model_families.items():\n",
    "        if models:\n",
    "            sns.scatterplot(\n",
    "                x=results_df.loc[models, 'total_tokens'], \n",
    "                y=results_df.loc[models, 'macro_f1'],\n",
    "                label=family,\n",
    "                s=100\n",
    "            )\n",
    "    \n",
    "    for i, model in enumerate(results_df.index):\n",
    "        plt.annotate(\n",
    "            model,\n",
    "            (results_df.loc[model, 'total_tokens'], results_df.loc[model, 'macro_f1']),\n",
    "            xytext=(5, 5),\n",
    "            textcoords='offset points'\n",
    "        )\n",
    "    \n",
    "    plt.xscale('log')\n",
    "    plt.xlabel(\"Total Number of Tokens (log scale)\")\n",
    "    plt.ylabel(\"Macro F1 Score\")\n",
    "    plt.title(\"Model Performance vs Number of Tokens\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.savefig(os.path.join(results_dir, \"performance_vs_tokens.png\"))\n",
    "    \n",
    "    print(f\"\\nResults saved to {results_dir}/\")\n",
    "    print(f\"Summary: {family_csv}\")\n",
    "    \n",
    "    # Generate a text summary report\n",
    "    with open(os.path.join(results_dir, \"summary_report.txt\"), 'w') as f:\n",
    "        f.write(\"MODEL EVALUATION SUMMARY\\n\")\n",
    "        f.write(\"======================\\n\\n\")\n",
    "        \n",
    "        f.write(\"Best Models by Metric:\\n\")\n",
    "        for metric in ['micro_f1', 'macro_f1', 'weighted_f1', 'macro_auroc']:\n",
    "            if metric in results_df.columns:\n",
    "                best_model = results_df[metric].idxmax()\n",
    "                f.write(f\"  Best {metric}: {best_model} ({results_df.loc[best_model, metric]:.4f})\\n\")\n",
    "        \n",
    "        f.write(\"\\nModel Family Comparison:\\n\")\n",
    "        for family, metrics in family_results.items():\n",
    "            f.write(f\"  {family}:\\n\")\n",
    "            f.write(f\"    Macro F1: {metrics['macro_f1']:.4f}\\n\")\n",
    "            f.write(f\"    Average Size: {metrics['model_size_mb']:.2f} MB\\n\")\n",
    "        \n",
    "        f.write(\"\\nToken Configuration Analysis:\\n\")\n",
    "        token_configs = [\"1token\", \"19_18token\", \"522_18token\"]\n",
    "        for config in token_configs:\n",
    "            models = [m for m in results_df.index if config in m]\n",
    "            if models:\n",
    "                config_df = results_df.loc[models]\n",
    "                f.write(f\"  {config}:\\n\")\n",
    "                f.write(f\"    Average Macro F1: {config_df['macro_f1'].mean():.4f}\\n\")\n",
    "                f.write(f\"    Best Model: {config_df['macro_f1'].idxmax()} ({config_df['macro_f1'].max():.4f})\\n\")\n",
    "        \n",
    "        f.write(\"\\nDetailed Model Rankings:\\n\")\n",
    "        for rank, (model, metrics) in enumerate(results_df.sort_values('macro_f1', ascending=False).iterrows(), 1):\n",
    "            f.write(f\"  {rank}. {model}:\\n\")\n",
    "            f.write(f\"     Macro F1: {metrics['macro_f1']:.4f}\\n\")\n",
    "            f.write(f\"     Size: {metrics['model_size_mb']:.2f} MB\\n\")\n",
    "            f.write(f\"     Parameters: {metrics['num_parameters']:,}\\n\")\n",
    "            f.write(f\"     Token Config: {metrics['spectra_tokens']} spectra, {metrics['gaia_tokens']} gaia\\n\")\n",
    "    \n",
    "    print(f\"Summary report generated: {results_dir}/summary_report.txt\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
