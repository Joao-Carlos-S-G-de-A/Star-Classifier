{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(binary) before removing bad lamost spectra: 399\n",
      "len(binary) after removing bad lamost spectra: 381\n",
      "len(star) before removing bad lamost spectra: 400\n",
      "len(star) after removing bad lamost spectra: 386\n",
      "len(gal) before removing bad lamost spectra: 399\n",
      "len(gal) after removing bad lamost spectra: 382\n",
      "len(agn) before removing bad lamost spectra: 400\n",
      "len(agn) after removing bad lamost spectra: 391\n",
      "mkdir: cannot create directory ‘Pickles/vcleaned4’: File exists\n"
     ]
    }
   ],
   "source": [
    "# Get gaia pkl \n",
    "vagngaia = pd.read_pickle(\"Pickles/vcleaned3/agn_gaia.pkl\")\n",
    "vbingaia = pd.read_pickle(\"Pickles/vcleaned3/bin_gaia.pkl\")\n",
    "vstargaia = pd.read_pickle(\"Pickles/vcleaned3/star_gaia.pkl\")\n",
    "vgalgaia = pd.read_pickle(\"Pickles/vcleaned3/gal_gaia.pkl\")\n",
    "\n",
    "# Get obsid of bad lamost spectra and make it all int 64\n",
    "bad_lamost = pd.read_pickle(\"Pickles/drops/all_lamost.pkl\")\n",
    "bad_lamost = list(map(int, bad_lamost))\n",
    "\n",
    "# remove bad lamost spectra from gaia dataframes whose obsid is in bad_lamost\n",
    "print(\"len(binary) before removing bad lamost spectra:\", len(vbingaia))\n",
    "vbingaia = vbingaia[~vbingaia[\"obsid\"].isin(bad_lamost)]\n",
    "print(\"len(binary) after removing bad lamost spectra:\", len(vbingaia))\n",
    "\n",
    "print(\"len(star) before removing bad lamost spectra:\", len(vstargaia))\n",
    "vstargaia = vstargaia[~vstargaia[\"obsid\"].isin(bad_lamost)]\n",
    "print(\"len(star) after removing bad lamost spectra:\", len(vstargaia))\n",
    "\n",
    "print(\"len(gal) before removing bad lamost spectra:\", len(vgalgaia))\n",
    "vgalgaia = vgalgaia[~vgalgaia[\"obsid\"].isin(bad_lamost)]\n",
    "print(\"len(gal) after removing bad lamost spectra:\", len(vgalgaia))\n",
    "\n",
    "print(\"len(agn) before removing bad lamost spectra:\", len(vagngaia))\n",
    "vagngaia = vagngaia[~vagngaia[\"obsid\"].isin(bad_lamost)]\n",
    "print(\"len(agn) after removing bad lamost spectra:\", len(vagngaia))\n",
    "\n",
    "# Make the folder for the cleaned dataframes\n",
    "!mkdir Pickles/vcleaned4\n",
    "\n",
    "# Save the cleaned dataframes\n",
    "vbingaia.to_pickle(\"Pickles/vcleaned4/bin_gaia.pkl\")\n",
    "vstargaia.to_pickle(\"Pickles/vcleaned4/star_gaia.pkl\")\n",
    "vgalgaia.to_pickle(\"Pickles/vcleaned4/gal_gaia.pkl\")\n",
    "vagngaia.to_pickle(\"Pickles/vcleaned4/agn_gaia.pkl\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lamost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GALAXIES: Number of rows before dropping: 383 and after dropping: 383\n",
      "BINARY STARS: Number of rows before dropping: 381 and after dropping: 381\n",
      "AGNs: Number of rows before dropping: 391 and after dropping: 391\n",
      "STARS: Number of rows before dropping: 386 and after dropping: 386\n",
      "Total number of rows removed: 0 out of 236\n"
     ]
    }
   ],
   "source": [
    "# open the pkl file with the list of files to drop\n",
    "nan_gaia = pd.read_pickle(\"Pickles/drops/gaiaall.pkl\")\n",
    "num_to_remove = len(nan_gaia)\n",
    "num_removed = 0\n",
    "\n",
    "\n",
    "# Training dataset\n",
    "# GALAXIES\n",
    "df = pd.read_pickle('Pickles/lmst/interpolated_data/val_gal.pkl')\n",
    "lenghtpre = len(df)\n",
    "df = df[~df['file_name'].isin(nan_gaia)]    \n",
    "print(f\"GALAXIES: Number of rows before dropping: {lenghtpre} and after dropping: {len(df)}\")\n",
    "num_removed += lenghtpre - len(df)\n",
    "df.to_pickle('Pickles/lmst/interpolated_data/val_gal2.pkl')\n",
    "\n",
    "# BINARY STARS\n",
    "df = pd.read_pickle('Pickles/lmst/interpolated_data/val_bin.pkl')\n",
    "lenghtpre = len(df)\n",
    "df = df[~df['file_name'].isin(nan_gaia)]\n",
    "print(f\"BINARY STARS: Number of rows before dropping: {lenghtpre} and after dropping: {len(df)}\")\n",
    "num_removed += lenghtpre - len(df)\n",
    "df.to_pickle('Pickles/lmst/interpolated_data/val_bin2.pkl')\n",
    "\n",
    "# AGNs\n",
    "df = pd.read_pickle('Pickles/lmst/interpolated_data/val_agn.pkl')\n",
    "lenghtpre = len(df)\n",
    "df = df[~df['file_name'].isin(nan_gaia)]\n",
    "print(f\"AGNs: Number of rows before dropping: {lenghtpre} and after dropping: {len(df)}\")\n",
    "num_removed += lenghtpre - len(df)\n",
    "df.to_pickle('Pickles/lmst/interpolated_data/val_agn2.pkl')\n",
    "\n",
    "# STARS\n",
    "df = pd.read_pickle('Pickles/lmst/interpolated_data/val_star.pkl')\n",
    "lenghtpre = len(df)\n",
    "df = df[~df['file_name'].isin(nan_gaia)]\n",
    "print(f\"STARS: Number of rows before dropping: {lenghtpre} and after dropping: {len(df)}\")\n",
    "num_removed += lenghtpre - len(df)\n",
    "print(f\"Total number of rows removed: {num_removed} out of {num_to_remove}\")\n",
    "df.to_pickle('Pickles/lmst/interpolated_data/val_star2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final: Remove obsids that do not match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches in binary: 381\n",
      "Number of non-matches in binary: 0\n",
      "Number of matches in star: 386\n",
      "Number of non-matches in star: 0\n",
      "Number of matches in gal: 382\n",
      "Number of non-matches in gal: 0\n",
      "Number of matches in agn: 391\n",
      "Number of non-matches in agn: 0\n"
     ]
    }
   ],
   "source": [
    "# load the gaia dataframes to match\n",
    "vbingaia = pd.read_pickle(\"Pickles/vcleaned4/bin_gaia.pkl\")\n",
    "vstargaia = pd.read_pickle(\"Pickles/vcleaned4/star_gaia.pkl\")\n",
    "vgalgaia = pd.read_pickle(\"Pickles/vcleaned4/gal_gaia.pkl\")\n",
    "vagngaia = pd.read_pickle(\"Pickles/vcleaned4/agn_gaia.pkl\")\n",
    "\n",
    "# load the lamost dataframes to match\n",
    "vbinlamost = pd.read_pickle(\"Pickles/lmst/interpolated_data/val_bin2.pkl\")\n",
    "vstarlamost = pd.read_pickle(\"Pickles/lmst/interpolated_data/val_star2.pkl\")\n",
    "vgallamost = pd.read_pickle(\"Pickles/lmst/interpolated_data/val_gal2.pkl\")\n",
    "vagnlamost = pd.read_pickle(\"Pickles/lmst/interpolated_data/val_agn2.pkl\")\n",
    "\n",
    "# rename the file_name column to obsid to match the column name in the gaia dataframe\n",
    "vbinlamost.rename(columns={\"file_name\": \"obsid\"}, inplace=True)\n",
    "vstarlamost.rename(columns={\"file_name\": \"obsid\"}, inplace=True)\n",
    "vgallamost.rename(columns={\"file_name\": \"obsid\"}, inplace=True)\n",
    "vagnlamost.rename(columns={\"file_name\": \"obsid\"}, inplace=True)\n",
    "\n",
    "# convert the obsid column to int64 to match the column in the gaia dataframe\n",
    "vbinlamost[\"obsid\"] = vbinlamost[\"obsid\"].astype(np.int64)\n",
    "vstarlamost[\"obsid\"] = vstarlamost[\"obsid\"].astype(np.int64)\n",
    "vgallamost[\"obsid\"] = vgallamost[\"obsid\"].astype(np.int64)\n",
    "vagnlamost[\"obsid\"] = vagnlamost[\"obsid\"].astype(np.int64)\n",
    "\n",
    "\n",
    "# match the dataframes and count the number of matches and non-matches\n",
    "matchedbin = pd.merge(vbingaia, vbinlamost, on=\"obsid\", how=\"inner\")\n",
    "print(\"Number of matches in binary:\", len(matchedbin))\n",
    "print(\"Number of non-matches in binary:\", len(vbingaia) - len(matchedbin))\n",
    "\n",
    "matchedstar = pd.merge(vstargaia, vstarlamost, on=\"obsid\", how=\"inner\")\n",
    "print(\"Number of matches in star:\", len(matchedstar))\n",
    "print(\"Number of non-matches in star:\", len(vstargaia) - len(matchedstar))\n",
    "\n",
    "matchedgal = pd.merge(vgalgaia, vgallamost, on=\"obsid\", how=\"inner\")\n",
    "print(\"Number of matches in gal:\", len(matchedgal))\n",
    "print(\"Number of non-matches in gal:\", len(vgalgaia) - len(matchedgal))\n",
    "\n",
    "matchedagn = pd.merge(vagngaia, vagnlamost, on=\"obsid\", how=\"inner\")\n",
    "print(\"Number of matches in agn:\", len(matchedagn))\n",
    "print(\"Number of non-matches in agn:\", len(vagngaia) - len(matchedagn))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the folder for the cleaned dataframes\n",
    "!mkdir Pickles/combinedgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the combined dataframes\n",
    "matchedbin.to_pickle(\"Pickles/fusionv0/vbin.pkl\")\n",
    "matchedstar.to_pickle(\"Pickles/fusionv0/vstar.pkl\")\n",
    "matchedgal.to_pickle(\"Pickles/fusionv0/vgal.pkl\")\n",
    "matchedagn.to_pickle(\"Pickles/fusionv0/vagn.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(binary) before removing bad lamost spectra: 40486\n",
      "len(binary) after removing bad lamost spectra: 40486\n",
      "len(star) before removing bad lamost spectra: 83055\n",
      "len(star) after removing bad lamost spectra: 83055\n",
      "len(gal) before removing bad lamost spectra: 1620\n",
      "len(gal) after removing bad lamost spectra: 1620\n",
      "len(agn) before removing bad lamost spectra: 35806\n",
      "len(agn) after removing bad lamost spectra: 35806\n"
     ]
    }
   ],
   "source": [
    "# Doing the same for the training data\n",
    "# Get gaia pkl\n",
    "tagngaia = pd.read_pickle(\"Pickles/tcleaned3/agn_gaia.pkl\")\n",
    "tbingaia = pd.read_pickle(\"Pickles/tcleaned3/bin_gaia.pkl\")\n",
    "tstargaia = pd.read_pickle(\"Pickles/tcleaned3/star_gaia.pkl\")\n",
    "tgalgaia = pd.read_pickle(\"Pickles/tcleaned3/gal_gaia.pkl\")\n",
    "\n",
    "# Get obsid of bad lamost spectra and make it all int 64\n",
    "bad_lamost = pd.read_pickle(\"Pickles/drops/all_lamost.pkl\")\n",
    "bad_lamost = list(map(int, bad_lamost))\n",
    "\n",
    "# remove bad lamost spectra from gaia dataframes whose obsid is in bad_lamost\n",
    "print(\"len(binary) before removing bad lamost spectra:\", len(tbingaia))\n",
    "tbingaia = tbingaia[~tbingaia[\"obsid\"].isin(bad_lamost)]\n",
    "print(\"len(binary) after removing bad lamost spectra:\", len(tbingaia))\n",
    "\n",
    "print(\"len(star) before removing bad lamost spectra:\", len(tstargaia))\n",
    "tstargaia = tstargaia[~tstargaia[\"obsid\"].isin(bad_lamost)]\n",
    "print(\"len(star) after removing bad lamost spectra:\", len(tstargaia))\n",
    "\n",
    "print(\"len(gal) before removing bad lamost spectra:\", len(tgalgaia))\n",
    "tgalgaia = tgalgaia[~tgalgaia[\"obsid\"].isin(bad_lamost)]\n",
    "print(\"len(gal) after removing bad lamost spectra:\", len(tgalgaia))\n",
    "\n",
    "print(\"len(agn) before removing bad lamost spectra:\", len(tagngaia))\n",
    "tagngaia = tagngaia[~tagngaia[\"obsid\"].isin(bad_lamost)]\n",
    "print(\"len(agn) after removing bad lamost spectra:\", len(tagngaia))\n",
    "\n",
    "# Make the folder for the cleaned dataframes\n",
    "!mkdir Pickles/tcleaned4\n",
    "\n",
    "# Save the cleaned dataframes\n",
    "tbingaia.to_pickle(\"Pickles/tcleaned4/bin_gaia.pkl\")\n",
    "tstargaia.to_pickle(\"Pickles/tcleaned4/star_gaia.pkl\")\n",
    "tgalgaia.to_pickle(\"Pickles/tcleaned4/gal_gaia.pkl\")\n",
    "tagngaia.to_pickle(\"Pickles/tcleaned4/agn_gaia.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lamost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GALAXIES: Number of rows before dropping: 1621 and after dropping: 1620\n",
      "BINARY STARS: Number of rows before dropping: 40554 and after dropping: 40483\n",
      "AGNs: Number of rows before dropping: 35811 and after dropping: 35806\n",
      "STARS: Number of rows before dropping: 83162 and after dropping: 83008\n",
      "Total number of rows removed: 231 out of 236\n"
     ]
    }
   ],
   "source": [
    "# open the pkl file with the list of files to drop\n",
    "nan_gaia = pd.read_pickle(\"Pickles/drops/gaiaall.pkl\")\n",
    "num_to_remove = len(nan_gaia)\n",
    "num_removed = 0\n",
    "\n",
    "# Training dataset\n",
    "# GALAXIES\n",
    "df = pd.read_pickle('Pickles/lmst/interpolated_data/train_gal.pkl')\n",
    "lenghtpre = len(df)\n",
    "df = df[~df['file_name'].isin(nan_gaia)]\n",
    "print(f\"GALAXIES: Number of rows before dropping: {lenghtpre} and after dropping: {len(df)}\")\n",
    "num_removed += lenghtpre - len(df)\n",
    "df.to_pickle('Pickles/lmst/interpolated_data/train_gal2.pkl')\n",
    "\n",
    "# BINARY STARS\n",
    "df = pd.read_pickle('Pickles/lmst/interpolated_data/train_bin.pkl')\n",
    "lenghtpre = len(df)\n",
    "df = df[~df['file_name'].isin(nan_gaia)]\n",
    "print(f\"BINARY STARS: Number of rows before dropping: {lenghtpre} and after dropping: {len(df)}\")\n",
    "num_removed += lenghtpre - len(df)\n",
    "df.to_pickle('Pickles/lmst/interpolated_data/train_bin2.pkl')\n",
    "\n",
    "# AGNs\n",
    "df = pd.read_pickle('Pickles/lmst/interpolated_data/train_agn.pkl')\n",
    "lenghtpre = len(df)\n",
    "df = df[~df['file_name'].isin(nan_gaia)]\n",
    "print(f\"AGNs: Number of rows before dropping: {lenghtpre} and after dropping: {len(df)}\")\n",
    "num_removed += lenghtpre - len(df)\n",
    "df.to_pickle('Pickles/lmst/interpolated_data/train_agn2.pkl')\n",
    "\n",
    "# STARS\n",
    "df = pd.read_pickle('Pickles/lmst/interpolated_data/train_star.pkl')\n",
    "lenghtpre = len(df)\n",
    "df = df[~df['file_name'].isin(nan_gaia)]\n",
    "print(f\"STARS: Number of rows before dropping: {lenghtpre} and after dropping: {len(df)}\")\n",
    "num_removed += lenghtpre - len(df)\n",
    "print(f\"Total number of rows removed: {num_removed} out of {num_to_remove}\")\n",
    "df.to_pickle('Pickles/lmst/interpolated_data/train_star2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final: Remove OBSID that do not match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One at a time as df are big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches in binary: 40485\n",
      "Number of non-matches in binary: 1\n",
      "Number of matches in binary after removing repeated rows: 40483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbingaia = pd.read_pickle(\"Pickles/tcleaned4/bin_gaia.pkl\")\n",
    "tbinlamost = pd.read_pickle(\"Pickles/lmst/interpolated_data/train_bin2.pkl\")\n",
    "tbinlamost.rename(columns={\"file_name\": \"obsid\"}, inplace=True)\n",
    "tbinlamost[\"obsid\"] = tbinlamost[\"obsid\"].astype(np.int64)\n",
    "matchedbin = pd.merge(tbingaia, tbinlamost, on=\"obsid\", how=\"inner\")\n",
    "print(\"Number of matches in binary:\", len(matchedbin))\n",
    "print(\"Number of non-matches in binary:\", len(tbingaia) - len(matchedbin))\n",
    "del tbingaia, tbinlamost\n",
    "gc.collect()\n",
    "# remove rows with repeated obsid and print them\n",
    "matchedbin.drop_duplicates(subset=\"obsid\",inplace=True)\n",
    "print(\"Number of matches in binary after removing repeated rows:\", len(matchedbin))\n",
    "# save the matched dataframes\n",
    "matchedbin.to_pickle(\"Pickles/fusionv0/tbin.pkl\")\n",
    "del matchedbin\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches in star: 83021\n",
      "Number of non-matches in star: 34\n",
      "Number of matches in star after removing repeated rows: 83008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tstargaia = pd.read_pickle(\"Pickles/tcleaned4/star_gaia.pkl\")\n",
    "tstarlamost = pd.read_pickle(\"Pickles/lmst/interpolated_data/train_star2.pkl\")\n",
    "tstarlamost.rename(columns={\"file_name\": \"obsid\"}, inplace=True)\n",
    "tstarlamost[\"obsid\"] = tstarlamost[\"obsid\"].astype(np.int64)\n",
    "matchedstar = pd.merge(tstargaia, tstarlamost, on=\"obsid\", how=\"inner\")\n",
    "print(\"Number of matches in star:\", len(matchedstar))\n",
    "print(\"Number of non-matches in star:\", len(tstargaia) - len(matchedstar))\n",
    "del tstargaia, tstarlamost\n",
    "gc.collect()\n",
    "# remove rows with repeated obsid and print them\n",
    "matchedstar.drop_duplicates(subset=\"obsid\",inplace=True)\n",
    "print(\"Number of matches in star after removing repeated rows:\", len(matchedstar))\n",
    "# save the matched dataframes\n",
    "matchedstar.to_pickle(\"Pickles/fusionv0/tstar.pkl\")\n",
    "del matchedstar\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches in gal: 1620\n",
      "Number of non-matches in gal: 0\n",
      "Number of matches in gal after removing repeated rows: 1620\n"
     ]
    }
   ],
   "source": [
    "tgalgaia = pd.read_pickle(\"Pickles/tcleaned4/gal_gaia.pkl\")\n",
    "tgalloamost = pd.read_pickle(\"Pickles/lmst/interpolated_data/train_gal2.pkl\")\n",
    "tgalloamost.rename(columns={\"file_name\": \"obsid\"}, inplace=True)\n",
    "tgalloamost[\"obsid\"] = tgalloamost[\"obsid\"].astype(np.int64)\n",
    "matchedgal = pd.merge(tgalgaia, tgalloamost, on=\"obsid\", how=\"inner\")\n",
    "print(\"Number of matches in gal:\", len(matchedgal))\n",
    "print(\"Number of non-matches in gal:\", len(tgalgaia) - len(matchedgal))\n",
    "del tgalgaia, tgalloamost\n",
    "gc.collect()\n",
    "# remove rows with repeated obsid and print them\n",
    "matchedgal.drop_duplicates(subset=\"obsid\",inplace=True)\n",
    "print(\"Number of matches in gal after removing repeated rows:\", len(matchedgal))\n",
    "# save the matched dataframes\n",
    "matchedgal.to_pickle(\"Pickles/fusionv0/tgal.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches in agn: 35806\n",
      "Number of non-matches in agn: 0\n",
      "Number of matches in agn after removing repeated rows: 35806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagngaia = pd.read_pickle(\"Pickles/tcleaned4/agn_gaia.pkl\")\n",
    "tagnlamost = pd.read_pickle(\"Pickles/lmst/interpolated_data/train_agn2.pkl\")\n",
    "tagnlamost.rename(columns={\"file_name\": \"obsid\"}, inplace=True)\n",
    "tagnlamost[\"obsid\"] = tagnlamost[\"obsid\"].astype(np.int64)\n",
    "matchedagn = pd.merge(tagngaia, tagnlamost, on=\"obsid\", how=\"inner\")\n",
    "print(\"Number of matches in agn:\", len(matchedagn))\n",
    "print(\"Number of non-matches in agn:\", len(tagngaia) - len(matchedagn))\n",
    "del tagngaia, tagnlamost\n",
    "gc.collect()\n",
    "# remove rows with repeated obsid and print them\n",
    "matchedagn.drop_duplicates(subset=\"obsid\",inplace=True)\n",
    "print(\"Number of matches in agn after removing repeated rows:\", len(matchedagn))\n",
    "# save the matched dataframes\n",
    "matchedagn.to_pickle(\"Pickles/fusionv0/tagn.pkl\")\n",
    "del matchedagn\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the dataframes\n",
    "tbin = pd.read_pickle(\"Pickles/fusionv0/tbin.pkl\")\n",
    "tstar = pd.read_pickle(\"Pickles/fusionv0/tstar.pkl\")\n",
    "tgal = pd.read_pickle(\"Pickles/fusionv0/tgal.pkl\")\n",
    "tagn = pd.read_pickle(\"Pickles/fusionv0/tagn.pkl\")\n",
    "vbin = pd.read_pickle(\"Pickles/fusionv0/vbin.pkl\")\n",
    "vstar = pd.read_pickle(\"Pickles/fusionv0/vstar.pkl\")\n",
    "vgal = pd.read_pickle(\"Pickles/fusionv0/vgal.pkl\")\n",
    "vagn = pd.read_pickle(\"Pickles/fusionv0/vagn.pkl\")\n",
    "\n",
    "# Combine the dataframes\n",
    "all = pd.concat([tbin, tstar, tgal, tagn, vbin, vstar, vgal, vagn], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the combined dataframe\n",
    "all.to_pickle(\"Pickles/fusionv0/all.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tbin, tstar, tgal, tagn, vbin, vstar, vgal, vagn, all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
