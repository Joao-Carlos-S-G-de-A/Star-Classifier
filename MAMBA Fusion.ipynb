{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import wandb\n",
    "import gc\n",
    "import pandas as pdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mambapy\n",
    "from mambapy.mamba import Mamba, MambaConfig\n",
    "from torch import nn, optim\n",
    "import pandas as pd\n",
    "from timm.models.vision_transformer import Mlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedDataset(Dataset):\n",
    "    def __init__(self, X, y, limit_per_label=1600):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.limit_per_label = limit_per_label\n",
    "        self.classes = np.unique(y)\n",
    "        self.indices = self.balance_classes()\n",
    "\n",
    "    def balance_classes(self):\n",
    "        indices = []\n",
    "        for cls in self.classes:\n",
    "            cls_indices = np.where(self.y == cls)[0]\n",
    "            if len(cls_indices) > self.limit_per_label:\n",
    "                cls_indices = np.random.choice(cls_indices, self.limit_per_label, replace=False)\n",
    "            indices.extend(cls_indices)\n",
    "        np.random.shuffle(indices)\n",
    "        return indices\n",
    "\n",
    "    def re_sample(self):\n",
    "        self.indices = self.balance_classes()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        index = self.indices[idx]\n",
    "        return self.X[index], self.y[index]\n",
    "# Custom Dataset for validation with limit per class\n",
    "class BalancedValidationDataset(Dataset):\n",
    "    def __init__(self, X, y, limit_per_label=400):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.limit_per_label = limit_per_label\n",
    "        self.classes = np.unique(y)\n",
    "        self.indices = self.balance_classes()\n",
    "\n",
    "    def balance_classes(self):\n",
    "        indices = []\n",
    "        for cls in self.classes:\n",
    "            cls_indices = np.where(self.y == cls)[0]\n",
    "            if len(cls_indices) > self.limit_per_label:\n",
    "                cls_indices = np.random.choice(cls_indices, self.limit_per_label, replace=False)\n",
    "            indices.extend(cls_indices)\n",
    "        np.random.shuffle(indices)\n",
    "        return indices\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        index = self.indices[idx]\n",
    "        return self.X[index], self.y[index]\n",
    "    \n",
    "# Create Datasets\n",
    "class BalancedDatasetFusion(Dataset):\n",
    "    def __init__(self, X_conv, X_gaia, y, limit_per_label=1600):\n",
    "        self.X_conv = X_conv\n",
    "        self.X_gaia = X_gaia\n",
    "        self.y = y\n",
    "        self.limit_per_label = limit_per_label\n",
    "        self.classes = np.unique(y)\n",
    "        self.indices = self.balance_classes()\n",
    "\n",
    "    def balance_classes(self):\n",
    "        indices = []\n",
    "        for cls in self.classes:\n",
    "            cls_indices = np.where(self.y == cls)[0]\n",
    "            if len(cls_indices) > self.limit_per_label:\n",
    "                cls_indices = np.random.choice(cls_indices, self.limit_per_label, replace=False)\n",
    "            indices.extend(cls_indices)\n",
    "        np.random.shuffle(indices)\n",
    "        return indices\n",
    "\n",
    "    def re_sample(self):\n",
    "        self.indices = self.balance_classes()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        index = self.indices[idx]\n",
    "        return self.X_conv[index], self.X_gaia[index], self.y[index]\n",
    "\n",
    "# Balanced Dataset Classes\n",
    "class BalancedDatasetFusion(Dataset):\n",
    "    def __init__(self, X_conv, X_gaia, y, limit_per_label=1600):\n",
    "        self.X_conv = X_conv\n",
    "        self.X_gaia = X_gaia\n",
    "        self.y = y\n",
    "        self.limit_per_label = limit_per_label\n",
    "        self.classes = np.unique(y)\n",
    "        self.indices = self.balance_classes()\n",
    "\n",
    "    def balance_classes(self):\n",
    "        indices = []\n",
    "        for cls in self.classes:\n",
    "            cls_indices = np.where(self.y == cls)[0]\n",
    "            if len(cls_indices) > self.limit_per_label:\n",
    "                cls_indices = np.random.choice(cls_indices, self.limit_per_label, replace=False)\n",
    "            indices.extend(cls_indices)\n",
    "        np.random.shuffle(indices)\n",
    "        return indices\n",
    "\n",
    "    def re_sample(self):\n",
    "        self.indices = self.balance_classes()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        index = self.indices[idx]\n",
    "        return self.X_conv[index], self.X_gaia[index], self.y[index]\n",
    "\n",
    "\n",
    "# MAMBA Classifier for Single Modality\n",
    "class StarClassifierMAMBA(nn.Module):\n",
    "    def __init__(self, d_model, num_classes, d_state=64, d_conv=4, input_dim=17, n_layers=6):\n",
    "        super(StarClassifierMAMBA, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # MAMBA layer initialization\n",
    "        config = MambaConfig(\n",
    "            d_model=d_model,\n",
    "            d_state=d_state,\n",
    "            d_conv=d_conv,\n",
    "            n_layers=n_layers\n",
    "        )\n",
    "        self.mamba_layer = Mamba(config)\n",
    "\n",
    "        # Input projection to match the MAMBA layer dimension\n",
    "        self.input_projection = nn.Linear(input_dim, d_model)\n",
    "\n",
    "        # Fully connected classifier head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Linear(d_model, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_projection(x)  # Ensure the input has the correct dimension\n",
    "        x = x.unsqueeze(1)  # Adds a sequence dimension (L=1)\n",
    "        x = self.mamba_layer(x)\n",
    "        x = x.mean(dim=1)  # Pooling operation for classification\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Cross Attention Block\n",
    "class CrossAttentionBlock(nn.Module):\n",
    "    def __init__(self, dim, num_heads):\n",
    "        super(CrossAttentionBlock, self).__init__()\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim=dim, num_heads=num_heads, batch_first=True)\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        combined = torch.cat([x1, x2], dim=1)\n",
    "        attn_output, _ = self.multihead_attn(combined, combined, combined)\n",
    "        return self.norm(attn_output)\n",
    "\n",
    "\n",
    "# Dual MAMBA Classifier with Cross Attention\n",
    "class DualMambaClassifier(nn.Module):\n",
    "    def __init__(self, gaia_dim, spectra_dim, d_model, num_classes, d_state=64, d_conv=4, n_layers=6):\n",
    "        super(DualMambaClassifier, self).__init__()\n",
    "        # MAMBA model for Gaia data\n",
    "        self.gaia_model = StarClassifierMAMBA(d_model, num_classes, d_state, d_conv, gaia_dim, n_layers)\n",
    "        # MAMBA model for spectra data\n",
    "        self.spectra_model = StarClassifierMAMBA(d_model, num_classes, d_state, d_conv, spectra_dim, n_layers)\n",
    "        \n",
    "        # Cross attention block\n",
    "        self.cross_attention = CrossAttentionBlock(dim=d_model, num_heads=8)\n",
    "\n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Linear(d_model, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, gaia_x, spectra_x):\n",
    "        print(f'Gaia input shape: {gaia_x.shape}')\n",
    "        print(f'Spectra input shape: {spectra_x.shape}')\n",
    "\n",
    "        gaia_features =self.gaia_model.input_projection(gaia_x)\n",
    "        spectra_features = self.spectra_model.input_projection(spectra_x)\n",
    "\n",
    "\n",
    "        print(f'Gaia features shape: {gaia_features.shape}')\n",
    "        print(f'Spectra features shape: {spectra_features.shape}')\n",
    "        # Process inputs through individual MAMBA models\n",
    "        gaia_features = self.gaia_model.mamba_layer(gaia_features)\n",
    "        spectra_features = self.spectra_model.mamba_layer(spectra_features)\n",
    "\n",
    "        # Combine the representations from each branch\n",
    "        branch_outputs = [gaia_features, spectra_features]\n",
    "        combined_features = torch.cat(branch_outputs, dim=1)\n",
    "        print(f'Combined features shape: {combined_features.shape}')\n",
    "        \n",
    "        # Apply cross-attention\n",
    "        fused_features = self.cross_attention(gaia_features, spectra_features)\n",
    "        print(f'Fused features shape: {fused_features.shape}')\n",
    "        \n",
    "        # Global average pooling and classification\n",
    "        pooled_features = fused_features.mean(dim=1)\n",
    "        print(f'Pooled features shape: {pooled_features.shape}')\n",
    "        \n",
    "        output = self.classifier(pooled_features)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "class StarClassifierMAMBA(nn.Module):\n",
    "    def __init__(self, d_model, num_classes, d_state=64, d_conv=4, input_dim=17, n_layers=6):\n",
    "        super(StarClassifierMAMBA, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # MAMBA layer initialization\n",
    "        config = MambaConfig(\n",
    "            d_model=d_model,\n",
    "            d_state=d_state,\n",
    "            d_conv=d_conv,\n",
    "            n_layers=n_layers\n",
    "\n",
    "        )\n",
    "        self.mamba_layer = Mamba(config)\n",
    "\n",
    "        # Input projection to match the MAMBA layer dimension\n",
    "        self.input_projection = nn.Linear(input_dim, d_model)\n",
    "\n",
    "        # Fully connected classifier head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Linear(d_model, num_classes)\n",
    "        )\n",
    "\n",
    "\n",
    "def forward(self, x):\n",
    "    x = self.input_projection(x)  # Ensure the input has the correct dimension\n",
    "    print(\"Shape after input_projection:\", x.shape)\n",
    "    \n",
    "    x = x.unsqueeze(1)  # Adds a sequence dimension (L=1).\n",
    "    print(\"Shape after unsqueeze:\", x.shape)\n",
    "    \n",
    "    x = self.mamba_layer(x)\n",
    "    print(\"Shape after mamba_layer:\", x.shape)\n",
    "    \n",
    "    x = x.mean(dim=1)  # Pooling operation for classification\n",
    "    print(\"Shape after mean:\", x.shape)\n",
    "    \n",
    "    x = self.classifier(x)\n",
    "    print(\"Shape before classifier:\", x.shape)\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Training Function\n",
    "def train_model_mamba(\n",
    "    model, train_loader, val_loader, test_loader, \n",
    "    num_epochs=500, lr=1e-4, max_patience=20, device='cuda'\n",
    "):\n",
    "    # Move model to device\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Define optimizer, scheduler, and loss function\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=int(max_patience / 3), verbose=True\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience = max_patience\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Resample training data\n",
    "        train_loader.dataset.re_sample()\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss, train_accuracy = 0.0, 0.0\n",
    "\n",
    "        for X_conv_batch, X_gaia_batch, y_batch in train_loader:\n",
    "            X_conv_batch, X_gaia_batch, y_batch = (\n",
    "                X_conv_batch.to(device), X_gaia_batch.to(device), y_batch.to(device)\n",
    "            )\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_gaia_batch, X_conv_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * X_conv_batch.size(0)\n",
    "            train_accuracy += (outputs.argmax(dim=1) == y_batch).float().mean().item()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss, val_accuracy = 0.0, 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_conv_val, X_gaia_val, y_val in val_loader:\n",
    "                X_conv_val, X_gaia_val, y_val = (\n",
    "                    X_conv_val.to(device), X_gaia_val.to(device), y_val.to(device)\n",
    "                )\n",
    "                outputs = model(X_gaia_val, X_conv_val)\n",
    "                loss = criterion(outputs, y_val)\n",
    "                val_loss += loss.item() * X_conv_val.size(0)\n",
    "                val_accuracy += (outputs.argmax(dim=1) == y_val).float().mean().item()\n",
    "\n",
    "        # Update scheduler\n",
    "        scheduler.step(val_loss / len(val_loader.dataset))\n",
    "\n",
    "        # Test phase\n",
    "        test_loss, test_accuracy = 0.0, 0.0\n",
    "        y_true, y_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for X_conv_test, X_gaia_test, y_test in test_loader:\n",
    "                X_conv_test, X_gaia_test, y_test = (\n",
    "                    X_conv_test.to(device), X_gaia_test.to(device), y_test.to(device)\n",
    "                )\n",
    "                outputs = model(X_gaia_test, X_conv_test)\n",
    "                loss = criterion(outputs, y_test)\n",
    "                test_loss += loss.item() * X_conv_test.size(0)\n",
    "                test_accuracy += (outputs.argmax(dim=1) == y_test).float().mean().item()\n",
    "                y_true.extend(y_test.cpu().numpy())\n",
    "                y_pred.extend(outputs.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        # Log metrics to WandB\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": train_loss / len(train_loader.dataset),\n",
    "            \"val_loss\": val_loss / len(val_loader.dataset),\n",
    "            \"train_accuracy\": train_accuracy / len(train_loader),\n",
    "            \"val_accuracy\": val_accuracy / len(val_loader),\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "            \"test_loss\": test_loss / len(test_loader.dataset),\n",
    "            \"test_accuracy\": test_accuracy / len(test_loader),\n",
    "            \"confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "                probs=None, y_true=y_true, preds=y_pred, class_names=np.unique(y_true)\n",
    "            ),\n",
    "            \"classification_report\": classification_report(\n",
    "                y_true, y_pred, target_names=[str(i) for i in range(len(np.unique(y_true)))]\n",
    "            )\n",
    "        })\n",
    "\n",
    "        # Early stopping logic\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience = max_patience\n",
    "            best_model = model.state_dict()\n",
    "        else:\n",
    "            patience -= 1\n",
    "            if patience <= 0:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    # Load the best model weights\n",
    "    model.load_state_dict(best_model)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129965, 3748)\n"
     ]
    }
   ],
   "source": [
    "# Fusion dataset opening\n",
    "batch_size = 128\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "        # Load and preprocess data\n",
    "        X = pd.read_pickle(\"Pickles/trainv2.pkl\")\n",
    "        gaia_features = [\"parallax\", \"ra\", \"dec\", \"ra_error\", \"dec_error\", \"parallax_error\", \"pmra\", \"pmdec\", \"pmra_error\", \"pmdec_error\", \n",
    "        \"phot_g_mean_flux\", \"flagnopllx\", \"phot_g_mean_flux_error\", \"phot_bp_mean_flux\", \"phot_rp_mean_flux\", \n",
    "        \"phot_bp_mean_flux_error\", \"phot_rp_mean_flux_error\"]\n",
    "\n",
    "        # Extract Gaia and LASMOST data\n",
    "        X_gaia = X[gaia_features].values\n",
    "        X_lamost = X.drop(gaia_features + [\"label\"] + [\"obsid\"] , axis=1).values\n",
    "        print(X_lamost.shape)\n",
    "        y = X[\"label\"]\n",
    "\n",
    "        # Mapping labels to integers\n",
    "        label_mapping = {'star': 0, 'binary_star': 1, 'galaxy': 2, 'agn': 3}\n",
    "        y = y.map(label_mapping).values\n",
    "\n",
    "        # Read test data\n",
    "        X_test = pd.read_pickle(\"Pickles/testv2.pkl\")\n",
    "        X_test_gaia = X_test[gaia_features].values\n",
    "        X_test_conv = X_test.drop(gaia_features + [\"label\"]  + [\"obsid\"] , axis=1).values\n",
    "        y_test = X_test[\"label\"]\n",
    "        y_test = y_test.map(label_mapping).values\n",
    "\n",
    "\n",
    "        # Split data into train and validation\n",
    "        X_train_conv, X_val_conv, X_train_gaia, X_val_gaia, y_train, y_val = train_test_split(X_lamost, X_gaia, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        X_train_conv = torch.tensor(X_train_conv, dtype=torch.float32).unsqueeze(1)\n",
    "        X_val_conv = torch.tensor(X_val_conv, dtype=torch.float32).unsqueeze(1)\n",
    "        X_train_gaia = torch.tensor(X_train_gaia, dtype=torch.float32).unsqueeze(1)\n",
    "        X_val_gaia = torch.tensor(X_val_gaia, dtype=torch.float32).unsqueeze(1)\n",
    "        y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "        y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "        X_test_conv = torch.tensor(X_test_conv, dtype=torch.float32)\n",
    "        X_test_gaia = torch.tensor(X_test_gaia, dtype=torch.float32)\n",
    "        y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_dataset = BalancedDatasetFusion(X_train_conv, X_train_gaia, y_train)\n",
    "        val_dataset = BalancedDatasetFusion(X_val_conv, X_val_gaia, y_val)\n",
    "        test_dataset = BalancedDatasetFusion(X_test_conv, X_test_gaia, y_test)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttentionBlock(nn.Module):\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0., theta=10000,\n",
    "                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm, has_mlp=True):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = CrossAttention(\n",
    "            dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop, theta=theta)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.has_mlp = has_mlp\n",
    "        if has_mlp:\n",
    "            self.norm2 = norm_layer(dim)\n",
    "            mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "            self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x[:, 0:1, ...] + self.drop_path(self.attn(self.norm1(x)))\n",
    "        if self.has_mlp:\n",
    "            x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "\n",
    "        return x\n",
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0., theta=10000):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.dim = dim\n",
    "        self.scale = qk_scale or (dim // num_heads) ** -0.5\n",
    "        self.theta = theta\n",
    "\n",
    "        self.wq = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        self.wk = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        self.wv = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "        \n",
    "        # Initialize rotary frequencies\n",
    "        self.freqs = init_rope_frequencies(dim, num_heads, theta)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        B, N, C = x.shape\n",
    "        q = self.wq(x[:, 0:1, ...]).view(B, 1, self.num_heads, C // self.num_heads).permute(0, 2, 1, 3)\n",
    "        k = self.wk(x).view(B, N, self.num_heads, C // self.num_heads).permute(0, 2, 1, 3)\n",
    "        v = self.wv(x).view(B, N, self.num_heads, C // self.num_heads).permute(0, 2, 1, 3)\n",
    "\n",
    "        # Apply rotary position embedding\n",
    "        q_rot, k_rot = apply_rotary_position_embeddings(self.freqs.to(x.device), q, k)\n",
    "\n",
    "        # Attention calculation with rotated embeddings\n",
    "        attn = (q_rot @ k_rot.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "        \n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, 1, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "def init_rope_frequencies(dim, num_heads, theta, rotate=False):\n",
    "    # Adjust the size of `mag` to match the per-head dimension\n",
    "    per_head_dim = dim // ( num_heads)\n",
    "    mag = 1 / (theta ** (torch.arange(0, per_head_dim).float() / (dim // num_heads))).unsqueeze(0)\n",
    "\n",
    "    # Adjust `angles` accordingly\n",
    "    angles = torch.rand(num_heads, per_head_dim//2) * 2 * torch.pi if rotate else torch.zeros(num_heads, per_head_dim//2)\n",
    "\n",
    "    # Compute `freq_x` and `freq_y` with matching dimensions\n",
    "    freq_x = mag * torch.cat([torch.cos(angles), torch.cos(torch.pi / 2 + angles)], dim=-1)\n",
    "    freq_y = mag * torch.cat([torch.sin(angles), torch.sin(torch.pi / 2 + angles)], dim=-1)\n",
    "\n",
    "    return torch.stack([freq_x, freq_y], dim=0)\n",
    "\n",
    "\n",
    "def apply_rotary_position_embeddings(freqs, q, k):\n",
    "    # Ensure `cos` and `sin` have the same shape as `q` and `k` by adding unsqueeze\n",
    "    cos, sin = freqs[0].unsqueeze(1), freqs[1].unsqueeze(1)   \n",
    "    \n",
    "    # Broadcast `cos` and `sin` to match `q` and `k` dimensions\n",
    "    q_rot = (q * cos) + (torch.roll(q, shifts=1, dims=-1) * sin)\n",
    "    k_rot = (k * cos) + (torch.roll(k, shifts=1, dims=-1) * sin)\n",
    "    \n",
    "    return q_rot, k_rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StarClassifierMAMBA(nn.Module):\n",
    "    def __init__(self, d_model, num_classes, d_state=64, d_conv=4, input_dim=17, n_layers=6):\n",
    "        super(StarClassifierMAMBA, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Embedding layer\n",
    "        self.input_projection = nn.Linear(input_dim, d_model)\n",
    "\n",
    "        # MAMBA layer initialization\n",
    "        config = MambaConfig(\n",
    "            d_model=d_model,\n",
    "            d_state=d_state,\n",
    "            d_conv=d_conv,\n",
    "            n_layers=n_layers\n",
    "        )\n",
    "        self.mamba_layer = Mamba(config)\n",
    "\n",
    "        # Fully connected classifier head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Linear(d_model, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply embedding: (seq_len, batch_size, input_dim) -> (seq_len, batch_size, d_model)\n",
    "        x = self.input_projection(x)\n",
    "        \n",
    "        # Ensure the input has the correct dimension\n",
    "        # Assuming x is of shape (batch_size, seq_len, input_dim)\n",
    "        x = x.permute(1, 0, 2)  # Change to (seq_len, batch_size, d_model)\n",
    "        \n",
    "        # Apply MAMBA layer: (seq_len, batch_size, d_model)\n",
    "        x = self.mamba_layer(x)\n",
    "        \n",
    "        # Pooling: (seq_len, batch_size, d_model) -> (batch_size, d_model)\n",
    "        x = x.mean(dim=0)\n",
    "        \n",
    "        # Final classification: (batch_size, num_classes)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StarClassifierMAMBA(nn.Module):\n",
    "    def __init__(self, d_model, num_classes, d_state=64, d_conv=4, input_dim=17, n_layers=6):\n",
    "        super(StarClassifierMAMBA, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # MAMBA layer initialization\n",
    "        config = MambaConfig(\n",
    "            d_model=d_model,\n",
    "            d_state=d_state,\n",
    "            d_conv=d_conv,\n",
    "            n_layers=n_layers\n",
    "        )\n",
    "        self.mamba_layer = Mamba(config)\n",
    "\n",
    "        # Input projection to match the MAMBA layer dimension\n",
    "        self.input_projection = nn.Linear(input_dim, d_model)\n",
    "\n",
    "        # Fully connected classifier head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Linear(d_model, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply embedding: (batch_size, seq_len, input_dim) -> (batch_size, seq_len, d_model)\n",
    "        x = self.input_projection(x)\n",
    "        \n",
    "        # Ensure the input has the correct dimension\n",
    "        # Assuming x is of shape (batch_size, seq_len, d_model)\n",
    "        x = x.permute(1, 0, 2)  # Change to (seq_len, batch_size, d_model)\n",
    "        \n",
    "        # Apply MAMBA layer: (seq_len, batch_size, d_model)\n",
    "        x = self.mamba_layer(x)\n",
    "        \n",
    "        # Pooling: (seq_len, batch_size, d_model) -> (batch_size, d_model)\n",
    "        x = x.mean(dim=0)\n",
    "        \n",
    "        # Final classification: (batch_size, num_classes)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class DualMambaClassifier(nn.Module):\n",
    "    def __init__(self, gaia_model, spectra_model, cross_attention, classifier):\n",
    "        super(DualMambaClassifier, self).__init__()\n",
    "        self.gaia_model = gaia_model\n",
    "        self.spectra_model = spectra_model\n",
    "        self.cross_attention = cross_attention\n",
    "        self.classifier = classifier\n",
    "\n",
    "    def forward(self, gaia_x, spectra_x):\n",
    "        print(f'Gaia input shape: {gaia_x.shape}')\n",
    "        print(f'Spectra input shape: {spectra_x.shape}')\n",
    "        \n",
    "        # Ensure the inputs are correctly aligned\n",
    "        if gaia_x.shape[1] != 17 or spectra_x.shape[2] != 3748:\n",
    "            raise ValueError(\"Input dimensions do not match the expected dimensions for Gaia and spectra data.\")\n",
    "        \n",
    "        # Project inputs to the model dimension\n",
    "        gaia_features = self.gaia_model.input_projection(gaia_x).unsqueeze(1)\n",
    "        spectra_features = self.spectra_model.input_projection(spectra_x.squeeze(1)).unsqueeze(1)\n",
    "        \n",
    "        print(f'Gaia features shape after projection: {gaia_features.shape}')\n",
    "        print(f'Spectra features shape after projection: {spectra_features.shape}')\n",
    "        \n",
    "        # Process inputs through MAMBA layers\n",
    "        gaia_features = self.gaia_model.mamba_layer(gaia_features)\n",
    "        spectra_features = self.spectra_model.mamba_layer(spectra_features)\n",
    "        \n",
    "        print(f'Gaia features shape after MAMBA layer: {gaia_features.shape}')\n",
    "        print(f'Spectra features shape after MAMBA layer: {spectra_features.shape}')\n",
    "        \n",
    "        # Combine the representations from each branch\n",
    "        branch_outputs = [gaia_features, spectra_features]\n",
    "        combined_features = torch.cat(branch_outputs, dim=1)\n",
    "        print(f'Combined features shape: {combined_features.shape}')\n",
    "        \n",
    "        # Apply cross-attention with both inputs\n",
    "        fused_features = self.cross_attention(gaia_features, spectra_features)\n",
    "        print(f'Fused features shape: {fused_features.shape}')\n",
    "        \n",
    "        # Global average pooling and classification\n",
    "        pooled_features = fused_features.mean(dim=1)\n",
    "        print(f'Pooled features shape: {pooled_features.shape}')\n",
    "        \n",
    "        output = self.classifier(pooled_features)\n",
    "        \n",
    "        return output\n",
    "# Dual MAMBA Classifier with Cross Attention\n",
    "class DualMambaClassifier(nn.Module):\n",
    "    def __init__(self, gaia_dim, spectra_dim, d_model, num_classes, d_state=64, d_conv=4, n_layers=6):\n",
    "        super(DualMambaClassifier, self).__init__()\n",
    "        # MAMBA model for Gaia data\n",
    "        self.gaia_model = StarClassifierMAMBA(d_model, num_classes, d_state, d_conv, gaia_dim, n_layers)\n",
    "        # MAMBA model for spectra data\n",
    "        self.spectra_model = StarClassifierMAMBA(d_model, num_classes, d_state, d_conv, spectra_dim, n_layers)\n",
    "        \n",
    "        # Cross attention block\n",
    "        self.cross_attention = CrossAttentionBlock(dim=d_model, num_heads=8)\n",
    "\n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Linear(d_model, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, gaia_x, spectra_x):\n",
    "        print(f'Gaia input shape: {gaia_x.shape}')\n",
    "        print(f'Spectra input shape: {spectra_x.shape}')\n",
    "\n",
    "        gaia_features =self.gaia_model.input_projection(gaia_x)\n",
    "        spectra_features = self.spectra_model.input_projection(spectra_x)\n",
    "\n",
    "\n",
    "        print(f'Gaia features shape: {gaia_features.shape}')\n",
    "        print(f'Spectra features shape: {spectra_features.shape}')\n",
    "        # Process inputs through individual MAMBA models\n",
    "        gaia_features = self.gaia_model.mamba_layer(gaia_features)\n",
    "        spectra_features = self.spectra_model.mamba_layer(spectra_features)\n",
    "\n",
    "        # Combine the representations from each branch\n",
    "        branch_outputs = [gaia_features, spectra_features]\n",
    "        combined_features = torch.cat(branch_outputs, dim=1)\n",
    "        print(f'Combined features shape: {combined_features.shape}')\n",
    "        \n",
    "        # Apply cross-attention\n",
    "        fused_features = self.cross_attention(gaia_features, spectra_features)\n",
    "        print(f'Fused features shape: {fused_features.shape}')\n",
    "        \n",
    "        # Global average pooling and classification\n",
    "        pooled_features = fused_features.mean(dim=1)\n",
    "        print(f'Pooled features shape: {pooled_features.shape}')\n",
    "        \n",
    "        output = self.classifier(pooled_features)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:usck7phi) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">eager-pine-27</strong> at: <a href='https://wandb.ai/joaoc-university-of-southampton/fusion-mamba-test/runs/usck7phi' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/fusion-mamba-test/runs/usck7phi</a><br/> View project at: <a href='https://wandb.ai/joaoc-university-of-southampton/fusion-mamba-test' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/fusion-mamba-test</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241129_142750-usck7phi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:usck7phi). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\jcwin\\OneDrive - University of Southampton\\_Southampton\\2024-25\\Star-Classifier\\wandb\\run-20241129_142811-sj6m8kbp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/joaoc-university-of-southampton/fusion-mamba-test/runs/sj6m8kbp' target=\"_blank\">usual-firebrand-28</a></strong> to <a href='https://wandb.ai/joaoc-university-of-southampton/fusion-mamba-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/joaoc-university-of-southampton/fusion-mamba-test' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/fusion-mamba-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/joaoc-university-of-southampton/fusion-mamba-test/runs/sj6m8kbp' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/fusion-mamba-test/runs/sj6m8kbp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DualMambaClassifier(\n",
      "  (gaia_model): StarClassifierMAMBA(\n",
      "    (mamba_layer): Mamba(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x ResidualBlock(\n",
      "          (mixer): MambaBlock(\n",
      "            (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "            (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "            (x_proj): Linear(in_features=512, out_features=144, bias=False)\n",
      "            (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "            (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "          )\n",
      "          (norm): RMSNorm()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (input_projection): Linear(in_features=17, out_features=256, bias=True)\n",
      "    (classifier): Sequential(\n",
      "      (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (1): Linear(in_features=256, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (spectra_model): StarClassifierMAMBA(\n",
      "    (mamba_layer): Mamba(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x ResidualBlock(\n",
      "          (mixer): MambaBlock(\n",
      "            (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "            (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "            (x_proj): Linear(in_features=512, out_features=144, bias=False)\n",
      "            (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "            (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "          )\n",
      "          (norm): RMSNorm()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (input_projection): Linear(in_features=3748, out_features=256, bias=True)\n",
      "    (classifier): Sequential(\n",
      "      (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (1): Linear(in_features=256, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (cross_attention): CrossAttentionBlock(\n",
      "    (multihead_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "    )\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=256, out_features=4, bias=True)\n",
      "  )\n",
      ")\n",
      "gaia_model.mamba_layer.layers.0.mixer.A_log 32768\n",
      "gaia_model.mamba_layer.layers.0.mixer.D 512\n",
      "gaia_model.mamba_layer.layers.0.mixer.in_proj.weight 262144\n",
      "gaia_model.mamba_layer.layers.0.mixer.conv1d.weight 2048\n",
      "gaia_model.mamba_layer.layers.0.mixer.conv1d.bias 512\n",
      "gaia_model.mamba_layer.layers.0.mixer.x_proj.weight 73728\n",
      "gaia_model.mamba_layer.layers.0.mixer.dt_proj.weight 8192\n",
      "gaia_model.mamba_layer.layers.0.mixer.dt_proj.bias 512\n",
      "gaia_model.mamba_layer.layers.0.mixer.out_proj.weight 131072\n",
      "gaia_model.mamba_layer.layers.0.norm.weight 256\n",
      "gaia_model.mamba_layer.layers.1.mixer.A_log 32768\n",
      "gaia_model.mamba_layer.layers.1.mixer.D 512\n",
      "gaia_model.mamba_layer.layers.1.mixer.in_proj.weight 262144\n",
      "gaia_model.mamba_layer.layers.1.mixer.conv1d.weight 2048\n",
      "gaia_model.mamba_layer.layers.1.mixer.conv1d.bias 512\n",
      "gaia_model.mamba_layer.layers.1.mixer.x_proj.weight 73728\n",
      "gaia_model.mamba_layer.layers.1.mixer.dt_proj.weight 8192\n",
      "gaia_model.mamba_layer.layers.1.mixer.dt_proj.bias 512\n",
      "gaia_model.mamba_layer.layers.1.mixer.out_proj.weight 131072\n",
      "gaia_model.mamba_layer.layers.1.norm.weight 256\n",
      "gaia_model.input_projection.weight 4352\n",
      "gaia_model.input_projection.bias 256\n",
      "gaia_model.classifier.0.weight 256\n",
      "gaia_model.classifier.0.bias 256\n",
      "gaia_model.classifier.1.weight 1024\n",
      "gaia_model.classifier.1.bias 4\n",
      "spectra_model.mamba_layer.layers.0.mixer.A_log 32768\n",
      "spectra_model.mamba_layer.layers.0.mixer.D 512\n",
      "spectra_model.mamba_layer.layers.0.mixer.in_proj.weight 262144\n",
      "spectra_model.mamba_layer.layers.0.mixer.conv1d.weight 2048\n",
      "spectra_model.mamba_layer.layers.0.mixer.conv1d.bias 512\n",
      "spectra_model.mamba_layer.layers.0.mixer.x_proj.weight 73728\n",
      "spectra_model.mamba_layer.layers.0.mixer.dt_proj.weight 8192\n",
      "spectra_model.mamba_layer.layers.0.mixer.dt_proj.bias 512\n",
      "spectra_model.mamba_layer.layers.0.mixer.out_proj.weight 131072\n",
      "spectra_model.mamba_layer.layers.0.norm.weight 256\n",
      "spectra_model.mamba_layer.layers.1.mixer.A_log 32768\n",
      "spectra_model.mamba_layer.layers.1.mixer.D 512\n",
      "spectra_model.mamba_layer.layers.1.mixer.in_proj.weight 262144\n",
      "spectra_model.mamba_layer.layers.1.mixer.conv1d.weight 2048\n",
      "spectra_model.mamba_layer.layers.1.mixer.conv1d.bias 512\n",
      "spectra_model.mamba_layer.layers.1.mixer.x_proj.weight 73728\n",
      "spectra_model.mamba_layer.layers.1.mixer.dt_proj.weight 8192\n",
      "spectra_model.mamba_layer.layers.1.mixer.dt_proj.bias 512\n",
      "spectra_model.mamba_layer.layers.1.mixer.out_proj.weight 131072\n",
      "spectra_model.mamba_layer.layers.1.norm.weight 256\n",
      "spectra_model.input_projection.weight 959488\n",
      "spectra_model.input_projection.bias 256\n",
      "spectra_model.classifier.0.weight 256\n",
      "spectra_model.classifier.0.bias 256\n",
      "spectra_model.classifier.1.weight 1024\n",
      "spectra_model.classifier.1.bias 4\n",
      "cross_attention.multihead_attn.in_proj_weight 196608\n",
      "cross_attention.multihead_attn.in_proj_bias 768\n",
      "cross_attention.multihead_attn.out_proj.weight 65536\n",
      "cross_attention.multihead_attn.out_proj.bias 256\n",
      "cross_attention.norm.weight 256\n",
      "cross_attention.norm.bias 256\n",
      "classifier.0.weight 256\n",
      "classifier.0.bias 256\n",
      "classifier.1.weight 1024\n",
      "classifier.1.bias 4\n",
      "Total number of parameters: 3279628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([75, 1, 17])\n",
      "Spectra input shape: torch.Size([75, 1, 3748])\n",
      "Gaia features shape: torch.Size([75, 1, 256])\n",
      "Spectra features shape: torch.Size([75, 1, 256])\n",
      "Combined features shape: torch.Size([75, 2, 256])\n",
      "Fused features shape: torch.Size([75, 2, 256])\n",
      "Pooled features shape: torch.Size([75, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([128, 1, 17])\n",
      "Spectra input shape: torch.Size([128, 1, 3748])\n",
      "Gaia features shape: torch.Size([128, 1, 256])\n",
      "Spectra features shape: torch.Size([128, 1, 256])\n",
      "Combined features shape: torch.Size([128, 2, 256])\n",
      "Fused features shape: torch.Size([128, 2, 256])\n",
      "Pooled features shape: torch.Size([128, 256])\n",
      "Gaia input shape: torch.Size([15, 1, 17])\n",
      "Spectra input shape: torch.Size([15, 1, 3748])\n",
      "Gaia features shape: torch.Size([15, 1, 256])\n",
      "Spectra features shape: torch.Size([15, 1, 256])\n",
      "Combined features shape: torch.Size([15, 2, 256])\n",
      "Fused features shape: torch.Size([15, 2, 256])\n",
      "Pooled features shape: torch.Size([15, 256])\n",
      "Gaia input shape: torch.Size([128, 17])\n",
      "Spectra input shape: torch.Size([128, 3748])\n",
      "Gaia features shape: torch.Size([128, 256])\n",
      "Spectra features shape: torch.Size([128, 256])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 32\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal number of parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m dual_model\u001b[38;5;241m.\u001b[39mparameters() \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mrequires_grad))\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Train the model using your `train_model_vit` or an adjusted training loop\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_mamba\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdual_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Save the model and finish WandB session\u001b[39;00m\n\u001b[0;32m     43\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "Cell \u001b[1;32mIn[47], line 318\u001b[0m, in \u001b[0;36mtrain_model_mamba\u001b[1;34m(model, train_loader, val_loader, test_loader, num_epochs, lr, max_patience, device)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_conv_test, X_gaia_test, y_test \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m    315\u001b[0m     X_conv_test, X_gaia_test, y_test \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    316\u001b[0m         X_conv_test\u001b[38;5;241m.\u001b[39mto(device), X_gaia_test\u001b[38;5;241m.\u001b[39mto(device), y_test\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    317\u001b[0m     )\n\u001b[1;32m--> 318\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_gaia_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_conv_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y_test)\n\u001b[0;32m    320\u001b[0m     test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m X_conv_test\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[64], line 119\u001b[0m, in \u001b[0;36mDualMambaClassifier.forward\u001b[1;34m(self, gaia_x, spectra_x)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpectra features shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspectra_features\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# Process inputs through individual MAMBA models\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m gaia_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgaia_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmamba_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgaia_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m spectra_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspectra_model\u001b[38;5;241m.\u001b[39mmamba_layer(spectra_features)\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# Combine the representations from each branch\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mambapy\\mamba.py:83\u001b[0m, in \u001b[0;36mMamba.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# x : (B, L, D)\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \n\u001b[0;32m     80\u001b[0m     \u001b[38;5;66;03m# y : (B, L, D)\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 83\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mambapy\\mamba.py:111\u001b[0m, in \u001b[0;36mResidualBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m# x : (B, L, D)\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m# output : (B, L, D)\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmixer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m x\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mambapy\\mamba.py:211\u001b[0m, in \u001b[0;36mMambaBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;66;03m# x : (B, L, D)\u001b[39;00m\n\u001b[0;32m    207\u001b[0m     \n\u001b[0;32m    208\u001b[0m     \u001b[38;5;66;03m# y : (B, L, D)\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m     _, L, _ \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    213\u001b[0m     xz \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj(x) \u001b[38;5;66;03m# (B, L, 2*ED)\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     x, z \u001b[38;5;241m=\u001b[39m xz\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# (B, L, ED), (B, L, ED)\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "# Define the model with your parameters\n",
    "d_model = 256 # Embedding dimension\n",
    "num_classes = 4  # Star classification categories\n",
    "\n",
    "# Define the training parameters\n",
    "num_epochs = 500\n",
    "lr = 2e-5\n",
    "patience = 50   \n",
    "depth = 2\n",
    "\n",
    "# Define the config dictionary object\n",
    "config = {\"num_classes\": num_classes, \"batch_size\": batch_size, \"lr\": lr, \"patience\": patience, \"num_epochs\": num_epochs, \"d_model\": d_model, \"depth\": depth}\n",
    "\n",
    "# Initialize WandB project\n",
    "wandb.init(project=\"fusion-mamba-test\", entity=\"joaoc-university-of-southampton\", config=config)\n",
    "# Initialize the dual model\n",
    "dual_model = DualMambaClassifier(\n",
    "    gaia_dim=17, spectra_dim=3748, d_model = d_model, num_classes=4, n_layers=depth\n",
    ")\n",
    "\n",
    "# Move the model to the device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "dual_model = dual_model.to(device)\n",
    "print(dual_model)\n",
    "# print number of parameters per layer\n",
    "for name, param in dual_model.named_parameters():\n",
    "    print(name, param.numel())\n",
    "print(\"Total number of parameters:\", sum(p.numel() for p in dual_model.parameters() if p.requires_grad))\n",
    "\n",
    "\n",
    "# Train the model using your `train_model_vit` or an adjusted training loop\n",
    "trained_model = train_model_mamba(\n",
    "    model=dual_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    num_epochs=num_epochs,\n",
    "    lr=lr,\n",
    "    max_patience=patience,\n",
    "    device=device\n",
    ")\n",
    "# Save the model and finish WandB session\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
