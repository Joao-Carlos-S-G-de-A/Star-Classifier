{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 18:22:31,524 - INFO - Gathering FITS files from pre-separated directories...\n",
      "2024-09-30 18:22:31,525 - INFO - Checking directory: training_set/gal_spectra\n",
      "2024-09-30 18:22:31,527 - INFO - Found 1699 files in training_set/gal_spectra\n",
      "2024-09-30 18:22:31,528 - INFO - Checking directory: training_set/star_spectra\n",
      "2024-09-30 18:22:31,567 - INFO - Found 86037 files in training_set/star_spectra\n",
      "2024-09-30 18:22:31,643 - INFO - Checking directory: training_set/agn_spectra\n",
      "2024-09-30 18:22:31,659 - INFO - Found 35936 files in training_set/agn_spectra\n",
      "2024-09-30 18:22:31,690 - INFO - Checking directory: training_set/bin_spectra\n",
      "2024-09-30 18:22:31,708 - INFO - Found 40676 files in training_set/bin_spectra\n",
      "2024-09-30 18:22:31,740 - INFO - Total spectra files collected: 164348\n",
      "2024-09-30 18:22:31,742 - INFO - Gathering FITS files from pre-separated directories...\n",
      "2024-09-30 18:22:31,743 - INFO - Checking directory: validation_set/gal_spectra\n",
      "2024-09-30 18:22:31,745 - INFO - Found 400 files in validation_set/gal_spectra\n",
      "2024-09-30 18:22:31,746 - INFO - Checking directory: validation_set/star_spectra\n",
      "2024-09-30 18:22:31,747 - INFO - Found 400 files in validation_set/star_spectra\n",
      "2024-09-30 18:22:31,748 - INFO - Checking directory: validation_set/agn_spectra\n",
      "2024-09-30 18:22:31,749 - INFO - Found 400 files in validation_set/agn_spectra\n",
      "2024-09-30 18:22:31,749 - INFO - Checking directory: validation_set/bin_spectra\n",
      "2024-09-30 18:22:31,750 - INFO - Found 400 files in validation_set/bin_spectra\n",
      "2024-09-30 18:22:31,751 - INFO - Total spectra files collected: 1600\n",
      "2024-09-30 18:35:45,749 - INFO - All FITS files converted to HDF5 and saved in training_h5\n",
      "2024-09-30 18:35:52,555 - INFO - All FITS files converted to HDF5 and saved in validation_h5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "from astropy.io import fits\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import random\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def convert_fits_to_h5(fits_file, h5_file, target_length=3748):\n",
    "    \"\"\"Converts a single FITS file to HDF5 format.\"\"\"\n",
    "    try:\n",
    "        with fits.open(fits_file) as hdul:\n",
    "            if len(hdul) > 0:  # Check if the Primary HDU exists\n",
    "                spectra_data = hdul[0].data  # Assuming the spectra data is in the Primary HDU\n",
    "                if spectra_data is not None:\n",
    "                    spectra_data = spectra_data[:target_length]  # Trim to target length if necessary\n",
    "                    \n",
    "                    # Save to HDF5\n",
    "                    with h5py.File(h5_file, 'w') as hf:\n",
    "                        hf.create_dataset('spectra', data=spectra_data)\n",
    "                else:\n",
    "                    logging.error(f\"{fits_file} does not contain data in the Primary HDU\")\n",
    "            else:\n",
    "                logging.error(f\"{fits_file} does not contain the expected HDU\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error converting {fits_file} to {h5_file}: {e}\")\n",
    "\n",
    "def batch_convert_fits_to_h5(file_list, target_dir, target_length=3748):\n",
    "    \"\"\"Convert a batch of FITS files to HDF5 format.\"\"\"\n",
    "    os.makedirs(target_dir, exist_ok=True)  # Create target directory if it doesn't exist\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(convert_fits_to_h5, fits_file, os.path.join(target_dir, os.path.splitext(os.path.basename(fits_file))[0] + \".h5\"), target_length) for fits_file in file_list]\n",
    "        for future in futures:\n",
    "            future.result()  # Wait for all threads to complete\n",
    "\n",
    "    logging.info(f\"All FITS files converted to HDF5 and saved in {target_dir}\")\n",
    "\n",
    "def generate_file_list_from_directories(base_dirs, limit_per_dir=10000):\n",
    "    \"\"\"Generates a list of files and labels from the pre-separated directories.\"\"\"\n",
    "    spectra_dirs = {\n",
    "        \"gal_spectra\": 0,  # Label 0 for galaxies\n",
    "        \"star_spectra\": 1,  # Label 1 for stars\n",
    "        \"agn_spectra\": 2,   # Label 2 for AGNs\n",
    "        \"bin_spectra\": 3    # Label 3 for binary stars\n",
    "    }\n",
    "\n",
    "    file_list = []\n",
    "    labels = []\n",
    "\n",
    "    logging.info(\"Gathering FITS files from pre-separated directories...\")\n",
    "    for dir_name, label in spectra_dirs.items():\n",
    "        for base_dir in base_dirs:\n",
    "            dir_path = os.path.join(base_dir, dir_name)\n",
    "            if os.path.exists(dir_path):\n",
    "                logging.info(f\"Checking directory: {dir_path}\")\n",
    "                dir_files = os.listdir(dir_path)\n",
    "                logging.info(f\"Found {len(dir_files)} files in {dir_path}\")\n",
    "\n",
    "                # Collect all files in the directory\n",
    "                for file in dir_files:\n",
    "                    file_path = os.path.join(dir_path, file)\n",
    "                    file_list.append(file_path)\n",
    "\n",
    "                # Randomly select files up to the limit\n",
    "                if len(file_list) > limit_per_dir:\n",
    "                    selected_files = random.sample(file_list, limit_per_dir)\n",
    "                else:\n",
    "                    selected_files = file_list\n",
    "\n",
    "                # Append selected files and their labels\n",
    "                labels.extend([label] * len(selected_files))\n",
    "\n",
    "    logging.info(f\"Total spectra files collected: {len(file_list)}\")\n",
    "    return file_list, labels\n",
    "\n",
    "# Convert all FITS files to HDF5\n",
    "train_files, train_labels = generate_file_list_from_directories([\"training_set\"], limit_per_dir=10000)\n",
    "val_files, val_labels = generate_file_list_from_directories([\"validation_set\"], limit_per_dir=10000)\n",
    "\n",
    "batch_convert_fits_to_h5(train_files, \"training_h5\")\n",
    "batch_convert_fits_to_h5(val_files, \"validation_h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 18:46:17,600 - INFO - Gathering FITS files from pre-separated directories...\n",
      "2024-09-30 18:46:17,601 - INFO - Checking directory: training_set/gal_spectra\n",
      "2024-09-30 18:46:17,603 - INFO - Found 1699 files in training_set/gal_spectra\n",
      "2024-09-30 18:46:17,604 - INFO - Checking directory: training_set/star_spectra\n",
      "2024-09-30 18:46:17,648 - INFO - Found 86037 files in training_set/star_spectra\n",
      "2024-09-30 18:46:17,710 - INFO - Checking directory: training_set/agn_spectra\n",
      "2024-09-30 18:46:17,726 - INFO - Found 35936 files in training_set/agn_spectra\n",
      "2024-09-30 18:46:17,754 - INFO - Checking directory: training_set/bin_spectra\n",
      "2024-09-30 18:46:17,770 - INFO - Found 40676 files in training_set/bin_spectra\n",
      "2024-09-30 18:46:17,806 - INFO - Total spectra files collected: 164348\n",
      "2024-09-30 18:46:17,808 - INFO - Gathering FITS files from pre-separated directories...\n",
      "2024-09-30 18:46:17,808 - INFO - Checking directory: validation_set/gal_spectra\n",
      "2024-09-30 18:46:17,810 - INFO - Found 400 files in validation_set/gal_spectra\n",
      "2024-09-30 18:46:17,811 - INFO - Checking directory: validation_set/star_spectra\n",
      "2024-09-30 18:46:17,812 - INFO - Found 400 files in validation_set/star_spectra\n",
      "2024-09-30 18:46:17,812 - INFO - Checking directory: validation_set/agn_spectra\n",
      "2024-09-30 18:46:17,813 - INFO - Found 400 files in validation_set/agn_spectra\n",
      "2024-09-30 18:46:17,814 - INFO - Checking directory: validation_set/bin_spectra\n",
      "2024-09-30 18:46:17,815 - INFO - Found 400 files in validation_set/bin_spectra\n",
      "2024-09-30 18:46:17,816 - INFO - Total spectra files collected: 1600\n",
      "2024-09-30 18:56:34,917 - INFO - All FITS files converted to NumPy arrays and saved in training_npy\n",
      "2024-09-30 18:56:40,549 - INFO - All FITS files converted to NumPy arrays and saved in validation_npy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import random\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def convert_fits_to_npy(fits_file, npy_file, target_length=3748):\n",
    "    \"\"\"Converts a single FITS file to NumPy format.\"\"\"\n",
    "    try:\n",
    "        with fits.open(fits_file) as hdul:\n",
    "            if len(hdul) > 0:  # Check if the Primary HDU exists\n",
    "                spectra_data = hdul[0].data  # Assuming the spectra data is in the Primary HDU\n",
    "                if spectra_data is not None:\n",
    "                    spectra_data = spectra_data[:target_length]  # Trim to target length if necessary\n",
    "                    \n",
    "                    # Save to NumPy array\n",
    "                    np.save(npy_file, spectra_data)\n",
    "                else:\n",
    "                    logging.error(f\"{fits_file} does not contain data in the Primary HDU\")\n",
    "            else:\n",
    "                logging.error(f\"{fits_file} does not contain the expected HDU\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error converting {fits_file} to {npy_file}: {e}\")\n",
    "\n",
    "def batch_convert_fits_to_npy(file_list, target_dir, target_length=3748):\n",
    "    \"\"\"Convert a batch of FITS files to NumPy format.\"\"\"\n",
    "    os.makedirs(target_dir, exist_ok=True)  # Create target directory if it doesn't exist\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(convert_fits_to_npy, fits_file, os.path.join(target_dir, os.path.splitext(os.path.basename(fits_file))[0] + \".npy\"), target_length) for fits_file in file_list]\n",
    "        for future in futures:\n",
    "            future.result()  # Wait for all threads to complete\n",
    "\n",
    "    logging.info(f\"All FITS files converted to NumPy arrays and saved in {target_dir}\")\n",
    "\n",
    "def generate_file_list_from_directories(base_dirs, limit_per_dir=10000):\n",
    "    \"\"\"Generates a list of files and labels from the pre-separated directories.\"\"\"\n",
    "    spectra_dirs = {\n",
    "        \"gal_spectra\": 0,  # Label 0 for galaxies\n",
    "        \"star_spectra\": 1,  # Label 1 for stars\n",
    "        \"agn_spectra\": 2,   # Label 2 for AGNs\n",
    "        \"bin_spectra\": 3    # Label 3 for binary stars\n",
    "    }\n",
    "\n",
    "    file_list = []\n",
    "    labels = []\n",
    "\n",
    "    logging.info(\"Gathering FITS files from pre-separated directories...\")\n",
    "    for dir_name, label in spectra_dirs.items():\n",
    "        for base_dir in base_dirs:\n",
    "            dir_path = os.path.join(base_dir, dir_name)\n",
    "            if os.path.exists(dir_path):\n",
    "                logging.info(f\"Checking directory: {dir_path}\")\n",
    "                dir_files = os.listdir(dir_path)\n",
    "                logging.info(f\"Found {len(dir_files)} files in {dir_path}\")\n",
    "\n",
    "                # Collect all files in the directory\n",
    "                for file in dir_files:\n",
    "                    file_path = os.path.join(dir_path, file)\n",
    "                    file_list.append(file_path)\n",
    "\n",
    "                # Randomly select files up to the limit\n",
    "                if len(file_list) > limit_per_dir:\n",
    "                    selected_files = random.sample(file_list, limit_per_dir)\n",
    "                else:\n",
    "                    selected_files = file_list\n",
    "\n",
    "                # Append selected files and their labels\n",
    "                labels.extend([label] * len(selected_files))\n",
    "\n",
    "    logging.info(f\"Total spectra files collected: {len(file_list)}\")\n",
    "    return file_list, labels\n",
    "\n",
    "# Convert all FITS files to NumPy arrays\n",
    "train_files, train_labels = generate_file_list_from_directories([\"training_set\"], limit_per_dir=10000)\n",
    "val_files, val_labels = generate_file_list_from_directories([\"validation_set\"], limit_per_dir=10000)\n",
    "\n",
    "batch_convert_fits_to_npy(train_files, \"training_npy\")\n",
    "batch_convert_fits_to_npy(val_files, \"validation_npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
