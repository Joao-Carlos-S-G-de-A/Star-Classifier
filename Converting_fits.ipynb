{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 18:22:31,524 - INFO - Gathering FITS files from pre-separated directories...\n",
      "2024-09-30 18:22:31,525 - INFO - Checking directory: training_set/gal_spectra\n",
      "2024-09-30 18:22:31,527 - INFO - Found 1699 files in training_set/gal_spectra\n",
      "2024-09-30 18:22:31,528 - INFO - Checking directory: training_set/star_spectra\n",
      "2024-09-30 18:22:31,567 - INFO - Found 86037 files in training_set/star_spectra\n",
      "2024-09-30 18:22:31,643 - INFO - Checking directory: training_set/agn_spectra\n",
      "2024-09-30 18:22:31,659 - INFO - Found 35936 files in training_set/agn_spectra\n",
      "2024-09-30 18:22:31,690 - INFO - Checking directory: training_set/bin_spectra\n",
      "2024-09-30 18:22:31,708 - INFO - Found 40676 files in training_set/bin_spectra\n",
      "2024-09-30 18:22:31,740 - INFO - Total spectra files collected: 164348\n",
      "2024-09-30 18:22:31,742 - INFO - Gathering FITS files from pre-separated directories...\n",
      "2024-09-30 18:22:31,743 - INFO - Checking directory: validation_set/gal_spectra\n",
      "2024-09-30 18:22:31,745 - INFO - Found 400 files in validation_set/gal_spectra\n",
      "2024-09-30 18:22:31,746 - INFO - Checking directory: validation_set/star_spectra\n",
      "2024-09-30 18:22:31,747 - INFO - Found 400 files in validation_set/star_spectra\n",
      "2024-09-30 18:22:31,748 - INFO - Checking directory: validation_set/agn_spectra\n",
      "2024-09-30 18:22:31,749 - INFO - Found 400 files in validation_set/agn_spectra\n",
      "2024-09-30 18:22:31,749 - INFO - Checking directory: validation_set/bin_spectra\n",
      "2024-09-30 18:22:31,750 - INFO - Found 400 files in validation_set/bin_spectra\n",
      "2024-09-30 18:22:31,751 - INFO - Total spectra files collected: 1600\n",
      "2024-09-30 18:35:45,749 - INFO - All FITS files converted to HDF5 and saved in training_h5\n",
      "2024-09-30 18:35:52,555 - INFO - All FITS files converted to HDF5 and saved in validation_h5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "from astropy.io import fits\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import random\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def convert_fits_to_h5(fits_file, h5_file, target_length=3748):\n",
    "    \"\"\"Converts a single FITS file to HDF5 format.\"\"\"\n",
    "    try:\n",
    "        with fits.open(fits_file) as hdul:\n",
    "            if len(hdul) > 0:  # Check if the Primary HDU exists\n",
    "                spectra_data = hdul[0].data  # Assuming the spectra data is in the Primary HDU\n",
    "                if spectra_data is not None:\n",
    "                    spectra_data = spectra_data[:target_length]  # Trim to target length if necessary\n",
    "                    \n",
    "                    # Save to HDF5\n",
    "                    with h5py.File(h5_file, 'w') as hf:\n",
    "                        hf.create_dataset('spectra', data=spectra_data)\n",
    "                else:\n",
    "                    logging.error(f\"{fits_file} does not contain data in the Primary HDU\")\n",
    "            else:\n",
    "                logging.error(f\"{fits_file} does not contain the expected HDU\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error converting {fits_file} to {h5_file}: {e}\")\n",
    "\n",
    "def batch_convert_fits_to_h5(file_list, target_dir, target_length=3748):\n",
    "    \"\"\"Convert a batch of FITS files to HDF5 format.\"\"\"\n",
    "    os.makedirs(target_dir, exist_ok=True)  # Create target directory if it doesn't exist\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(convert_fits_to_h5, fits_file, os.path.join(target_dir, os.path.splitext(os.path.basename(fits_file))[0] + \".h5\"), target_length) for fits_file in file_list]\n",
    "        for future in futures:\n",
    "            future.result()  # Wait for all threads to complete\n",
    "\n",
    "    logging.info(f\"All FITS files converted to HDF5 and saved in {target_dir}\")\n",
    "\n",
    "def generate_file_list_from_directories(base_dirs, limit_per_dir=10000):\n",
    "    \"\"\"Generates a list of files and labels from the pre-separated directories.\"\"\"\n",
    "    spectra_dirs = {\n",
    "        \"gal_spectra\": 0,  # Label 0 for galaxies\n",
    "        \"star_spectra\": 1,  # Label 1 for stars\n",
    "        \"agn_spectra\": 2,   # Label 2 for AGNs\n",
    "        \"bin_spectra\": 3    # Label 3 for binary stars\n",
    "    }\n",
    "\n",
    "    file_list = []\n",
    "    labels = []\n",
    "\n",
    "    logging.info(\"Gathering FITS files from pre-separated directories...\")\n",
    "    for dir_name, label in spectra_dirs.items():\n",
    "        for base_dir in base_dirs:\n",
    "            dir_path = os.path.join(base_dir, dir_name)\n",
    "            if os.path.exists(dir_path):\n",
    "                logging.info(f\"Checking directory: {dir_path}\")\n",
    "                dir_files = os.listdir(dir_path)\n",
    "                logging.info(f\"Found {len(dir_files)} files in {dir_path}\")\n",
    "\n",
    "                # Collect all files in the directory\n",
    "                for file in dir_files:\n",
    "                    file_path = os.path.join(dir_path, file)\n",
    "                    file_list.append(file_path)\n",
    "\n",
    "                # Randomly select files up to the limit\n",
    "                if len(file_list) > limit_per_dir:\n",
    "                    selected_files = random.sample(file_list, limit_per_dir)\n",
    "                else:\n",
    "                    selected_files = file_list\n",
    "\n",
    "                # Append selected files and their labels\n",
    "                labels.extend([label] * len(selected_files))\n",
    "\n",
    "    logging.info(f\"Total spectra files collected: {len(file_list)}\")\n",
    "    return file_list, labels\n",
    "\n",
    "# Convert all FITS files to HDF5\n",
    "train_files, train_labels = generate_file_list_from_directories([\"training_set\"], limit_per_dir=10000)\n",
    "val_files, val_labels = generate_file_list_from_directories([\"validation_set\"], limit_per_dir=10000)\n",
    "\n",
    "batch_convert_fits_to_h5(train_files, \"training_h5\")\n",
    "batch_convert_fits_to_h5(val_files, \"validation_h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-01 16:07:01,158 - INFO - Gathering FITS files from pre-separated directories...\n",
      "2024-10-01 16:07:01,160 - INFO - Total spectra files collected: 0\n",
      "2024-10-01 16:07:01,161 - INFO - Gathering FITS files from pre-separated directories...\n",
      "2024-10-01 16:07:01,162 - INFO - Total spectra files collected: 0\n",
      "2024-10-01 16:07:01,164 - INFO - All FITS files converted to NumPy arrays and saved in training_npy/bin_spectra\n",
      "2024-10-01 16:07:01,166 - INFO - All FITS files converted to NumPy arrays and saved in validation_npy/bin_spectra\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import random\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def convert_fits_to_npy(fits_file, npy_file, target_length=3748):\n",
    "    \"\"\"Converts a single FITS file to NumPy format.\"\"\"\n",
    "    try:\n",
    "        with fits.open(fits_file) as hdul:\n",
    "            if len(hdul) > 0:  # Check if the Primary HDU exists\n",
    "                spectra_data = hdul[0].data  # Assuming the spectra data is in the Primary HDU\n",
    "                if spectra_data is not None:\n",
    "                    spectra_data = spectra_data[:target_length]  # Trim to target length if necessary\n",
    "                    \n",
    "                    # Save to NumPy array\n",
    "                    np.save(npy_file, spectra_data)\n",
    "                else:\n",
    "                    logging.error(f\"{fits_file} does not contain data in the Primary HDU\")\n",
    "            else:\n",
    "                logging.error(f\"{fits_file} does not contain the expected HDU\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error converting {fits_file} to {npy_file}: {e}\")\n",
    "\n",
    "def batch_convert_fits_to_npy(file_list, target_dir, target_length=3748):\n",
    "    \"\"\"Convert a batch of FITS files to NumPy format.\"\"\"\n",
    "    os.makedirs(target_dir, exist_ok=True)  # Create target directory if it doesn't exist\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(convert_fits_to_npy, fits_file, os.path.join(target_dir, os.path.splitext(os.path.basename(fits_file))[0] + \".npy\"), target_length) for fits_file in file_list]\n",
    "        for future in futures:\n",
    "            future.result()  # Wait for all threads to complete\n",
    "\n",
    "    logging.info(f\"All FITS files converted to NumPy arrays and saved in {target_dir}\")\n",
    "\n",
    "def generate_file_list_from_directories(base_dirs, limit_per_dir=10000):\n",
    "    \"\"\"Generates a list of files and labels from the pre-separated directories.\"\"\"\n",
    "    spectra_dirs = {\n",
    "        \"gal_spectra\": 0,  # Label 0 for galaxies\n",
    "        \"star_spectra\": 1,  # Label 1 for stars\n",
    "        \"agn_spectra\": 2,   # Label 2 for AGNs\n",
    "        \"bin_spectra\": 3    # Label 3 for binary stars\n",
    "    }\n",
    "\n",
    "    file_list = []\n",
    "    labels = []\n",
    "\n",
    "    logging.info(\"Gathering FITS files from pre-separated directories...\")\n",
    "    for dir_name, label in spectra_dirs.items():\n",
    "        for base_dir in base_dirs:\n",
    "            dir_path = os.path.join(base_dir, dir_name)\n",
    "            if os.path.exists(dir_path):\n",
    "                logging.info(f\"Checking directory: {dir_path}\")\n",
    "                dir_files = os.listdir(dir_path)\n",
    "                logging.info(f\"Found {len(dir_files)} files in {dir_path}\")\n",
    "\n",
    "                # Collect all files in the directory\n",
    "                for file in dir_files:\n",
    "                    file_path = os.path.join(dir_path, file)\n",
    "                    file_list.append(file_path)\n",
    "\n",
    "                # Randomly select files up to the limit\n",
    "                if len(file_list) > limit_per_dir:\n",
    "                    selected_files = random.sample(file_list, limit_per_dir)\n",
    "                else:\n",
    "                    selected_files = file_list\n",
    "\n",
    "                # Append selected files and their labels\n",
    "                labels.extend([label] * len(selected_files))\n",
    "\n",
    "    logging.info(f\"Total spectra files collected: {len(file_list)}\")\n",
    "    return file_list, labels\n",
    "\n",
    "# Convert all FITS files to NumPy arrays\n",
    "train_files, train_labels = generate_file_list_from_directories([\"training_set/bin_spectra\"], limit_per_dir=10000)\n",
    "val_files, val_labels = generate_file_list_from_directories([\"validation_set/bin_spectra\"], limit_per_dir=10000)\n",
    "\n",
    "batch_convert_fits_to_npy(train_files, \"training_npy/bin_spectra\")\n",
    "batch_convert_fits_to_npy(val_files, \"validation_npy/bin_spectra\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-01 16:12:43,251 - INFO - Gathering FITS files from pre-separated directories...\n",
      "2024-10-01 16:12:43,253 - INFO - Checking directory: training_set/gal_spectra\n",
      "2024-10-01 16:12:43,258 - INFO - Found 1699 files in training_set/gal_spectra\n",
      "2024-10-01 16:12:43,261 - INFO - Checking directory: training_set/star_spectra\n",
      "2024-10-01 16:12:43,430 - INFO - Found 86037 files in training_set/star_spectra\n",
      "2024-10-01 16:12:43,494 - INFO - Checking directory: training_set/agn_spectra\n",
      "2024-10-01 16:12:43,561 - INFO - Found 35936 files in training_set/agn_spectra\n",
      "2024-10-01 16:12:43,585 - INFO - Checking directory: training_set/bin_spectra\n",
      "2024-10-01 16:12:43,655 - INFO - Found 40676 files in training_set/bin_spectra\n",
      "2024-10-01 16:12:43,686 - INFO - Total spectra files collected: 31699\n",
      "2024-10-01 16:12:43,689 - INFO - Gathering FITS files from pre-separated directories...\n",
      "2024-10-01 16:12:43,690 - INFO - Checking directory: validation_set/gal_spectra\n",
      "2024-10-01 16:12:43,692 - INFO - Found 400 files in validation_set/gal_spectra\n",
      "2024-10-01 16:12:43,693 - INFO - Checking directory: validation_set/star_spectra\n",
      "2024-10-01 16:12:43,694 - INFO - Found 400 files in validation_set/star_spectra\n",
      "2024-10-01 16:12:43,694 - INFO - Checking directory: validation_set/agn_spectra\n",
      "2024-10-01 16:12:43,696 - INFO - Found 400 files in validation_set/agn_spectra\n",
      "2024-10-01 16:12:43,697 - INFO - Checking directory: validation_set/bin_spectra\n",
      "2024-10-01 16:12:43,698 - INFO - Found 400 files in validation_set/bin_spectra\n",
      "2024-10-01 16:12:43,699 - INFO - Total spectra files collected: 1600\n",
      "2024-10-01 16:14:22,208 - INFO - All FITS files converted to NumPy arrays and saved in training_npy\n",
      "2024-10-01 16:14:27,041 - INFO - All FITS files converted to NumPy arrays and saved in validation_npy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import random\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def convert_fits_to_npy(fits_file, npy_file, target_length=3748):\n",
    "    \"\"\"Converts a single FITS file to NumPy format.\"\"\"\n",
    "    try:\n",
    "        with fits.open(fits_file) as hdul:\n",
    "            if len(hdul) > 0:  # Check if the Primary HDU exists\n",
    "                spectra_data = hdul[0].data  # Assuming the spectra data is in the Primary HDU\n",
    "                if spectra_data is not None:\n",
    "                    spectra_data = spectra_data[:target_length]  # Trim to target length if necessary\n",
    "                    \n",
    "                    # Save to NumPy array\n",
    "                    np.save(npy_file, spectra_data)\n",
    "                else:\n",
    "                    logging.error(f\"{fits_file} does not contain data in the Primary HDU\")\n",
    "            else:\n",
    "                logging.error(f\"{fits_file} does not contain the expected HDU\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error converting {fits_file} to {npy_file}: {e}\")\n",
    "\n",
    "def batch_convert_fits_to_npy(file_list, target_dir, target_length=3748):\n",
    "    \"\"\"Convert a batch of FITS files to NumPy format.\"\"\"\n",
    "    os.makedirs(target_dir, exist_ok=True)  # Create target directory if it doesn't exist\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(convert_fits_to_npy, fits_file, os.path.join(target_dir, os.path.splitext(os.path.basename(fits_file))[0] + \".npy\"), target_length) for fits_file in file_list]\n",
    "        for future in futures:\n",
    "            future.result()  # Wait for all threads to complete\n",
    "\n",
    "    logging.info(f\"All FITS files converted to NumPy arrays and saved in {target_dir}\")\n",
    "\n",
    "def generate_file_list_from_directories(base_dirs, limit_per_dir=10000):\n",
    "    \"\"\"Generates a list of files and labels from the pre-separated directories.\"\"\"\n",
    "    spectra_dirs = {\n",
    "        \"gal_spectra\": 0,  # Label 0 for galaxies\n",
    "        \"star_spectra\": 1,  # Label 1 for stars\n",
    "        \"agn_spectra\": 2,   # Label 2 for AGNs\n",
    "        \"bin_spectra\": 3    # Label 3 for binary stars\n",
    "    }\n",
    "\n",
    "    file_list = []\n",
    "    labels = []\n",
    "\n",
    "    logging.info(\"Gathering FITS files from pre-separated directories...\")\n",
    "    for dir_name, label in spectra_dirs.items():\n",
    "        for base_dir in base_dirs:\n",
    "            dir_path = os.path.join(base_dir, dir_name)\n",
    "            if os.path.exists(dir_path):\n",
    "                logging.info(f\"Checking directory: {dir_path}\")\n",
    "                dir_files = os.listdir(dir_path)\n",
    "                logging.info(f\"Found {len(dir_files)} files in {dir_path}\")\n",
    "\n",
    "                # Collect all files in the directory\n",
    "                current_file_list = []\n",
    "                for file in dir_files:\n",
    "                    file_path = os.path.join(dir_path, file)\n",
    "                    current_file_list.append(file_path)\n",
    "\n",
    "                # Randomly select files up to the limit\n",
    "                if len(current_file_list) > limit_per_dir:\n",
    "                    selected_files = random.sample(current_file_list, limit_per_dir)\n",
    "                else:\n",
    "                    selected_files = current_file_list\n",
    "\n",
    "                # Append selected files and their labels\n",
    "                file_list.extend(selected_files)\n",
    "                labels.extend([label] * len(selected_files))\n",
    "\n",
    "    logging.info(f\"Total spectra files collected: {len(file_list)}\")\n",
    "    return file_list, labels\n",
    "\n",
    "# Convert all FITS files to NumPy arrays\n",
    "train_files, train_labels = generate_file_list_from_directories([\"training_set\"], limit_per_dir=10000)\n",
    "val_files, val_labels = generate_file_list_from_directories([\"validation_set\"], limit_per_dir=10000)\n",
    "\n",
    "batch_convert_fits_to_npy(train_files, \"training_npy\")\n",
    "batch_convert_fits_to_npy(val_files, \"validation_npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-01 16:29:04,900 - INFO - Gathering FITS files from pre-separated directories...\n",
      "2024-10-01 16:29:04,901 - INFO - Checking directory: training_set/gal_spectra\n",
      "2024-10-01 16:29:04,905 - INFO - Found 1699 files in training_set/gal_spectra\n",
      "2024-10-01 16:29:04,907 - INFO - Checking directory: training_set/star_spectra\n",
      "2024-10-01 16:29:05,062 - INFO - Found 86037 files in training_set/star_spectra\n",
      "2024-10-01 16:29:05,114 - INFO - Checking directory: training_set/agn_spectra\n",
      "2024-10-01 16:29:05,174 - INFO - Found 35936 files in training_set/agn_spectra\n",
      "2024-10-01 16:29:05,198 - INFO - Checking directory: training_set/bin_spectra\n",
      "2024-10-01 16:29:05,264 - INFO - Found 40676 files in training_set/bin_spectra\n",
      "2024-10-01 16:29:05,289 - INFO - Total spectra files collected: 31699\n",
      "2024-10-01 16:29:05,293 - INFO - Gathering FITS files from pre-separated directories...\n",
      "2024-10-01 16:29:05,294 - INFO - Checking directory: validation_set/gal_spectra\n",
      "2024-10-01 16:29:05,296 - INFO - Found 400 files in validation_set/gal_spectra\n",
      "2024-10-01 16:29:05,297 - INFO - Checking directory: validation_set/star_spectra\n",
      "2024-10-01 16:29:05,298 - INFO - Found 400 files in validation_set/star_spectra\n",
      "2024-10-01 16:29:05,299 - INFO - Checking directory: validation_set/agn_spectra\n",
      "2024-10-01 16:29:05,301 - INFO - Found 400 files in validation_set/agn_spectra\n",
      "2024-10-01 16:29:05,302 - INFO - Checking directory: validation_set/bin_spectra\n",
      "2024-10-01 16:29:05,303 - INFO - Found 400 files in validation_set/bin_spectra\n",
      "2024-10-01 16:29:05,304 - INFO - Total spectra files collected: 1600\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 90\u001b[0m\n\u001b[1;32m     87\u001b[0m train_files, train_labels \u001b[38;5;241m=\u001b[39m generate_file_list_from_directories([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_set\u001b[39m\u001b[38;5;124m\"\u001b[39m], limit_per_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)\n\u001b[1;32m     88\u001b[0m val_files, val_labels \u001b[38;5;241m=\u001b[39m generate_file_list_from_directories([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_set\u001b[39m\u001b[38;5;124m\"\u001b[39m], limit_per_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)\n\u001b[0;32m---> 90\u001b[0m \u001b[43mbatch_convert_fits_to_npy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m batch_convert_fits_to_npy(val_files, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 34\u001b[0m, in \u001b[0;36mbatch_convert_fits_to_npy\u001b[0;34m(file_list, base_target_dir, target_length)\u001b[0m\n\u001b[1;32m     31\u001b[0m futures \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fits_file \u001b[38;5;129;01min\u001b[39;00m file_list:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Determine the subdirectory structure\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     sub_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrelpath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(fits_file), start\u001b[38;5;241m=\u001b[39m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommonpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_list\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     35\u001b[0m     target_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_target_dir, sub_dir)\n\u001b[1;32m     36\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(target_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Create target subdirectory if it doesn't exist\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/posixpath.py:522\u001b[0m, in \u001b[0;36mcommonpath\u001b[0;34m(paths)\u001b[0m\n\u001b[1;32m    519\u001b[0m     curdir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 522\u001b[0m     split_paths \u001b[38;5;241m=\u001b[39m [path\u001b[38;5;241m.\u001b[39msplit(sep) \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m paths]\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    525\u001b[0m         isabs, \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(p[:\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m sep \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m paths)\n",
      "File \u001b[0;32m/usr/lib/python3.10/posixpath.py:522\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    519\u001b[0m     curdir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 522\u001b[0m     split_paths \u001b[38;5;241m=\u001b[39m [\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msep\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m paths]\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    525\u001b[0m         isabs, \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(p[:\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m sep \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m paths)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-01 16:54:31,427 - INFO - Gathering FITS files from pre-separated directories...\n",
      "2024-10-01 16:54:31,428 - INFO - Checking directory: training_set/gal_spectra\n",
      "2024-10-01 16:54:31,430 - INFO - Found 1699 files in training_set/gal_spectra\n",
      "2024-10-01 16:54:31,431 - INFO - Checking directory: training_set/star_spectra\n",
      "2024-10-01 16:54:31,462 - INFO - Found 86037 files in training_set/star_spectra\n",
      "2024-10-01 16:54:31,515 - INFO - Checking directory: training_set/agn_spectra\n",
      "2024-10-01 16:54:31,529 - INFO - Found 35936 files in training_set/agn_spectra\n",
      "2024-10-01 16:54:31,551 - INFO - Checking directory: training_set/bin_spectra\n",
      "2024-10-01 16:54:31,566 - INFO - Found 40676 files in training_set/bin_spectra\n",
      "2024-10-01 16:54:31,591 - INFO - Total spectra files collected: 164348\n",
      "2024-10-01 16:54:31,593 - INFO - Gathering FITS files from pre-separated directories...\n",
      "2024-10-01 16:54:31,594 - INFO - Checking directory: validation_set/gal_spectra\n",
      "2024-10-01 16:54:31,595 - INFO - Found 400 files in validation_set/gal_spectra\n",
      "2024-10-01 16:54:31,596 - INFO - Checking directory: validation_set/star_spectra\n",
      "2024-10-01 16:54:31,596 - INFO - Found 400 files in validation_set/star_spectra\n",
      "2024-10-01 16:54:31,597 - INFO - Checking directory: validation_set/agn_spectra\n",
      "2024-10-01 16:54:31,598 - INFO - Found 400 files in validation_set/agn_spectra\n",
      "2024-10-01 16:54:31,598 - INFO - Checking directory: validation_set/bin_spectra\n",
      "2024-10-01 16:54:31,599 - INFO - Found 400 files in validation_set/bin_spectra\n",
      "2024-10-01 16:54:31,599 - INFO - Total spectra files collected: 1600\n",
      "Converting FITS to NumPy:   0%|          | 362/164348 [03:02<24:04:07,  1.89it/s]Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7efe1edb6c80>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcwind/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n",
      "Converting FITS to NumPy:   0%|          | 384/164348 [03:15<24:45:38,  1.84it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm  # Added for progress bar\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def convert_fits_to_npy(fits_file, npy_file, target_length=3748):\n",
    "    \"\"\"Converts a single FITS file to NumPy format.\"\"\"\n",
    "    try:\n",
    "        with fits.open(fits_file) as hdul:\n",
    "            if len(hdul) > 0:  # Check if the Primary HDU exists\n",
    "                spectra_data = hdul[0].data  # Assuming the spectra data is in the Primary HDU\n",
    "                if spectra_data is not None:\n",
    "                    spectra_data = spectra_data[:target_length]  # Trim to target length if necessary\n",
    "                    \n",
    "                    # Save to NumPy array\n",
    "                    np.save(npy_file, spectra_data)\n",
    "                else:\n",
    "                    logging.error(f\"{fits_file} does not contain data in the Primary HDU\")\n",
    "            else:\n",
    "                logging.error(f\"{fits_file} does not contain the expected HDU\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error converting {fits_file} to {npy_file}: {e}\")\n",
    "\n",
    "def batch_convert_fits_to_npy(file_list, base_target_dir, target_length=3748, max_workers=8):\n",
    "    \"\"\"Convert a batch of FITS files to NumPy format.\"\"\"\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        for fits_file in tqdm(file_list, desc=\"Converting FITS to NumPy\"):  # Added progress bar\n",
    "            # Determine the subdirectory structure\n",
    "            sub_dir = os.path.relpath(os.path.dirname(fits_file), start=os.path.commonpath(file_list))\n",
    "            target_dir = os.path.join(base_target_dir, sub_dir)\n",
    "            os.makedirs(target_dir, exist_ok=True)  # Create target subdirectory if it doesn't exist\n",
    "            \n",
    "            npy_file = os.path.join(target_dir, os.path.splitext(os.path.basename(fits_file))[0] + \".npy\")\n",
    "            futures.append(executor.submit(convert_fits_to_npy, fits_file, npy_file, target_length))\n",
    "        \n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing conversions\"):\n",
    "            future.result()  # Wait for all threads to complete\n",
    "\n",
    "    logging.info(f\"All FITS files converted to NumPy arrays and saved in {base_target_dir}\")\n",
    "\n",
    "def generate_file_list_from_directories(base_dirs, limit_per_dir=10000):\n",
    "    \"\"\"Generates a list of files and labels from the pre-separated directories.\"\"\"\n",
    "    spectra_dirs = {\n",
    "        \"gal_spectra\": 0,  # Label 0 for galaxies\n",
    "        \"star_spectra\": 1,  # Label 1 for stars\n",
    "        \"agn_spectra\": 2,   # Label 2 for AGNs\n",
    "        \"bin_spectra\": 3    # Label 3 for binary stars\n",
    "    }\n",
    "\n",
    "    file_list = []\n",
    "    labels = []\n",
    "\n",
    "    logging.info(\"Gathering FITS files from pre-separated directories...\")\n",
    "    for dir_name, label in spectra_dirs.items():\n",
    "        for base_dir in base_dirs:\n",
    "            dir_path = os.path.join(base_dir, dir_name)\n",
    "            if os.path.exists(dir_path):\n",
    "                logging.info(f\"Checking directory: {dir_path}\")\n",
    "                dir_files = os.listdir(dir_path)\n",
    "                logging.info(f\"Found {len(dir_files)} files in {dir_path}\")\n",
    "\n",
    "                # Collect all files in the directory\n",
    "                current_file_list = []\n",
    "                for file in dir_files:\n",
    "                    file_path = os.path.join(dir_path, file)\n",
    "                    current_file_list.append(file_path)\n",
    "\n",
    "                # Randomly select files up to the limit\n",
    "                if len(current_file_list) > limit_per_dir:\n",
    "                    selected_files = random.sample(current_file_list, limit_per_dir)\n",
    "                else:\n",
    "                    selected_files = current_file_list\n",
    "\n",
    "                # Append selected files and their labels\n",
    "                file_list.extend(selected_files)\n",
    "                labels.extend([label] * len(selected_files))\n",
    "\n",
    "    logging.info(f\"Total spectra files collected: {len(file_list)}\")\n",
    "    return file_list, labels\n",
    "\n",
    "# Convert all FITS files to NumPy arrays\n",
    "train_files, train_labels = generate_file_list_from_directories([\"training_set\"], limit_per_dir=1000000)\n",
    "val_files, val_labels = generate_file_list_from_directories([\"validation_set\"], limit_per_dir=1000000)\n",
    "\n",
    "batch_convert_fits_to_npy(train_files, \"training_npy\", max_workers=10000)  # Adjust max_workers for more threads\n",
    "batch_convert_fits_to_npy(val_files, \"validation_npy\", max_workers=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 12:31:22,304 - INFO - Gathering FITS files from pre-separated directories...\n",
      "2024-10-02 12:31:22,305 - INFO - Checking directory: training_set/gal_spectra\n",
      "2024-10-02 12:31:22,310 - INFO - Found 1699 files in training_set/gal_spectra\n",
      "2024-10-02 12:31:22,312 - INFO - Checking directory: training_set/star_spectra\n",
      "2024-10-02 12:31:22,468 - INFO - Found 86037 files in training_set/star_spectra\n",
      "2024-10-02 12:31:22,516 - INFO - Checking directory: training_set/agn_spectra\n",
      "2024-10-02 12:31:22,578 - INFO - Found 35936 files in training_set/agn_spectra\n",
      "2024-10-02 12:31:22,598 - INFO - Checking directory: training_set/bin_spectra\n",
      "2024-10-02 12:31:22,666 - INFO - Found 40676 files in training_set/bin_spectra\n",
      "2024-10-02 12:31:22,689 - INFO - Total spectra files collected: 164348\n",
      "2024-10-02 12:31:22,691 - INFO - Gathering FITS files from pre-separated directories...\n",
      "2024-10-02 12:31:22,691 - INFO - Checking directory: validation_set/gal_spectra\n",
      "2024-10-02 12:31:22,693 - INFO - Found 400 files in validation_set/gal_spectra\n",
      "2024-10-02 12:31:22,694 - INFO - Checking directory: validation_set/star_spectra\n",
      "2024-10-02 12:31:22,695 - INFO - Found 400 files in validation_set/star_spectra\n",
      "2024-10-02 12:31:22,696 - INFO - Checking directory: validation_set/agn_spectra\n",
      "2024-10-02 12:31:22,698 - INFO - Found 400 files in validation_set/agn_spectra\n",
      "2024-10-02 12:31:22,698 - INFO - Checking directory: validation_set/bin_spectra\n",
      "2024-10-02 12:31:22,699 - INFO - Found 400 files in validation_set/bin_spectra\n",
      "2024-10-02 12:31:22,700 - INFO - Total spectra files collected: 1600\n",
      "Converting FITS to NumPy:   0%|          | 340/164348 [02:49<22:46:15,  2.00it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 88\u001b[0m\n\u001b[1;32m     85\u001b[0m train_files, train_labels \u001b[38;5;241m=\u001b[39m generate_file_list_from_directories([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_set\u001b[39m\u001b[38;5;124m\"\u001b[39m], limit_per_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000000\u001b[39m)\n\u001b[1;32m     86\u001b[0m val_files, val_labels \u001b[38;5;241m=\u001b[39m generate_file_list_from_directories([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_set\u001b[39m\u001b[38;5;124m\"\u001b[39m], limit_per_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000000\u001b[39m)\n\u001b[0;32m---> 88\u001b[0m \u001b[43mbatch_convert_fits_to_npy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust max_workers for more threads\u001b[39;00m\n\u001b[1;32m     89\u001b[0m batch_convert_fits_to_npy(val_files, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_npy\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 32\u001b[0m, in \u001b[0;36mbatch_convert_fits_to_npy\u001b[0;34m(file_list, base_target_dir, target_length, max_workers)\u001b[0m\n\u001b[1;32m     29\u001b[0m futures \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fits_file \u001b[38;5;129;01min\u001b[39;00m tqdm(file_list, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting FITS to NumPy\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Determine the subdirectory structure\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     sub_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrelpath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(fits_file), start\u001b[38;5;241m=\u001b[39m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommonpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_list\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     33\u001b[0m     target_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_target_dir, sub_dir)\n\u001b[1;32m     34\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(target_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/posixpath.py:529\u001b[0m, in \u001b[0;36mcommonpath\u001b[0;34m(paths)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt mix absolute and relative paths\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 529\u001b[0m split_paths \u001b[38;5;241m=\u001b[39m [[c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m s \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mand\u001b[39;00m c \u001b[38;5;241m!=\u001b[39m curdir] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m split_paths]\n\u001b[1;32m    530\u001b[0m s1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(split_paths)\n\u001b[1;32m    531\u001b[0m s2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(split_paths)\n",
      "File \u001b[0;32m/usr/lib/python3.10/posixpath.py:529\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt mix absolute and relative paths\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 529\u001b[0m split_paths \u001b[38;5;241m=\u001b[39m [[c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m s \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mand\u001b[39;00m c \u001b[38;5;241m!=\u001b[39m curdir] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m split_paths]\n\u001b[1;32m    530\u001b[0m s1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(split_paths)\n\u001b[1;32m    531\u001b[0m s2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(split_paths)\n",
      "File \u001b[0;32m/usr/lib/python3.10/posixpath.py:529\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt mix absolute and relative paths\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 529\u001b[0m split_paths \u001b[38;5;241m=\u001b[39m [[c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m s \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mand\u001b[39;00m c \u001b[38;5;241m!=\u001b[39m curdir] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m split_paths]\n\u001b[1;32m    530\u001b[0m s1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(split_paths)\n\u001b[1;32m    531\u001b[0m s2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(split_paths)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # Progress bar\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def convert_fits_to_npy(fits_file, npy_file, target_length=3748):\n",
    "    \"\"\"Converts a single FITS file to NumPy format, focusing on the first row and first 3748 columns.\"\"\"\n",
    "    try:\n",
    "        with fits.open(fits_file, memmap=True) as hdul:  # Enable memory mapping for efficiency\n",
    "            spectra_data = hdul[0].data  # Assuming the spectra data is in the Primary HDU\n",
    "            if spectra_data is not None and spectra_data.shape[0] > 0:\n",
    "                # Only extract the first row and the first `target_length` columns\n",
    "                spectra_data = spectra_data[0, :target_length]\n",
    "                \n",
    "                # Save to NumPy array\n",
    "                np.save(npy_file, spectra_data)\n",
    "            else:\n",
    "                logging.error(f\"{fits_file} does not contain valid data in the Primary HDU\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error converting {fits_file} to {npy_file}: {e}\")\n",
    "\n",
    "def batch_convert_fits_to_npy(file_list, base_target_dir, target_length=3748, max_workers=8):\n",
    "    \"\"\"Convert a batch of FITS files to NumPy format.\"\"\"\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        for fits_file in tqdm(file_list, desc=\"Converting FITS to NumPy\"):\n",
    "            # Determine the subdirectory structure\n",
    "            sub_dir = os.path.relpath(os.path.dirname(fits_file), start=os.path.commonpath(file_list))\n",
    "            target_dir = os.path.join(base_target_dir, sub_dir)\n",
    "            os.makedirs(target_dir, exist_ok=True)\n",
    "            \n",
    "            npy_file = os.path.join(target_dir, os.path.splitext(os.path.basename(fits_file))[0] + \".npy\")\n",
    "            futures.append(executor.submit(convert_fits_to_npy, fits_file, npy_file, target_length))\n",
    "        \n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing conversions\"):\n",
    "            future.result()\n",
    "\n",
    "    logging.info(f\"All FITS files converted to NumPy arrays and saved in {base_target_dir}\")\n",
    "\n",
    "def generate_file_list_from_directories(base_dirs, limit_per_dir=10000):\n",
    "    \"\"\"Generates a list of files and labels from the pre-separated directories.\"\"\"\n",
    "    spectra_dirs = {\n",
    "        \"gal_spectra\": 0,  # Label 0 for galaxies\n",
    "        \"star_spectra\": 1,  # Label 1 for stars\n",
    "        \"agn_spectra\": 2,   # Label 2 for AGNs\n",
    "        \"bin_spectra\": 3    # Label 3 for binary stars\n",
    "    }\n",
    "\n",
    "    file_list = []\n",
    "    labels = []\n",
    "\n",
    "    logging.info(\"Gathering FITS files from pre-separated directories...\")\n",
    "    for dir_name, label in spectra_dirs.items():\n",
    "        for base_dir in base_dirs:\n",
    "            dir_path = os.path.join(base_dir, dir_name)\n",
    "            if os.path.exists(dir_path):\n",
    "                logging.info(f\"Checking directory: {dir_path}\")\n",
    "                dir_files = os.listdir(dir_path)\n",
    "                logging.info(f\"Found {len(dir_files)} files in {dir_path}\")\n",
    "\n",
    "                # Collect all files in the directory\n",
    "                current_file_list = []\n",
    "                for file in dir_files:\n",
    "                    file_path = os.path.join(dir_path, file)\n",
    "                    current_file_list.append(file_path)\n",
    "\n",
    "                # Randomly select files up to the limit\n",
    "                if len(current_file_list) > limit_per_dir:\n",
    "                    selected_files = random.sample(current_file_list, limit_per_dir)\n",
    "                else:\n",
    "                    selected_files = current_file_list\n",
    "\n",
    "                # Append selected files and their labels\n",
    "                file_list.extend(selected_files)\n",
    "                labels.extend([label] * len(selected_files))\n",
    "\n",
    "    logging.info(f\"Total spectra files collected: {len(file_list)}\")\n",
    "    return file_list, labels\n",
    "\n",
    "# Convert all FITS files to NumPy arrays\n",
    "train_files, train_labels = generate_file_list_from_directories([\"training_set\"], limit_per_dir=1000000)\n",
    "val_files, val_labels = generate_file_list_from_directories([\"validation_set\"], limit_per_dir=1000000)\n",
    "\n",
    "batch_convert_fits_to_npy(train_files, \"training_npy\", max_workers=10000)  # Adjust max_workers for more threads\n",
    "batch_convert_fits_to_npy(val_files, \"validation_npy\", max_workers=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
