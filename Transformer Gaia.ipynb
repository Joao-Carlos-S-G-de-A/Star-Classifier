{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Create dataset classes (using your BalancedDataset approach) and training function\n",
    "class BalancedDataset(Dataset):\n",
    "    def __init__(self, X, y, limit_per_label=1600):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.limit_per_label = limit_per_label\n",
    "        self.classes = np.unique(y)\n",
    "        self.indices = self.balance_classes()\n",
    "\n",
    "    def balance_classes(self):\n",
    "        indices = []\n",
    "        for cls in self.classes:\n",
    "            cls_indices = np.where(self.y == cls)[0]\n",
    "            if len(cls_indices) > self.limit_per_label:\n",
    "                cls_indices = np.random.choice(cls_indices, self.limit_per_label, replace=False)\n",
    "            indices.extend(cls_indices)\n",
    "        np.random.shuffle(indices)\n",
    "        return indices\n",
    "\n",
    "    def re_sample(self):\n",
    "        self.indices = self.balance_classes()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        index = self.indices[idx]\n",
    "        return self.X[index], self.y[index]\n",
    "# Custom Dataset for validation with limit per class\n",
    "class BalancedValidationDataset(Dataset):\n",
    "    def __init__(self, X, y, limit_per_label=400):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.limit_per_label = limit_per_label\n",
    "        self.classes = np.unique(y)\n",
    "        self.indices = self.balance_classes()\n",
    "\n",
    "    def balance_classes(self):\n",
    "        indices = []\n",
    "        for cls in self.classes:\n",
    "            cls_indices = np.where(self.y == cls)[0]\n",
    "            if len(cls_indices) > self.limit_per_label:\n",
    "                cls_indices = np.random.choice(cls_indices, self.limit_per_label, replace=False)\n",
    "            indices.extend(cls_indices)\n",
    "        np.random.shuffle(indices)\n",
    "        return indices\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        index = self.indices[idx]\n",
    "        return self.X[index], self.y[index]\n",
    "# Training function (similar to your ConvNet setup but using WandB)\n",
    "def train_model_vit(model, train_loader, val_loader, test_loader, num_epochs=500, lr=1e-4, max_patience=5, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_test_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Re-sample training data at the start of each epoch\n",
    "        train_loader.dataset.re_sample()\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * X_batch.size(0)\n",
    "            train_accuracy = (outputs.argmax(dim=1) == y_batch).float().mean()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in val_loader:\n",
    "                X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "                outputs = model(X_val)\n",
    "                loss = criterion(outputs, y_val)\n",
    "                val_loss += loss.item() * X_val.size(0)\n",
    "                val_accuracy = (outputs.argmax(dim=1) == y_val).float().mean()\n",
    "        \n",
    "        # Test phase\n",
    "        test_loss = 0.0\n",
    "        test_accuracy = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_test, y_test in test_loader:\n",
    "                X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "                outputs = model(X_test)\n",
    "                loss = criterion(outputs, y_test)\n",
    "                test_loss += loss.item() * X_test.size(0)\n",
    "                test_accuracy = (outputs.argmax(dim=1) == y_test).float().mean()\n",
    "\n",
    "\n",
    "        # Log metrics to WandB\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss, \"epoch\": epoch, \n",
    "                   \"train_accuracy\": train_accuracy.item(), \"val_accuracy\": val_accuracy.item(), \n",
    "                   \"test_accuracy\": test_accuracy.item(), \"test_loss\": test_loss})\n",
    "        \n",
    "        # Early stopping\n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            patience = max_patience\n",
    "        else:\n",
    "            patience -= 1\n",
    "            if patience <= 0:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    return model\n",
    "class VisionTransformer1D(nn.Module):\n",
    "    def __init__(self, input_size=3748, num_classes=4, patch_size=5, dim=128, depth=12, heads=16, mlp_dim=256, dropout=0.2):\n",
    "        super(VisionTransformer1D, self).__init__()\n",
    "\n",
    "        # Store patch size and dimensionality for embedding\n",
    "        self.patch_size = patch_size\n",
    "        self.dim = dim\n",
    "\n",
    "        # Patch Embedding layer\n",
    "        self.patch_embed = nn.Linear(patch_size, dim)\n",
    "\n",
    "        # Positional Encoding (initialize to a reasonable size, but we’ll adjust it dynamically)\n",
    "        max_patches = (input_size + patch_size - 1) // patch_size  # Approximate max patches\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, max_patches, dim))\n",
    "\n",
    "        # Transformer blocks\n",
    "        self.transformer = nn.TransformerEncoder(nn.TransformerEncoderLayer(dim, heads, mlp_dim, dropout), depth)\n",
    "\n",
    "        # MLP Head\n",
    "        self.fc = nn.Sequential(nn.LayerNorm(dim), nn.Linear(dim, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Handle input dimensions and ensure padding for patch divisibility\n",
    "        batch_size, channels, seq_len = x.shape  # Assuming x has 3 dimensions\n",
    "        x = x.squeeze(1) if channels == 1 else x  # Remove channel dimension if it's 1\n",
    "\n",
    "        # Calculate required padding for divisibility by patch_size and pad input\n",
    "        pad_length = (self.patch_size - (seq_len % self.patch_size)) % self.patch_size\n",
    "        x = nn.functional.pad(x, (0, pad_length))\n",
    "        \n",
    "        # Dynamically calculate number of patches after padding\n",
    "        num_patches = x.size(1) // self.patch_size\n",
    "        x = x.view(batch_size, num_patches, self.patch_size)  # Reshape to patches\n",
    "        \n",
    "        # Embed patches and add positional encoding (resize pos_embedding if needed)\n",
    "        if self.pos_embedding.size(1) != num_patches:\n",
    "            self.pos_embedding = nn.Parameter(self.pos_embedding[:, :num_patches, :])\n",
    "        x = self.patch_embed(x) + self.pos_embedding\n",
    "\n",
    "        # Transformer forward pass\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        # Classify based on the first token representation\n",
    "        x = self.fc(x[:, 0])\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Main script to load data and train the model\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    X = pd.read_pickle(\"Pickles/train.pkl\")\n",
    "    y = X[\"label\"]\n",
    "    label_mapping = {'star': 0, 'binary_star': 1, 'galaxy': 2, 'agn': 3}\n",
    "    y = y.map(label_mapping).values\n",
    "    columns = [\"parallax\", \"ra\", \"dec\", \"ra_error\", \"dec_error\", \"parallax_error\", \"pmra\", \"pmdec\", \"pmra_error\", \"pmdec_error\", \n",
    "           \"phot_g_mean_flux\", \"flagnopllx\", \"phot_g_mean_flux_error\", \"phot_bp_mean_flux\", \"phot_rp_mean_flux\", \n",
    "           \"phot_bp_mean_flux_error\", \"phot_rp_mean_flux_error\"]\n",
    "    X = X[columns]\n",
    "    \n",
    "    # Read test data\n",
    "    X_test = pd.read_pickle(\"Pickles/test.pkl\")\n",
    "    y_test = X_test[\"label\"].map(label_mapping).values\n",
    "    X_test = X_test[columns]\n",
    "\n",
    "    # Convert test data to torch tensors\n",
    "    X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)  # Convert DataFrame to NumPy array first\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    # Create the test dataset without the unsqueeze\n",
    "    test_dataset = BalancedValidationDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "    # Create the DataLoader\n",
    "    test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Clear memory\n",
    "    del X, y\n",
    "    gc.collect()\n",
    "\n",
    "    # Convert to torch tensors and create datasets\n",
    "    X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "    X_val = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "    y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "    train_dataset = BalancedDataset(X_train, y_train)\n",
    "    val_dataset = BalancedValidationDataset(X_val, y_val)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding overlapping patches to the VisionTransformer1D model\n",
    "class VisionTransformer1D(nn.Module):\n",
    "    def __init__(self, input_size=17, num_classes=4, patch_size=20, overlap=0.5, dim=128, depth=12, heads=16, mlp_dim=256, dropout=0.2):\n",
    "        super(VisionTransformer1D, self).__init__()\n",
    "\n",
    "        # Store patch size, overlap, and dimensionality for embedding\n",
    "        self.patch_size = patch_size\n",
    "        self.overlap = overlap\n",
    "        self.dim = dim\n",
    "\n",
    "        # Calculate the stride based on the overlap percentage\n",
    "        self.stride = int(patch_size * (1 - overlap))\n",
    "        \n",
    "        # Patch Embedding layer\n",
    "        self.patch_embed = nn.Linear(patch_size, dim)\n",
    "\n",
    "        # Positional Encoding\n",
    "        max_patches = (input_size - patch_size) // self.stride + 1  # Dynamically calculated max patches\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, max_patches, dim))\n",
    "\n",
    "        # Transformer blocks\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(dim, heads, mlp_dim, dropout), depth\n",
    "        )\n",
    "\n",
    "        # MLP Head\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.shape # channels is 1\n",
    "\n",
    "        # Calculate the number of patches with overlap and extract overlapping patches\n",
    "        num_patches = (seq_len - self.patch_size) // self.stride + 1\n",
    "        patches = [x[:, i * self.stride : i * self.stride + self.patch_size]\n",
    "            for i in range(num_patches)]\n",
    "        x = torch.stack(patches, dim=1)  # Shape: (batch_size, num_patches, patch_size)\n",
    "\n",
    "        # Embed patches and add positional encoding\n",
    "        x = self.patch_embed(x) + self.pos_embedding[:, :num_patches, :]\n",
    "\n",
    "        # Transformer forward pass\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        # Classify based on the first token representation\n",
    "        x = self.fc(x[:, 0])\n",
    "\n",
    "        return x\n",
    "    \n",
    "# Adding overlapping patches to the VisionTransformer1D model\n",
    "class VisionTransformer1D(nn.Module):\n",
    "    def __init__(self, input_size=3748, num_classes=4, patch_size=20, overlap=0.5, dim=128, depth=12, heads=16, mlp_dim=256, dropout=0.2):\n",
    "        super(VisionTransformer1D, self).__init__()\n",
    "\n",
    "        # Store patch size, overlap, and dimensionality for embedding\n",
    "        self.patch_size = patch_size\n",
    "        self.overlap = overlap\n",
    "        self.dim = dim\n",
    "\n",
    "        # Calculate the stride based on the overlap percentage\n",
    "        self.stride = int(patch_size * (1 - overlap))\n",
    "        \n",
    "        # Patch Embedding layer\n",
    "        self.patch_embed = nn.Linear(patch_size, dim)\n",
    "\n",
    "        # Positional Encoding\n",
    "        max_patches = (input_size - patch_size) // self.stride + 1  # Dynamically calculated max patches\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, max_patches, dim))\n",
    "\n",
    "        # Transformer blocks\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(dim, heads, mlp_dim, dropout), depth\n",
    "        )\n",
    "\n",
    "        # MLP Head\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.shape # channels is 1\n",
    "\n",
    "        # Calculate the number of patches with overlap and extract overlapping patches\n",
    "        num_patches = (seq_len - self.patch_size) // self.stride + 1\n",
    "        patches = [x[:, i * self.stride : i * self.stride + self.patch_size]\n",
    "            for i in range(num_patches)]\n",
    "        x = torch.stack(patches, dim=1)  # Shape: (batch_size, num_patches, patch_size)\n",
    "\n",
    "        # Embed patches and add positional encoding\n",
    "        x = self.patch_embed(x) + self.pos_embedding[:, :num_patches, :]\n",
    "\n",
    "        # Transformer forward pass\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        # Classify based on the first token representation\n",
    "        x = self.fc(x[:, 0])\n",
    "\n",
    "        return x       \n",
    "\n",
    "\n",
    "\n",
    "# Training function with learning rate scheduler\n",
    "def train_model_vit(model, train_loader, val_loader, test_loader, num_epochs=500, lr=1e-4, max_patience=20, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=int(max_patience/5), verbose=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_test_loss = float('inf')\n",
    "    patience = max_patience\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loader.dataset.re_sample()\n",
    "        model.train()\n",
    "        train_loss, train_accuracy = 0.0, 0.0\n",
    "        \n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * X_batch.size(0)\n",
    "            train_accuracy += (outputs.argmax(dim=1) == y_batch).float().mean().item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss, val_accuracy = 0.0, 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in val_loader:\n",
    "                X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "                outputs = model(X_val)\n",
    "                loss = criterion(outputs, y_val)\n",
    "                val_loss += loss.item() * X_val.size(0)\n",
    "                val_accuracy += (outputs.argmax(dim=1) == y_val).float().mean().item()\n",
    "        \n",
    "        # Test phase\n",
    "        test_loss, test_accuracy = 0.0, 0.0\n",
    "        y_true, y_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for X_test, y_test in test_loader:\n",
    "                X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "                outputs = model(X_test)\n",
    "                loss = criterion(outputs, y_test)\n",
    "                test_loss += loss.item() * X_test.size(0)\n",
    "                test_accuracy += (outputs.argmax(dim=1) == y_test).float().mean().item()\n",
    "                y_true.extend(y_test.cpu().numpy())\n",
    "                y_pred.extend(outputs.argmax(dim=1).cpu().numpy())\n",
    "        \n",
    "        # Scheduler step\n",
    "        scheduler.step(test_loss / len(test_loader.dataset))\n",
    "\n",
    "        # Log metrics to WandB\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": train_loss / len(train_loader.dataset),\n",
    "            \"val_loss\": val_loss / len(val_loader.dataset),\n",
    "            \"train_accuracy\": train_accuracy / len(train_loader),\n",
    "            \"val_accuracy\": val_accuracy / len(val_loader),\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "            \"test_loss\": test_loss / len(test_loader.dataset),\n",
    "            \"test_accuracy\": test_accuracy / len(test_loader),\n",
    "            \"confusion_matrix\": wandb.plot.confusion_matrix(probs=None,\n",
    "                y_true=y_true, preds=y_pred, class_names=np.unique(y_true)),\n",
    "            \"classification_report\": classification_report(y_true, y_pred, target_names=label_mapping.keys())\n",
    "        })\n",
    "        \n",
    "        # Early stopping\n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            patience = max_patience\n",
    "        else:\n",
    "            patience -= 1\n",
    "            if patience <= 0:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\jcwin\\OneDrive - University of Southampton\\_Southampton\\2024-25\\Star-Classifier\\wandb\\run-20241104_162328-fbeu8a98</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/joaoc-university-of-southampton/gaia-crossvit/runs/fbeu8a98' target=\"_blank\">graceful-shape-5</a></strong> to <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-crossvit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-crossvit' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/gaia-crossvit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-crossvit/runs/fbeu8a98' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/gaia-crossvit/runs/fbeu8a98</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇█████</td></tr><tr><td>learning_rate</td><td>████████████████████████████▄▄▄▃▃▂▂▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁▂▃▃▃▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇████████████████</td></tr><tr><td>test_loss</td><td>█▇▆▅▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▂▄▆▇▇▇▇▇▇▇▇▇▇█▇███████████████████████</td></tr><tr><td>train_loss</td><td>█▇▄▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▂▄▄▄▄▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇█▇███████████████</td></tr><tr><td>val_loss</td><td>█▇▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>classification_report</td><td>              precis...</td></tr><tr><td>epoch</td><td>182</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>test_accuracy</td><td>0.86563</td></tr><tr><td>test_loss</td><td>0.35289</td></tr><tr><td>train_accuracy</td><td>0.83149</td></tr><tr><td>train_loss</td><td>0.39434</td></tr><tr><td>val_accuracy</td><td>0.83192</td></tr><tr><td>val_loss</td><td>0.38979</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">graceful-shape-5</strong> at: <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-crossvit/runs/fbeu8a98' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/gaia-crossvit/runs/fbeu8a98</a><br/> View project at: <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-crossvit' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/gaia-crossvit</a><br/>Synced 5 W&B file(s), 0 media file(s), 334 artifact file(s) and 183 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241104_162328-fbeu8a98\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "class CrossAttentionBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm, has_mlp=True):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = CrossAttention(\n",
    "            dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
    "        # NOTE: drop path for stochastic depth, we shall see if this is better than dropout here\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.has_mlp = has_mlp\n",
    "        if has_mlp:\n",
    "            self.norm2 = norm_layer(dim)\n",
    "            mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "            self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x[:, 0:1, ...] + self.drop_path(self.attn(self.norm1(x)))\n",
    "        if self.has_mlp:\n",
    "            x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "class VisionTransformer1D(nn.Module):\n",
    "    def __init__(self, input_size=3748, num_classes=4, patch_sizes=[20, 40], overlap=0.5, dim=128, depth=6, heads=8, mlp_dim=256, dropout=0.2):\n",
    "        super(VisionTransformer1D, self).__init__()\n",
    "        self.num_branches = len(patch_sizes)\n",
    "        self.dim = dim\n",
    "        self.overlap = overlap\n",
    "        self.branches = nn.ModuleList()\n",
    "        \n",
    "        # Set up branches for different patch sizes\n",
    "        for patch_size in patch_sizes:\n",
    "            stride = int(patch_size * (1 - overlap))\n",
    "            max_patches = (input_size - patch_size) // stride + 1\n",
    "            patch_embed = nn.Linear(patch_size, dim)\n",
    "            pos_embedding = nn.Parameter(torch.randn(1, max_patches, dim))\n",
    "            transformer = nn.TransformerEncoder(\n",
    "                nn.TransformerEncoderLayer(dim, heads, mlp_dim, dropout), depth\n",
    "            )\n",
    "            self.branches.append(nn.ModuleDict({\n",
    "                'patch_embed': patch_embed,\n",
    "                'pos_embedding': pos_embedding,\n",
    "                'transformer': transformer\n",
    "            }))\n",
    "        \n",
    "        # Cross-Attention for fusion of multiple patch sizes\n",
    "        self.cross_attention = CrossAttentionBlock(dim, heads)\n",
    "        \n",
    "        # Classification head\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.shape  # channels is 1\n",
    "        branch_outputs = []\n",
    "        \n",
    "        # Extract patches, embed, and process with transformer for each branch\n",
    "        for branch in self.branches:\n",
    "            patch_size = branch['patch_embed'].in_features\n",
    "            stride = int(patch_size * (1 - self.overlap))\n",
    "            num_patches = (seq_len - patch_size) // stride + 1\n",
    "            patches = [x[:, i * stride : i * stride + patch_size] for i in range(num_patches)]\n",
    "            x_branch = torch.stack(patches, dim=1)  # Shape: (batch_size, num_patches, patch_size)\n",
    "            x_branch = branch['patch_embed'](x_branch) + branch['pos_embedding'][:, :num_patches, :]\n",
    "            x_branch = branch['transformer'](x_branch)\n",
    "            branch_outputs.append(x_branch)\n",
    "\n",
    "        # Apply cross-attention to combine the representations from each branch\n",
    "        x_fused = torch.cat(branch_outputs, dim=1)  # Concatenate along sequence dimension\n",
    "        x_fused = self.cross_attention(x_fused)\n",
    "\n",
    "        # Classification based on the first token representation\n",
    "        x = self.fc(x_fused[:, 0])\n",
    "        return x\n",
    "    \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import wandb\n",
    "from timm.models.layers import DropPath, to_2tuple, trunc_normal_\n",
    "from timm.models.registry import register_model\n",
    "from timm.models.vision_transformer import _cfg, Mlp, Block\n",
    "\n",
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        # NOTE scale factor was wrong in my original version, can set manually to be compat with prev weights\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        self.wq = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        self.wk = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        self.wv = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        B, N, C = x.shape\n",
    "        q = self.wq(x[:, 0:1, ...]).reshape(B, 1, self.num_heads, C // self.num_heads).permute(0, 2, 1, 3)  # B1C -> B1H(C/H) -> BH1(C/H)\n",
    "        k = self.wk(x).reshape(B, N, self.num_heads, C // self.num_heads).permute(0, 2, 1, 3)  # BNC -> BNH(C/H) -> BHN(C/H)\n",
    "        v = self.wv(x).reshape(B, N, self.num_heads, C // self.num_heads).permute(0, 2, 1, 3)  # BNC -> BNH(C/H) -> BHN(C/H)\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale  # BH1(C/H) @ BH(C/H)N -> BH1N\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, 1, C)   # (BH1N @ BHN(C/H)) -> BH1(C/H) -> B1H(C/H) -> B1C\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CrossAttentionBlock(nn.Module):\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm, has_mlp=True):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = CrossAttention(\n",
    "            dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.has_mlp = has_mlp\n",
    "        if has_mlp:\n",
    "            self.norm2 = norm_layer(dim)\n",
    "            mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "            self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x[:, 0:1, ...] + self.drop_path(self.attn(self.norm1(x)))\n",
    "        if self.has_mlp:\n",
    "            x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "class VisionTransformer1D(nn.Module):\n",
    "    def __init__(self, input_size=3748, num_classes=4, patch_sizes=[20, 40], overlap=0.5, dim=128, depth=6, heads=8, mlp_dim=256, dropout=0.2):\n",
    "        super(VisionTransformer1D, self).__init__()\n",
    "        self.num_branches = len(patch_sizes)\n",
    "        self.dim = dim\n",
    "        self.overlap = overlap\n",
    "        self.branches = nn.ModuleList()\n",
    "        \n",
    "        # Set up branches for different patch sizes\n",
    "        for patch_size in patch_sizes:\n",
    "            stride = int(patch_size * (1 - overlap))\n",
    "            max_patches = (input_size - patch_size) // stride + 1\n",
    "            patch_embed = nn.Linear(patch_size, dim)\n",
    "            pos_embedding = nn.Embedding(max_patches, dim)  # Changed to nn.Embedding to act as a module\n",
    "            transformer = nn.TransformerEncoder(\n",
    "                nn.TransformerEncoderLayer(dim, heads, mlp_dim, dropout), depth\n",
    "            )\n",
    "            self.branches.append(nn.ModuleDict({\n",
    "                'patch_embed': patch_embed,\n",
    "                'pos_embedding': pos_embedding,\n",
    "                'transformer': transformer\n",
    "            }))\n",
    "        \n",
    "        # Cross-Attention for fusion of multiple patch sizes\n",
    "        self.cross_attention = CrossAttentionBlock(dim, heads)\n",
    "        \n",
    "        # Classification head\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.shape\n",
    "        branch_outputs = []\n",
    "        \n",
    "        # Extract patches, embed, and process with transformer for each branch\n",
    "        for branch in self.branches:\n",
    "            patch_size = branch['patch_embed'].in_features\n",
    "            stride = int(patch_size * (1 - self.overlap))\n",
    "            num_patches = (seq_len - patch_size) // stride + 1\n",
    "            patches = [x[:, i * stride : i * stride + patch_size] for i in range(num_patches)]\n",
    "            x_branch = torch.stack(patches, dim=1)\n",
    "            x_branch = branch['patch_embed'](x_branch) + branch['pos_embedding'](torch.arange(num_patches, device=x.device)).unsqueeze(0)\n",
    "            x_branch = branch['transformer'](x_branch)\n",
    "            branch_outputs.append(x_branch)\n",
    "\n",
    "        # Apply cross-attention to combine the representations from each branch\n",
    "        x_fused = torch.cat(branch_outputs, dim=1)\n",
    "        x_fused = self.cross_attention(x_fused)\n",
    "\n",
    "        # Classification based on the first token representation\n",
    "        x = self.fc(x_fused[:, 0])\n",
    "        return x\n",
    "\n",
    "# Define the hyperparameters and train as before\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the hyperparameters\n",
    "num_classes = 4\n",
    "patch_sizes=[1, 17]\n",
    "dim = 64\n",
    "depth = 7\n",
    "heads = 8\n",
    "mlp_dim = 64\n",
    "dropout = 0.3\n",
    "batch_size = 512\n",
    "lr = 0.0001\n",
    "patience = 30\n",
    "num_epochs = 200\n",
    "\n",
    "\n",
    "# Define the config dictionary object\n",
    "config = {\"num_classes\": num_classes, \"patch_size\": patch_sizes, \"dim\": dim, \"depth\": depth, \"heads\": heads, \"mlp_dim\": mlp_dim, \n",
    "          \"dropout\": dropout, \"batch_size\": batch_size, \"lr\": lr, \"patience\": patience}\n",
    "\n",
    "# Initialize WandB project\n",
    "wandb.init(project=\"gaia-crossvit\", entity=\"joaoc-university-of-southampton\", config=config)\n",
    "# Initialize and train the model\n",
    "model_vit = VisionTransformer1D(input_size=17, num_classes=num_classes, patch_sizes=patch_sizes, dim=dim, depth=depth, heads=heads, mlp_dim=mlp_dim, dropout=dropout, overlap=0)\n",
    "trained_model = train_model_vit(model_vit, train_loader, val_loader, test_loader, num_epochs=num_epochs, lr=lr, max_patience=patience)\n",
    "\n",
    "# Save the model and finish WandB session\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\jcwin\\OneDrive - University of Southampton\\_Southampton\\2024-25\\Star-Classifier\\wandb\\run-20241104_165345-iow38gl1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/joaoc-university-of-southampton/gaia-crossvit/runs/iow38gl1' target=\"_blank\">absurd-meadow-7</a></strong> to <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-crossvit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-crossvit' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/gaia-crossvit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-crossvit/runs/iow38gl1' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/gaia-crossvit/runs/iow38gl1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import wandb\n",
    "from timm.models.layers import DropPath, to_2tuple, trunc_normal_\n",
    "from timm.models.registry import register_model\n",
    "from timm.models.vision_transformer import _cfg, Mlp, Block\n",
    "\n",
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        # NOTE scale factor was wrong in my original version, can set manually to be compat with prev weights\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        self.wq = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        self.wk = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        self.wv = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        B, N, C = x.shape\n",
    "        q = self.wq(x[:, 0:1, ...]).reshape(B, 1, self.num_heads, C // self.num_heads).permute(0, 2, 1, 3)  # B1C -> B1H(C/H) -> BH1(C/H)\n",
    "        k = self.wk(x).reshape(B, N, self.num_heads, C // self.num_heads).permute(0, 2, 1, 3)  # BNC -> BNH(C/H) -> BHN(C/H)\n",
    "        v = self.wv(x).reshape(B, N, self.num_heads, C // self.num_heads).permute(0, 2, 1, 3)  # BNC -> BNH(C/H) -> BHN(C/H)\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale  # BH1(C/H) @ BH(C/H)N -> BH1N\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, 1, C)   # (BH1N @ BHN(C/H)) -> BH1(C/H) -> B1H(C/H) -> B1C\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CrossAttentionBlock(nn.Module):\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm, has_mlp=True):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = CrossAttention(\n",
    "            dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.has_mlp = has_mlp\n",
    "        if has_mlp:\n",
    "            self.norm2 = norm_layer(dim)\n",
    "            mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "            self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x[:, 0:1, ...] + self.drop_path(self.attn(self.norm1(x)))\n",
    "        if self.has_mlp:\n",
    "            x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "class VisionTransformer1D(nn.Module):\n",
    "    def __init__(self, input_size=3748, num_classes=4, patch_sizes=[20, 40], overlap=0.5, dim=128, depth=6, heads=8, mlp_dim=256, dropout=0.2):\n",
    "        super(VisionTransformer1D, self).__init__()\n",
    "        self.num_branches = len(patch_sizes)\n",
    "        self.dim = dim\n",
    "        self.overlap = overlap\n",
    "        self.branches = nn.ModuleList()\n",
    "        \n",
    "        # Set up branches for different patch sizes\n",
    "        for patch_size in patch_sizes:\n",
    "            stride = int(patch_size * (1 - overlap))\n",
    "            max_patches = (input_size - patch_size) // stride + 1\n",
    "            patch_embed = nn.Linear(patch_size, dim)\n",
    "            pos_embedding = nn.Embedding(max_patches, dim)  # Changed to nn.Embedding to act as a module\n",
    "            transformer = nn.TransformerEncoder(\n",
    "                nn.TransformerEncoderLayer(dim, heads, mlp_dim, dropout), depth\n",
    "            )\n",
    "            self.branches.append(nn.ModuleDict({\n",
    "                'patch_embed': patch_embed,\n",
    "                'pos_embedding': pos_embedding,\n",
    "                'transformer': transformer\n",
    "            }))\n",
    "        \n",
    "        # Cross-Attention for fusion of multiple patch sizes\n",
    "        self.cross_attention = CrossAttentionBlock(dim, heads)\n",
    "        \n",
    "        # Classification head\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.shape\n",
    "        branch_outputs = []\n",
    "        \n",
    "        # Extract patches, embed, and process with transformer for each branch\n",
    "        for branch in self.branches:\n",
    "            patch_size = branch['patch_embed'].in_features\n",
    "            stride = int(patch_size * (1 - self.overlap))\n",
    "            num_patches = (seq_len - patch_size) // stride + 1\n",
    "            patches = [x[:, i * stride : i * stride + patch_size] for i in range(num_patches)]\n",
    "            x_branch = torch.stack(patches, dim=1)\n",
    "            x_branch = branch['patch_embed'](x_branch) + branch['pos_embedding'](torch.arange(num_patches, device=x.device)).unsqueeze(0)\n",
    "            x_branch = branch['transformer'](x_branch)\n",
    "            branch_outputs.append(x_branch)\n",
    "\n",
    "        # Apply cross-attention to combine the representations from each branch\n",
    "        x_fused = torch.cat(branch_outputs, dim=1)\n",
    "        x_fused = self.cross_attention(x_fused)\n",
    "\n",
    "        # Classification based on the first token representation\n",
    "        x = self.fc(x_fused[:, 0])\n",
    "        return x\n",
    "\n",
    "# Define the hyperparameters and train as before\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the hyperparameters\n",
    "num_classes = 4\n",
    "patch_sizes=[1, 3, 17]\n",
    "dim = 64\n",
    "depth = 7\n",
    "heads = 8\n",
    "mlp_dim = 64\n",
    "dropout = 0.3\n",
    "batch_size = 512\n",
    "lr = 0.0001\n",
    "patience = 30\n",
    "num_epochs = 200\n",
    "\n",
    "\n",
    "# Define the config dictionary object\n",
    "config = {\"num_classes\": num_classes, \"patch_size\": patch_sizes, \"dim\": dim, \"depth\": depth, \"heads\": heads, \"mlp_dim\": mlp_dim, \n",
    "          \"dropout\": dropout, \"batch_size\": batch_size, \"lr\": lr, \"patience\": patience}\n",
    "\n",
    "# Initialize WandB project\n",
    "wandb.init(project=\"gaia-crossvit\", entity=\"joaoc-university-of-southampton\", config=config)\n",
    "# Initialize and train the model\n",
    "model_vit = VisionTransformer1D(num_classes=num_classes, patch_sizes=patch_sizes, dim=dim, depth=depth, heads=heads, mlp_dim=mlp_dim, dropout=dropout, overlap=0)\n",
    "trained_model = train_model_vit(model_vit, train_loader, val_loader, test_loader, num_epochs=num_epochs, lr=lr, max_patience=patience)\n",
    "\n",
    "# Save the model and finish WandB session\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:tmi4egk9) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▃▄▅▅▅▆▆▇▆▇▇▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>█▇▅▃▃▃▃▂▂▂▂▂▁▁▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▃▂▂▂▆▆▇▆▇▇▇█▇▇████</td></tr><tr><td>val_loss</td><td>█▇▃▆▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>train_accuracy</td><td>0.60379</td></tr><tr><td>train_loss</td><td>0.86367</td></tr><tr><td>val_accuracy</td><td>0.62737</td></tr><tr><td>val_loss</td><td>0.84139</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">worthy-dew-12</strong> at: <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-vit/runs/tmi4egk9' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/gaia-vit/runs/tmi4egk9</a><br/> View project at: <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-vit' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/gaia-vit</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241104_150848-tmi4egk9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:tmi4egk9). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\jcwin\\OneDrive - University of Southampton\\_Southampton\\2024-25\\Star-Classifier\\wandb\\run-20241104_151040-taul22vs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/joaoc-university-of-southampton/gaia-vit/runs/taul22vs' target=\"_blank\">youthful-deluge-13</a></strong> to <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-vit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-vit' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/gaia-vit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-vit/runs/taul22vs' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/gaia-vit/runs/taul22vs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d422bb88bed14d02a95c42a78d4b46fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.159 MB of 0.159 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇████</td></tr><tr><td>learning_rate</td><td>██████████████▄▄▄▄▄▄▄▄▄▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁▆▇▇▇▇▇▇▇▇█▇█▇█▇████████████████████████</td></tr><tr><td>test_loss</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇███▇▇▇████████████████▇</td></tr><tr><td>train_loss</td><td>█▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▄▅▄▆▇▆▅▇▇▇▇▇█▇████████████████████████</td></tr><tr><td>val_loss</td><td>█▇▆▇▄▅▃▃▃▃▂▂▃▂▂▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>classification_report</td><td>              precis...</td></tr><tr><td>epoch</td><td>150</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>test_accuracy</td><td>0.64268</td></tr><tr><td>test_loss</td><td>0.78574</td></tr><tr><td>train_accuracy</td><td>0.62849</td></tr><tr><td>train_loss</td><td>0.82283</td></tr><tr><td>val_accuracy</td><td>0.6684</td></tr><tr><td>val_loss</td><td>0.80992</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">youthful-deluge-13</strong> at: <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-vit/runs/taul22vs' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/gaia-vit/runs/taul22vs</a><br/> View project at: <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-vit' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/gaia-vit</a><br/>Synced 5 W&B file(s), 0 media file(s), 298 artifact file(s) and 151 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241104_151040-taul22vs\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the hyperparameters\n",
    "num_classes = 4\n",
    "patch_size = 1\n",
    "dim = 16\n",
    "depth = 3\n",
    "heads = 4\n",
    "mlp_dim = 64\n",
    "dropout = 0.3\n",
    "batch_size = 512\n",
    "lr = 0.001\n",
    "patience = 30\n",
    "num_epochs = 200\n",
    "\n",
    "\n",
    "# Define the config dictionary object\n",
    "config = {\"num_classes\": num_classes, \"patch_size\": patch_size, \"dim\": dim, \"depth\": depth, \"heads\": heads, \"mlp_dim\": mlp_dim, \n",
    "          \"dropout\": dropout, \"batch_size\": batch_size, \"lr\": lr, \"patience\": patience}\n",
    "\n",
    "# Initialize WandB project\n",
    "wandb.init(project=\"gaia-vit\", entity=\"joaoc-university-of-southampton\", config=config)\n",
    "# Initialize and train the model\n",
    "model_vit = VisionTransformer1D(num_classes=num_classes, patch_size=patch_size, dim=dim, depth=depth, heads=heads, mlp_dim=mlp_dim, dropout=dropout, overlap=0)\n",
    "trained_model = train_model_vit(model_vit, train_loader, val_loader, test_loader, num_epochs=num_epochs, lr=lr, max_patience=patience)\n",
    "\n",
    "# Save the model and finish WandB session\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\jcwin\\OneDrive - University of Southampton\\_Southampton\\2024-25\\Star-Classifier\\wandb\\run-20241104_153651-o9ciw0hy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/joaoc-university-of-southampton/gaia-vit/runs/o9ciw0hy' target=\"_blank\">divine-shape-16</a></strong> to <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-vit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-vit' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/gaia-vit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-vit/runs/o9ciw0hy' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/gaia-vit/runs/o9ciw0hy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df333c8a8d2a46d187cde1fc56b5285b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.221 MB of 0.221 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>learning_rate</td><td>████████████████████████▄▄▄▃▃▃▃▂▂▂▁▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁▂▄▄▄▆▆▇▇▇▇▇▇█▇▇████████████████████████</td></tr><tr><td>test_loss</td><td>█▇▅▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▂▃▄▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇███▇▇██▇███████</td></tr><tr><td>train_loss</td><td>█▇▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▃▅▅▅▆▆▇▇▇▇████████████████████████████</td></tr><tr><td>val_loss</td><td>█▆▅▄▄▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>classification_report</td><td>              precis...</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>learning_rate</td><td>2e-05</td></tr><tr><td>test_accuracy</td><td>0.70684</td></tr><tr><td>test_loss</td><td>0.67709</td></tr><tr><td>train_accuracy</td><td>0.68935</td></tr><tr><td>train_loss</td><td>0.72315</td></tr><tr><td>val_accuracy</td><td>0.70423</td></tr><tr><td>val_loss</td><td>0.71598</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">divine-shape-16</strong> at: <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-vit/runs/o9ciw0hy' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/gaia-vit/runs/o9ciw0hy</a><br/> View project at: <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-vit' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/gaia-vit</a><br/>Synced 5 W&B file(s), 0 media file(s), 396 artifact file(s) and 200 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241104_153651-o9ciw0hy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the hyperparameters\n",
    "num_classes = 4\n",
    "patch_size = 2\n",
    "dim = 16\n",
    "depth = 3\n",
    "heads = 4\n",
    "mlp_dim = 64\n",
    "dropout = 0.3\n",
    "batch_size = 512\n",
    "lr = 0.001\n",
    "patience = 30\n",
    "num_epochs = 200\n",
    "\n",
    "\n",
    "# Define the config dictionary object\n",
    "config = {\"num_classes\": num_classes, \"patch_size\": patch_size, \"dim\": dim, \"depth\": depth, \"heads\": heads, \"mlp_dim\": mlp_dim, \n",
    "          \"dropout\": dropout, \"batch_size\": batch_size, \"lr\": lr, \"patience\": patience}\n",
    "\n",
    "# Initialize WandB project\n",
    "wandb.init(project=\"gaia-vit\", entity=\"joaoc-university-of-southampton\", config=config)\n",
    "# Initialize and train the model\n",
    "model_vit = VisionTransformer1D(num_classes=num_classes, patch_size=patch_size, dim=dim, depth=depth, heads=heads, mlp_dim=mlp_dim, dropout=dropout, overlap=0)\n",
    "trained_model = train_model_vit(model_vit, train_loader, val_loader, test_loader, num_epochs=num_epochs, lr=lr, max_patience=patience)\n",
    "\n",
    "# Save the model and finish WandB session\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\jcwin\\OneDrive - University of Southampton\\_Southampton\\2024-25\\Star-Classifier\\wandb\\run-20241104_152033-fow5v5we</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/joaoc-university-of-southampton/gaia-vit/runs/fow5v5we' target=\"_blank\">warm-wood-15</a></strong> to <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-vit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-vit' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/gaia-vit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-vit/runs/fow5v5we' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/gaia-vit/runs/fow5v5we</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344ace38dfd0417faf35b6e8e0d7e87e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.274 MB of 0.274 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇███</td></tr><tr><td>learning_rate</td><td>██████████▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁▃▇▇▇▇▇▇███▇▇███████████████████████████</td></tr><tr><td>test_loss</td><td>█▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▃▅▅▆▆▇▇▇▇▇▇▇▇█▇▇▇▇█▇█▇▇▇▇▇███▇█▇██▇█▇▇▇</td></tr><tr><td>train_loss</td><td>█▄▄▃▃▂▂▂▂▃▂▁▂▂▂▂▁▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▅▆▇▇▇▇▇███████████████████████████████</td></tr><tr><td>val_loss</td><td>█▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>classification_report</td><td>              precis...</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>learning_rate</td><td>2e-05</td></tr><tr><td>test_accuracy</td><td>0.65186</td></tr><tr><td>test_loss</td><td>0.75806</td></tr><tr><td>train_accuracy</td><td>0.64916</td></tr><tr><td>train_loss</td><td>0.77607</td></tr><tr><td>val_accuracy</td><td>0.67491</td></tr><tr><td>val_loss</td><td>0.7785</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">warm-wood-15</strong> at: <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-vit/runs/fow5v5we' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/gaia-vit/runs/fow5v5we</a><br/> View project at: <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-vit' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/gaia-vit</a><br/>Synced 5 W&B file(s), 0 media file(s), 396 artifact file(s) and 200 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241104_152033-fow5v5we\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the hyperparameters\n",
    "num_classes = 4\n",
    "patch_size = 1\n",
    "dim = 32\n",
    "depth = 10\n",
    "heads = 8\n",
    "mlp_dim = 256\n",
    "dropout = 0.3\n",
    "batch_size = 512\n",
    "lr = 0.001\n",
    "patience = 50\n",
    "num_epochs = 200\n",
    "\n",
    "\n",
    "# Define the config dictionary object\n",
    "config = {\"num_classes\": num_classes, \"patch_size\": patch_size, \"dim\": dim, \"depth\": depth, \"heads\": heads, \"mlp_dim\": mlp_dim, \n",
    "          \"dropout\": dropout, \"batch_size\": batch_size, \"lr\": lr, \"patience\": patience}\n",
    "\n",
    "# Initialize WandB project\n",
    "wandb.init(project=\"gaia-vit\", entity=\"joaoc-university-of-southampton\", config=config)\n",
    "# Initialize and train the model\n",
    "model_vit = VisionTransformer1D(num_classes=num_classes, patch_size=patch_size, dim=dim, depth=depth, heads=heads, mlp_dim=mlp_dim, dropout=dropout, overlap=0)\n",
    "trained_model = train_model_vit(model_vit, train_loader, val_loader, test_loader, num_epochs=num_epochs, lr=lr, max_patience=patience)\n",
    "\n",
    "# Save the model and finish WandB session\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\jcwin\\OneDrive - University of Southampton\\_Southampton\\2024-25\\Star-Classifier\\wandb\\run-20241104_151500-tausr4oj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/joaoc-university-of-southampton/gaia-vit/runs/tausr4oj' target=\"_blank\">sunny-cherry-14</a></strong> to <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-vit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-vit' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/gaia-vit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-vit/runs/tausr4oj' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/gaia-vit/runs/tausr4oj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "C:\\Users\\jcwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264a35557ca64b139b3df6f4105296be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.219 MB of 0.219 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>learning_rate</td><td>███████████████▄▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁▄▆▆▇▇▇▇▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>test_loss</td><td>█▆▄▃▄▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▄▅▅▆▇▇▇▇▇▇▇▇█▇█████████████████████████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███▇████████████████</td></tr><tr><td>val_loss</td><td>█▇▆▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>classification_report</td><td>              precis...</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>learning_rate</td><td>3e-05</td></tr><tr><td>test_accuracy</td><td>0.89287</td></tr><tr><td>test_loss</td><td>0.29216</td></tr><tr><td>train_accuracy</td><td>0.87809</td></tr><tr><td>train_loss</td><td>0.30457</td></tr><tr><td>val_accuracy</td><td>0.86124</td></tr><tr><td>val_loss</td><td>0.33497</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sunny-cherry-14</strong> at: <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-vit/runs/tausr4oj' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/gaia-vit/runs/tausr4oj</a><br/> View project at: <a href='https://wandb.ai/joaoc-university-of-southampton/gaia-vit' target=\"_blank\">https://wandb.ai/joaoc-university-of-southampton/gaia-vit</a><br/>Synced 5 W&B file(s), 0 media file(s), 392 artifact file(s) and 200 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241104_151500-tausr4oj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the hyperparameters\n",
    "num_classes = 4\n",
    "patch_size = 17\n",
    "dim = 32\n",
    "depth = 10\n",
    "heads = 8\n",
    "mlp_dim = 256\n",
    "dropout = 0.3\n",
    "batch_size = 512\n",
    "lr = 0.001\n",
    "patience = 50\n",
    "num_epochs = 200\n",
    "\n",
    "\n",
    "# Define the config dictionary object\n",
    "config = {\"num_classes\": num_classes, \"patch_size\": patch_size, \"dim\": dim, \"depth\": depth, \"heads\": heads, \"mlp_dim\": mlp_dim, \n",
    "          \"dropout\": dropout, \"batch_size\": batch_size, \"lr\": lr, \"patience\": patience}\n",
    "\n",
    "# Initialize WandB project\n",
    "wandb.init(project=\"gaia-vit\", entity=\"joaoc-university-of-southampton\", config=config)\n",
    "# Initialize and train the model\n",
    "model_vit = VisionTransformer1D(num_classes=num_classes, patch_size=patch_size, dim=dim, depth=depth, heads=heads, mlp_dim=mlp_dim, dropout=dropout, overlap=0)\n",
    "trained_model = train_model_vit(model_vit, train_loader, val_loader, test_loader, num_epochs=num_epochs, lr=lr, max_patience=patience)\n",
    "\n",
    "# Save the model and finish WandB session\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters\n",
    "num_classes = 4\n",
    "patch_size = 1\n",
    "dim = 32\n",
    "depth = 3\n",
    "heads = 8\n",
    "mlp_dim = 64\n",
    "dropout = 0.3\n",
    "batch_size = 512\n",
    "lr = 0.001\n",
    "patience = 30\n",
    "num_epochs = 200\n",
    "\n",
    "\n",
    "# Define the config dictionary object\n",
    "config = {\"num_classes\": num_classes, \"patch_size\": patch_size, \"dim\": dim, \"depth\": depth, \"heads\": heads, \"mlp_dim\": mlp_dim, \n",
    "          \"dropout\": dropout, \"batch_size\": batch_size, \"lr\": lr, \"patience\": patience}\n",
    "\n",
    "# Initialize WandB project\n",
    "wandb.init(project=\"gaia-vit\", entity=\"joaoc-university-of-southampton\", config=config)\n",
    "# Initialize and train the model\n",
    "model_vit = VisionTransformer1D(num_classes=num_classes, patch_size=patch_size, dim=dim, depth=depth, heads=heads, mlp_dim=mlp_dim, dropout=dropout, overlap=0)\n",
    "trained_model = train_model_vit(model_vit, train_loader, val_loader, test_loader, num_epochs=num_epochs, lr=lr, max_patience=patience)\n",
    "\n",
    "# Save the model and finish WandB session\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your input size is the number of features in your dataset\n",
    "input_size = 17  # Adjust this based on your actual number of features\n",
    "num_classes = 4  # Number of classes in your classification problem\n",
    "\n",
    "model = FCNN(input_size=17, hidden_sizes=[64, 128, 512, 512,512, 128, 64], num_classes=4)\n",
    "\n",
    "print(model)\n",
    "print(\"Number of parameters:\", sum(p.numel() for p in model.parameters() if p.requires_grad))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
